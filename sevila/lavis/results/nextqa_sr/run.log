2023-10-29 22:06:40,814 [INFO] 
=====  Running Parameters    =====
2023-10-29 22:06:40,815 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 8,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "find_unused_parameters": true,
    "gpu": 0,
    "init_lr": 3e-05,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 0,
    "num_beams": 5,
    "num_workers": 8,
    "output_dir": "results/nextqa_sr",
    "rank": 0,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "videoqa",
    "test_splits": [
        "val"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "warmup_lr": 1e-08,
    "warmup_steps": 500,
    "weight_decay": 0.05,
    "world_size": 1
}
2023-10-29 22:06:40,815 [INFO] 
======  Dataset Attributes  ======
2023-10-29 22:06:40,815 [INFO] 
======== nextqa =======
2023-10-29 22:06:40,816 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "storage": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json",
                "url": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json"
            },
            "train": {
                "storage": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/train.json",
                "url": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/train.json"
            },
            "val": {
                "storage": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json",
                "url": "/root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json"
            }
        },
        "videos": {
            "storage": "/root/autodl-tmp/VQA/NExT-QA/NExTVideo"
        }
    },
    "data_type": "videos",
    "text_processor": {
        "eval": {
            "max_words": 50,
            "name": "blip_question"
        },
        "train": {
            "max_words": 50,
            "name": "blip_question"
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 224,
            "n_frms": 32,
            "name": "blip_video_eval"
        },
        "train": {
            "image_size": 224,
            "n_frms": 4,
            "name": "blip2_video_train"
        }
    }
}
2023-10-29 22:06:40,816 [INFO] 
======  Model Attributes  ======
2023-10-29 22:06:40,816 [INFO] {
    "answer_num": 5,
    "arch": "sevila",
    "drop_path_rate": 0,
    "finetuned": "sevila_checkpoints/sevila_pretrained.pth",
    "frame_num": 4,
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": true,
    "model_type": "pretrain_flant5xl",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth",
    "prompt": "",
    "t5_model": "google/flan-t5-xl",
    "task": "qvh_train_loc_freeze_qa_vid",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
2023-10-29 22:06:40,817 [INFO] Using existing file /root/autodl-tmp/VQA/NExT-QA/qa_annos/train.json.
2023-10-29 22:06:40,817 [INFO] Using existing file /root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json.
2023-10-29 22:06:40,817 [INFO] Using existing file /root/autodl-tmp/VQA/NExT-QA/qa_annos/val.json.
2023-10-29 22:06:40,817 [INFO] Building datasets...
2023-10-29 22:06:58,029 [INFO] freeze vision encoder
2023-10-29 22:07:08,084 [WARNING] '(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /google/flan-t5-xl/resolve/main/tokenizer_config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f9404eed5d0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 371770ef-d6ba-43a6-a398-d2d797532679)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-xl/resolve/main/tokenizer_config.json
2023-10-29 22:07:48,817 [INFO] Missing keys ['visual_encoder.cls_token', 'visual_encoder.pos_embed', 'visual_encoder.patch_embed.proj.weight', 'visual_encoder.patch_embed.proj.bias', 'visual_encoder.blocks.0.norm1.weight', 'visual_encoder.blocks.0.norm1.bias', 'visual_encoder.blocks.0.attn.q_bias', 'visual_encoder.blocks.0.attn.v_bias', 'visual_encoder.blocks.0.attn.qkv.weight', 'visual_encoder.blocks.0.attn.proj.weight', 'visual_encoder.blocks.0.attn.proj.bias', 'visual_encoder.blocks.0.norm2.weight', 'visual_encoder.blocks.0.norm2.bias', 'visual_encoder.blocks.0.mlp.fc1.weight', 'visual_encoder.blocks.0.mlp.fc1.bias', 'visual_encoder.blocks.0.mlp.fc2.weight', 'visual_encoder.blocks.0.mlp.fc2.bias', 'visual_encoder.blocks.1.norm1.weight', 'visual_encoder.blocks.1.norm1.bias', 'visual_encoder.blocks.1.attn.q_bias', 'visual_encoder.blocks.1.attn.v_bias', 'visual_encoder.blocks.1.attn.qkv.weight', 'visual_encoder.blocks.1.attn.proj.weight', 'visual_encoder.blocks.1.attn.proj.bias', 'visual_encoder.blocks.1.norm2.weight', 'visual_encoder.blocks.1.norm2.bias', 'visual_encoder.blocks.1.mlp.fc1.weight', 'visual_encoder.blocks.1.mlp.fc1.bias', 'visual_encoder.blocks.1.mlp.fc2.weight', 'visual_encoder.blocks.1.mlp.fc2.bias', 'visual_encoder.blocks.2.norm1.weight', 'visual_encoder.blocks.2.norm1.bias', 'visual_encoder.blocks.2.attn.q_bias', 'visual_encoder.blocks.2.attn.v_bias', 'visual_encoder.blocks.2.attn.qkv.weight', 'visual_encoder.blocks.2.attn.proj.weight', 'visual_encoder.blocks.2.attn.proj.bias', 'visual_encoder.blocks.2.norm2.weight', 'visual_encoder.blocks.2.norm2.bias', 'visual_encoder.blocks.2.mlp.fc1.weight', 'visual_encoder.blocks.2.mlp.fc1.bias', 'visual_encoder.blocks.2.mlp.fc2.weight', 'visual_encoder.blocks.2.mlp.fc2.bias', 'visual_encoder.blocks.3.norm1.weight', 'visual_encoder.blocks.3.norm1.bias', 'visual_encoder.blocks.3.attn.q_bias', 'visual_encoder.blocks.3.attn.v_bias', 'visual_encoder.blocks.3.attn.qkv.weight', 'visual_encoder.blocks.3.attn.proj.weight', 'visual_encoder.blocks.3.attn.proj.bias', 'visual_encoder.blocks.3.norm2.weight', 'visual_encoder.blocks.3.norm2.bias', 'visual_encoder.blocks.3.mlp.fc1.weight', 'visual_encoder.blocks.3.mlp.fc1.bias', 'visual_encoder.blocks.3.mlp.fc2.weight', 'visual_encoder.blocks.3.mlp.fc2.bias', 'visual_encoder.blocks.4.norm1.weight', 'visual_encoder.blocks.4.norm1.bias', 'visual_encoder.blocks.4.attn.q_bias', 'visual_encoder.blocks.4.attn.v_bias', 'visual_encoder.blocks.4.attn.qkv.weight', 'visual_encoder.blocks.4.attn.proj.weight', 'visual_encoder.blocks.4.attn.proj.bias', 'visual_encoder.blocks.4.norm2.weight', 'visual_encoder.blocks.4.norm2.bias', 'visual_encoder.blocks.4.mlp.fc1.weight', 'visual_encoder.blocks.4.mlp.fc1.bias', 'visual_encoder.blocks.4.mlp.fc2.weight', 'visual_encoder.blocks.4.mlp.fc2.bias', 'visual_encoder.blocks.5.norm1.weight', 'visual_encoder.blocks.5.norm1.bias', 'visual_encoder.blocks.5.attn.q_bias', 'visual_encoder.blocks.5.attn.v_bias', 'visual_encoder.blocks.5.attn.qkv.weight', 'visual_encoder.blocks.5.attn.proj.weight', 'visual_encoder.blocks.5.attn.proj.bias', 'visual_encoder.blocks.5.norm2.weight', 'visual_encoder.blocks.5.norm2.bias', 'visual_encoder.blocks.5.mlp.fc1.weight', 'visual_encoder.blocks.5.mlp.fc1.bias', 'visual_encoder.blocks.5.mlp.fc2.weight', 'visual_encoder.blocks.5.mlp.fc2.bias', 'visual_encoder.blocks.6.norm1.weight', 'visual_encoder.blocks.6.norm1.bias', 'visual_encoder.blocks.6.attn.q_bias', 'visual_encoder.blocks.6.attn.v_bias', 'visual_encoder.blocks.6.attn.qkv.weight', 'visual_encoder.blocks.6.attn.proj.weight', 'visual_encoder.blocks.6.attn.proj.bias', 'visual_encoder.blocks.6.norm2.weight', 'visual_encoder.blocks.6.norm2.bias', 'visual_encoder.blocks.6.mlp.fc1.weight', 'visual_encoder.blocks.6.mlp.fc1.bias', 'visual_encoder.blocks.6.mlp.fc2.weight', 'visual_encoder.blocks.6.mlp.fc2.bias', 'visual_encoder.blocks.7.norm1.weight', 'visual_encoder.blocks.7.norm1.bias', 'visual_encoder.blocks.7.attn.q_bias', 'visual_encoder.blocks.7.attn.v_bias', 'visual_encoder.blocks.7.attn.qkv.weight', 'visual_encoder.blocks.7.attn.proj.weight', 'visual_encoder.blocks.7.attn.proj.bias', 'visual_encoder.blocks.7.norm2.weight', 'visual_encoder.blocks.7.norm2.bias', 'visual_encoder.blocks.7.mlp.fc1.weight', 'visual_encoder.blocks.7.mlp.fc1.bias', 'visual_encoder.blocks.7.mlp.fc2.weight', 'visual_encoder.blocks.7.mlp.fc2.bias', 'visual_encoder.blocks.8.norm1.weight', 'visual_encoder.blocks.8.norm1.bias', 'visual_encoder.blocks.8.attn.q_bias', 'visual_encoder.blocks.8.attn.v_bias', 'visual_encoder.blocks.8.attn.qkv.weight', 'visual_encoder.blocks.8.attn.proj.weight', 'visual_encoder.blocks.8.attn.proj.bias', 'visual_encoder.blocks.8.norm2.weight', 'visual_encoder.blocks.8.norm2.bias', 'visual_encoder.blocks.8.mlp.fc1.weight', 'visual_encoder.blocks.8.mlp.fc1.bias', 'visual_encoder.blocks.8.mlp.fc2.weight', 'visual_encoder.blocks.8.mlp.fc2.bias', 'visual_encoder.blocks.9.norm1.weight', 'visual_encoder.blocks.9.norm1.bias', 'visual_encoder.blocks.9.attn.q_bias', 'visual_encoder.blocks.9.attn.v_bias', 'visual_encoder.blocks.9.attn.qkv.weight', 'visual_encoder.blocks.9.attn.proj.weight', 'visual_encoder.blocks.9.attn.proj.bias', 'visual_encoder.blocks.9.norm2.weight', 'visual_encoder.blocks.9.norm2.bias', 'visual_encoder.blocks.9.mlp.fc1.weight', 'visual_encoder.blocks.9.mlp.fc1.bias', 'visual_encoder.blocks.9.mlp.fc2.weight', 'visual_encoder.blocks.9.mlp.fc2.bias', 'visual_encoder.blocks.10.norm1.weight', 'visual_encoder.blocks.10.norm1.bias', 'visual_encoder.blocks.10.attn.q_bias', 'visual_encoder.blocks.10.attn.v_bias', 'visual_encoder.blocks.10.attn.qkv.weight', 'visual_encoder.blocks.10.attn.proj.weight', 'visual_encoder.blocks.10.attn.proj.bias', 'visual_encoder.blocks.10.norm2.weight', 'visual_encoder.blocks.10.norm2.bias', 'visual_encoder.blocks.10.mlp.fc1.weight', 'visual_encoder.blocks.10.mlp.fc1.bias', 'visual_encoder.blocks.10.mlp.fc2.weight', 'visual_encoder.blocks.10.mlp.fc2.bias', 'visual_encoder.blocks.11.norm1.weight', 'visual_encoder.blocks.11.norm1.bias', 'visual_encoder.blocks.11.attn.q_bias', 'visual_encoder.blocks.11.attn.v_bias', 'visual_encoder.blocks.11.attn.qkv.weight', 'visual_encoder.blocks.11.attn.proj.weight', 'visual_encoder.blocks.11.attn.proj.bias', 'visual_encoder.blocks.11.norm2.weight', 'visual_encoder.blocks.11.norm2.bias', 'visual_encoder.blocks.11.mlp.fc1.weight', 'visual_encoder.blocks.11.mlp.fc1.bias', 'visual_encoder.blocks.11.mlp.fc2.weight', 'visual_encoder.blocks.11.mlp.fc2.bias', 'visual_encoder.blocks.12.norm1.weight', 'visual_encoder.blocks.12.norm1.bias', 'visual_encoder.blocks.12.attn.q_bias', 'visual_encoder.blocks.12.attn.v_bias', 'visual_encoder.blocks.12.attn.qkv.weight', 'visual_encoder.blocks.12.attn.proj.weight', 'visual_encoder.blocks.12.attn.proj.bias', 'visual_encoder.blocks.12.norm2.weight', 'visual_encoder.blocks.12.norm2.bias', 'visual_encoder.blocks.12.mlp.fc1.weight', 'visual_encoder.blocks.12.mlp.fc1.bias', 'visual_encoder.blocks.12.mlp.fc2.weight', 'visual_encoder.blocks.12.mlp.fc2.bias', 'visual_encoder.blocks.13.norm1.weight', 'visual_encoder.blocks.13.norm1.bias', 'visual_encoder.blocks.13.attn.q_bias', 'visual_encoder.blocks.13.attn.v_bias', 'visual_encoder.blocks.13.attn.qkv.weight', 'visual_encoder.blocks.13.attn.proj.weight', 'visual_encoder.blocks.13.attn.proj.bias', 'visual_encoder.blocks.13.norm2.weight', 'visual_encoder.blocks.13.norm2.bias', 'visual_encoder.blocks.13.mlp.fc1.weight', 'visual_encoder.blocks.13.mlp.fc1.bias', 'visual_encoder.blocks.13.mlp.fc2.weight', 'visual_encoder.blocks.13.mlp.fc2.bias', 'visual_encoder.blocks.14.norm1.weight', 'visual_encoder.blocks.14.norm1.bias', 'visual_encoder.blocks.14.attn.q_bias', 'visual_encoder.blocks.14.attn.v_bias', 'visual_encoder.blocks.14.attn.qkv.weight', 'visual_encoder.blocks.14.attn.proj.weight', 'visual_encoder.blocks.14.attn.proj.bias', 'visual_encoder.blocks.14.norm2.weight', 'visual_encoder.blocks.14.norm2.bias', 'visual_encoder.blocks.14.mlp.fc1.weight', 'visual_encoder.blocks.14.mlp.fc1.bias', 'visual_encoder.blocks.14.mlp.fc2.weight', 'visual_encoder.blocks.14.mlp.fc2.bias', 'visual_encoder.blocks.15.norm1.weight', 'visual_encoder.blocks.15.norm1.bias', 'visual_encoder.blocks.15.attn.q_bias', 'visual_encoder.blocks.15.attn.v_bias', 'visual_encoder.blocks.15.attn.qkv.weight', 'visual_encoder.blocks.15.attn.proj.weight', 'visual_encoder.blocks.15.attn.proj.bias', 'visual_encoder.blocks.15.norm2.weight', 'visual_encoder.blocks.15.norm2.bias', 'visual_encoder.blocks.15.mlp.fc1.weight', 'visual_encoder.blocks.15.mlp.fc1.bias', 'visual_encoder.blocks.15.mlp.fc2.weight', 'visual_encoder.blocks.15.mlp.fc2.bias', 'visual_encoder.blocks.16.norm1.weight', 'visual_encoder.blocks.16.norm1.bias', 'visual_encoder.blocks.16.attn.q_bias', 'visual_encoder.blocks.16.attn.v_bias', 'visual_encoder.blocks.16.attn.qkv.weight', 'visual_encoder.blocks.16.attn.proj.weight', 'visual_encoder.blocks.16.attn.proj.bias', 'visual_encoder.blocks.16.norm2.weight', 'visual_encoder.blocks.16.norm2.bias', 'visual_encoder.blocks.16.mlp.fc1.weight', 'visual_encoder.blocks.16.mlp.fc1.bias', 'visual_encoder.blocks.16.mlp.fc2.weight', 'visual_encoder.blocks.16.mlp.fc2.bias', 'visual_encoder.blocks.17.norm1.weight', 'visual_encoder.blocks.17.norm1.bias', 'visual_encoder.blocks.17.attn.q_bias', 'visual_encoder.blocks.17.attn.v_bias', 'visual_encoder.blocks.17.attn.qkv.weight', 'visual_encoder.blocks.17.attn.proj.weight', 'visual_encoder.blocks.17.attn.proj.bias', 'visual_encoder.blocks.17.norm2.weight', 'visual_encoder.blocks.17.norm2.bias', 'visual_encoder.blocks.17.mlp.fc1.weight', 'visual_encoder.blocks.17.mlp.fc1.bias', 'visual_encoder.blocks.17.mlp.fc2.weight', 'visual_encoder.blocks.17.mlp.fc2.bias', 'visual_encoder.blocks.18.norm1.weight', 'visual_encoder.blocks.18.norm1.bias', 'visual_encoder.blocks.18.attn.q_bias', 'visual_encoder.blocks.18.attn.v_bias', 'visual_encoder.blocks.18.attn.qkv.weight', 'visual_encoder.blocks.18.attn.proj.weight', 'visual_encoder.blocks.18.attn.proj.bias', 'visual_encoder.blocks.18.norm2.weight', 'visual_encoder.blocks.18.norm2.bias', 'visual_encoder.blocks.18.mlp.fc1.weight', 'visual_encoder.blocks.18.mlp.fc1.bias', 'visual_encoder.blocks.18.mlp.fc2.weight', 'visual_encoder.blocks.18.mlp.fc2.bias', 'visual_encoder.blocks.19.norm1.weight', 'visual_encoder.blocks.19.norm1.bias', 'visual_encoder.blocks.19.attn.q_bias', 'visual_encoder.blocks.19.attn.v_bias', 'visual_encoder.blocks.19.attn.qkv.weight', 'visual_encoder.blocks.19.attn.proj.weight', 'visual_encoder.blocks.19.attn.proj.bias', 'visual_encoder.blocks.19.norm2.weight', 'visual_encoder.blocks.19.norm2.bias', 'visual_encoder.blocks.19.mlp.fc1.weight', 'visual_encoder.blocks.19.mlp.fc1.bias', 'visual_encoder.blocks.19.mlp.fc2.weight', 'visual_encoder.blocks.19.mlp.fc2.bias', 'visual_encoder.blocks.20.norm1.weight', 'visual_encoder.blocks.20.norm1.bias', 'visual_encoder.blocks.20.attn.q_bias', 'visual_encoder.blocks.20.attn.v_bias', 'visual_encoder.blocks.20.attn.qkv.weight', 'visual_encoder.blocks.20.attn.proj.weight', 'visual_encoder.blocks.20.attn.proj.bias', 'visual_encoder.blocks.20.norm2.weight', 'visual_encoder.blocks.20.norm2.bias', 'visual_encoder.blocks.20.mlp.fc1.weight', 'visual_encoder.blocks.20.mlp.fc1.bias', 'visual_encoder.blocks.20.mlp.fc2.weight', 'visual_encoder.blocks.20.mlp.fc2.bias', 'visual_encoder.blocks.21.norm1.weight', 'visual_encoder.blocks.21.norm1.bias', 'visual_encoder.blocks.21.attn.q_bias', 'visual_encoder.blocks.21.attn.v_bias', 'visual_encoder.blocks.21.attn.qkv.weight', 'visual_encoder.blocks.21.attn.proj.weight', 'visual_encoder.blocks.21.attn.proj.bias', 'visual_encoder.blocks.21.norm2.weight', 'visual_encoder.blocks.21.norm2.bias', 'visual_encoder.blocks.21.mlp.fc1.weight', 'visual_encoder.blocks.21.mlp.fc1.bias', 'visual_encoder.blocks.21.mlp.fc2.weight', 'visual_encoder.blocks.21.mlp.fc2.bias', 'visual_encoder.blocks.22.norm1.weight', 'visual_encoder.blocks.22.norm1.bias', 'visual_encoder.blocks.22.attn.q_bias', 'visual_encoder.blocks.22.attn.v_bias', 'visual_encoder.blocks.22.attn.qkv.weight', 'visual_encoder.blocks.22.attn.proj.weight', 'visual_encoder.blocks.22.attn.proj.bias', 'visual_encoder.blocks.22.norm2.weight', 'visual_encoder.blocks.22.norm2.bias', 'visual_encoder.blocks.22.mlp.fc1.weight', 'visual_encoder.blocks.22.mlp.fc1.bias', 'visual_encoder.blocks.22.mlp.fc2.weight', 'visual_encoder.blocks.22.mlp.fc2.bias', 'visual_encoder.blocks.23.norm1.weight', 'visual_encoder.blocks.23.norm1.bias', 'visual_encoder.blocks.23.attn.q_bias', 'visual_encoder.blocks.23.attn.v_bias', 'visual_encoder.blocks.23.attn.qkv.weight', 'visual_encoder.blocks.23.attn.proj.weight', 'visual_encoder.blocks.23.attn.proj.bias', 'visual_encoder.blocks.23.norm2.weight', 'visual_encoder.blocks.23.norm2.bias', 'visual_encoder.blocks.23.mlp.fc1.weight', 'visual_encoder.blocks.23.mlp.fc1.bias', 'visual_encoder.blocks.23.mlp.fc2.weight', 'visual_encoder.blocks.23.mlp.fc2.bias', 'visual_encoder.blocks.24.norm1.weight', 'visual_encoder.blocks.24.norm1.bias', 'visual_encoder.blocks.24.attn.q_bias', 'visual_encoder.blocks.24.attn.v_bias', 'visual_encoder.blocks.24.attn.qkv.weight', 'visual_encoder.blocks.24.attn.proj.weight', 'visual_encoder.blocks.24.attn.proj.bias', 'visual_encoder.blocks.24.norm2.weight', 'visual_encoder.blocks.24.norm2.bias', 'visual_encoder.blocks.24.mlp.fc1.weight', 'visual_encoder.blocks.24.mlp.fc1.bias', 'visual_encoder.blocks.24.mlp.fc2.weight', 'visual_encoder.blocks.24.mlp.fc2.bias', 'visual_encoder.blocks.25.norm1.weight', 'visual_encoder.blocks.25.norm1.bias', 'visual_encoder.blocks.25.attn.q_bias', 'visual_encoder.blocks.25.attn.v_bias', 'visual_encoder.blocks.25.attn.qkv.weight', 'visual_encoder.blocks.25.attn.proj.weight', 'visual_encoder.blocks.25.attn.proj.bias', 'visual_encoder.blocks.25.norm2.weight', 'visual_encoder.blocks.25.norm2.bias', 'visual_encoder.blocks.25.mlp.fc1.weight', 'visual_encoder.blocks.25.mlp.fc1.bias', 'visual_encoder.blocks.25.mlp.fc2.weight', 'visual_encoder.blocks.25.mlp.fc2.bias', 'visual_encoder.blocks.26.norm1.weight', 'visual_encoder.blocks.26.norm1.bias', 'visual_encoder.blocks.26.attn.q_bias', 'visual_encoder.blocks.26.attn.v_bias', 'visual_encoder.blocks.26.attn.qkv.weight', 'visual_encoder.blocks.26.attn.proj.weight', 'visual_encoder.blocks.26.attn.proj.bias', 'visual_encoder.blocks.26.norm2.weight', 'visual_encoder.blocks.26.norm2.bias', 'visual_encoder.blocks.26.mlp.fc1.weight', 'visual_encoder.blocks.26.mlp.fc1.bias', 'visual_encoder.blocks.26.mlp.fc2.weight', 'visual_encoder.blocks.26.mlp.fc2.bias', 'visual_encoder.blocks.27.norm1.weight', 'visual_encoder.blocks.27.norm1.bias', 'visual_encoder.blocks.27.attn.q_bias', 'visual_encoder.blocks.27.attn.v_bias', 'visual_encoder.blocks.27.attn.qkv.weight', 'visual_encoder.blocks.27.attn.proj.weight', 'visual_encoder.blocks.27.attn.proj.bias', 'visual_encoder.blocks.27.norm2.weight', 'visual_encoder.blocks.27.norm2.bias', 'visual_encoder.blocks.27.mlp.fc1.weight', 'visual_encoder.blocks.27.mlp.fc1.bias', 'visual_encoder.blocks.27.mlp.fc2.weight', 'visual_encoder.blocks.27.mlp.fc2.bias', 'visual_encoder.blocks.28.norm1.weight', 'visual_encoder.blocks.28.norm1.bias', 'visual_encoder.blocks.28.attn.q_bias', 'visual_encoder.blocks.28.attn.v_bias', 'visual_encoder.blocks.28.attn.qkv.weight', 'visual_encoder.blocks.28.attn.proj.weight', 'visual_encoder.blocks.28.attn.proj.bias', 'visual_encoder.blocks.28.norm2.weight', 'visual_encoder.blocks.28.norm2.bias', 'visual_encoder.blocks.28.mlp.fc1.weight', 'visual_encoder.blocks.28.mlp.fc1.bias', 'visual_encoder.blocks.28.mlp.fc2.weight', 'visual_encoder.blocks.28.mlp.fc2.bias', 'visual_encoder.blocks.29.norm1.weight', 'visual_encoder.blocks.29.norm1.bias', 'visual_encoder.blocks.29.attn.q_bias', 'visual_encoder.blocks.29.attn.v_bias', 'visual_encoder.blocks.29.attn.qkv.weight', 'visual_encoder.blocks.29.attn.proj.weight', 'visual_encoder.blocks.29.attn.proj.bias', 'visual_encoder.blocks.29.norm2.weight', 'visual_encoder.blocks.29.norm2.bias', 'visual_encoder.blocks.29.mlp.fc1.weight', 'visual_encoder.blocks.29.mlp.fc1.bias', 'visual_encoder.blocks.29.mlp.fc2.weight', 'visual_encoder.blocks.29.mlp.fc2.bias', 'visual_encoder.blocks.30.norm1.weight', 'visual_encoder.blocks.30.norm1.bias', 'visual_encoder.blocks.30.attn.q_bias', 'visual_encoder.blocks.30.attn.v_bias', 'visual_encoder.blocks.30.attn.qkv.weight', 'visual_encoder.blocks.30.attn.proj.weight', 'visual_encoder.blocks.30.attn.proj.bias', 'visual_encoder.blocks.30.norm2.weight', 'visual_encoder.blocks.30.norm2.bias', 'visual_encoder.blocks.30.mlp.fc1.weight', 'visual_encoder.blocks.30.mlp.fc1.bias', 'visual_encoder.blocks.30.mlp.fc2.weight', 'visual_encoder.blocks.30.mlp.fc2.bias', 'visual_encoder.blocks.31.norm1.weight', 'visual_encoder.blocks.31.norm1.bias', 'visual_encoder.blocks.31.attn.q_bias', 'visual_encoder.blocks.31.attn.v_bias', 'visual_encoder.blocks.31.attn.qkv.weight', 'visual_encoder.blocks.31.attn.proj.weight', 'visual_encoder.blocks.31.attn.proj.bias', 'visual_encoder.blocks.31.norm2.weight', 'visual_encoder.blocks.31.norm2.bias', 'visual_encoder.blocks.31.mlp.fc1.weight', 'visual_encoder.blocks.31.mlp.fc1.bias', 'visual_encoder.blocks.31.mlp.fc2.weight', 'visual_encoder.blocks.31.mlp.fc2.bias', 'visual_encoder.blocks.32.norm1.weight', 'visual_encoder.blocks.32.norm1.bias', 'visual_encoder.blocks.32.attn.q_bias', 'visual_encoder.blocks.32.attn.v_bias', 'visual_encoder.blocks.32.attn.qkv.weight', 'visual_encoder.blocks.32.attn.proj.weight', 'visual_encoder.blocks.32.attn.proj.bias', 'visual_encoder.blocks.32.norm2.weight', 'visual_encoder.blocks.32.norm2.bias', 'visual_encoder.blocks.32.mlp.fc1.weight', 'visual_encoder.blocks.32.mlp.fc1.bias', 'visual_encoder.blocks.32.mlp.fc2.weight', 'visual_encoder.blocks.32.mlp.fc2.bias', 'visual_encoder.blocks.33.norm1.weight', 'visual_encoder.blocks.33.norm1.bias', 'visual_encoder.blocks.33.attn.q_bias', 'visual_encoder.blocks.33.attn.v_bias', 'visual_encoder.blocks.33.attn.qkv.weight', 'visual_encoder.blocks.33.attn.proj.weight', 'visual_encoder.blocks.33.attn.proj.bias', 'visual_encoder.blocks.33.norm2.weight', 'visual_encoder.blocks.33.norm2.bias', 'visual_encoder.blocks.33.mlp.fc1.weight', 'visual_encoder.blocks.33.mlp.fc1.bias', 'visual_encoder.blocks.33.mlp.fc2.weight', 'visual_encoder.blocks.33.mlp.fc2.bias', 'visual_encoder.blocks.34.norm1.weight', 'visual_encoder.blocks.34.norm1.bias', 'visual_encoder.blocks.34.attn.q_bias', 'visual_encoder.blocks.34.attn.v_bias', 'visual_encoder.blocks.34.attn.qkv.weight', 'visual_encoder.blocks.34.attn.proj.weight', 'visual_encoder.blocks.34.attn.proj.bias', 'visual_encoder.blocks.34.norm2.weight', 'visual_encoder.blocks.34.norm2.bias', 'visual_encoder.blocks.34.mlp.fc1.weight', 'visual_encoder.blocks.34.mlp.fc1.bias', 'visual_encoder.blocks.34.mlp.fc2.weight', 'visual_encoder.blocks.34.mlp.fc2.bias', 'visual_encoder.blocks.35.norm1.weight', 'visual_encoder.blocks.35.norm1.bias', 'visual_encoder.blocks.35.attn.q_bias', 'visual_encoder.blocks.35.attn.v_bias', 'visual_encoder.blocks.35.attn.qkv.weight', 'visual_encoder.blocks.35.attn.proj.weight', 'visual_encoder.blocks.35.attn.proj.bias', 'visual_encoder.blocks.35.norm2.weight', 'visual_encoder.blocks.35.norm2.bias', 'visual_encoder.blocks.35.mlp.fc1.weight', 'visual_encoder.blocks.35.mlp.fc1.bias', 'visual_encoder.blocks.35.mlp.fc2.weight', 'visual_encoder.blocks.35.mlp.fc2.bias', 'visual_encoder.blocks.36.norm1.weight', 'visual_encoder.blocks.36.norm1.bias', 'visual_encoder.blocks.36.attn.q_bias', 'visual_encoder.blocks.36.attn.v_bias', 'visual_encoder.blocks.36.attn.qkv.weight', 'visual_encoder.blocks.36.attn.proj.weight', 'visual_encoder.blocks.36.attn.proj.bias', 'visual_encoder.blocks.36.norm2.weight', 'visual_encoder.blocks.36.norm2.bias', 'visual_encoder.blocks.36.mlp.fc1.weight', 'visual_encoder.blocks.36.mlp.fc1.bias', 'visual_encoder.blocks.36.mlp.fc2.weight', 'visual_encoder.blocks.36.mlp.fc2.bias', 'visual_encoder.blocks.37.norm1.weight', 'visual_encoder.blocks.37.norm1.bias', 'visual_encoder.blocks.37.attn.q_bias', 'visual_encoder.blocks.37.attn.v_bias', 'visual_encoder.blocks.37.attn.qkv.weight', 'visual_encoder.blocks.37.attn.proj.weight', 'visual_encoder.blocks.37.attn.proj.bias', 'visual_encoder.blocks.37.norm2.weight', 'visual_encoder.blocks.37.norm2.bias', 'visual_encoder.blocks.37.mlp.fc1.weight', 'visual_encoder.blocks.37.mlp.fc1.bias', 'visual_encoder.blocks.37.mlp.fc2.weight', 'visual_encoder.blocks.37.mlp.fc2.bias', 'visual_encoder.blocks.38.norm1.weight', 'visual_encoder.blocks.38.norm1.bias', 'visual_encoder.blocks.38.attn.q_bias', 'visual_encoder.blocks.38.attn.v_bias', 'visual_encoder.blocks.38.attn.qkv.weight', 'visual_encoder.blocks.38.attn.proj.weight', 'visual_encoder.blocks.38.attn.proj.bias', 'visual_encoder.blocks.38.norm2.weight', 'visual_encoder.blocks.38.norm2.bias', 'visual_encoder.blocks.38.mlp.fc1.weight', 'visual_encoder.blocks.38.mlp.fc1.bias', 'visual_encoder.blocks.38.mlp.fc2.weight', 'visual_encoder.blocks.38.mlp.fc2.bias', 't5_model.shared.weight', 't5_model.encoder.embed_tokens.weight', 't5_model.encoder.block.0.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.0.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.0.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.0.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 't5_model.encoder.block.0.layer.0.layer_norm.weight', 't5_model.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.0.layer.1.layer_norm.weight', 't5_model.encoder.block.1.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.1.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.1.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.1.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.1.layer.0.layer_norm.weight', 't5_model.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.1.layer.1.layer_norm.weight', 't5_model.encoder.block.2.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.2.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.2.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.2.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.2.layer.0.layer_norm.weight', 't5_model.encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.2.layer.1.layer_norm.weight', 't5_model.encoder.block.3.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.3.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.3.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.3.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.3.layer.0.layer_norm.weight', 't5_model.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.3.layer.1.layer_norm.weight', 't5_model.encoder.block.4.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.4.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.4.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.4.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.4.layer.0.layer_norm.weight', 't5_model.encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.4.layer.1.layer_norm.weight', 't5_model.encoder.block.5.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.5.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.5.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.5.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.5.layer.0.layer_norm.weight', 't5_model.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.5.layer.1.layer_norm.weight', 't5_model.encoder.block.6.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.6.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.6.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.6.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.6.layer.0.layer_norm.weight', 't5_model.encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.6.layer.1.layer_norm.weight', 't5_model.encoder.block.7.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.7.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.7.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.7.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.7.layer.0.layer_norm.weight', 't5_model.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.7.layer.1.layer_norm.weight', 't5_model.encoder.block.8.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.8.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.8.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.8.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.8.layer.0.layer_norm.weight', 't5_model.encoder.block.8.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.8.layer.1.layer_norm.weight', 't5_model.encoder.block.9.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.9.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.9.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.9.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.9.layer.0.layer_norm.weight', 't5_model.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.9.layer.1.layer_norm.weight', 't5_model.encoder.block.10.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.10.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.10.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.10.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.10.layer.0.layer_norm.weight', 't5_model.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.10.layer.1.layer_norm.weight', 't5_model.encoder.block.11.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.11.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.11.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.11.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.11.layer.0.layer_norm.weight', 't5_model.encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.11.layer.1.layer_norm.weight', 't5_model.encoder.block.12.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.12.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.12.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.12.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.12.layer.0.layer_norm.weight', 't5_model.encoder.block.12.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.12.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.12.layer.1.layer_norm.weight', 't5_model.encoder.block.13.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.13.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.13.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.13.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.13.layer.0.layer_norm.weight', 't5_model.encoder.block.13.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.13.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.13.layer.1.layer_norm.weight', 't5_model.encoder.block.14.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.14.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.14.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.14.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.14.layer.0.layer_norm.weight', 't5_model.encoder.block.14.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.14.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.14.layer.1.layer_norm.weight', 't5_model.encoder.block.15.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.15.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.15.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.15.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.15.layer.0.layer_norm.weight', 't5_model.encoder.block.15.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.15.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.15.layer.1.layer_norm.weight', 't5_model.encoder.block.16.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.16.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.16.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.16.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.16.layer.0.layer_norm.weight', 't5_model.encoder.block.16.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.16.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.16.layer.1.layer_norm.weight', 't5_model.encoder.block.17.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.17.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.17.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.17.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.17.layer.0.layer_norm.weight', 't5_model.encoder.block.17.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.17.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.17.layer.1.layer_norm.weight', 't5_model.encoder.block.18.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.18.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.18.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.18.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.18.layer.0.layer_norm.weight', 't5_model.encoder.block.18.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.18.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.18.layer.1.layer_norm.weight', 't5_model.encoder.block.19.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.19.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.19.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.19.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.19.layer.0.layer_norm.weight', 't5_model.encoder.block.19.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.19.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.19.layer.1.layer_norm.weight', 't5_model.encoder.block.20.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.20.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.20.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.20.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.20.layer.0.layer_norm.weight', 't5_model.encoder.block.20.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.20.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.20.layer.1.layer_norm.weight', 't5_model.encoder.block.21.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.21.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.21.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.21.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.21.layer.0.layer_norm.weight', 't5_model.encoder.block.21.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.21.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.21.layer.1.layer_norm.weight', 't5_model.encoder.block.22.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.22.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.22.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.22.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.22.layer.0.layer_norm.weight', 't5_model.encoder.block.22.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.22.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.22.layer.1.layer_norm.weight', 't5_model.encoder.block.23.layer.0.SelfAttention.q.weight', 't5_model.encoder.block.23.layer.0.SelfAttention.k.weight', 't5_model.encoder.block.23.layer.0.SelfAttention.v.weight', 't5_model.encoder.block.23.layer.0.SelfAttention.o.weight', 't5_model.encoder.block.23.layer.0.layer_norm.weight', 't5_model.encoder.block.23.layer.1.DenseReluDense.wi_0.weight', 't5_model.encoder.block.23.layer.1.DenseReluDense.wi_1.weight', 't5_model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 't5_model.encoder.block.23.layer.1.layer_norm.weight', 't5_model.encoder.final_layer_norm.weight', 't5_model.decoder.embed_tokens.weight', 't5_model.decoder.block.0.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.0.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.0.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.0.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 't5_model.decoder.block.0.layer.0.layer_norm.weight', 't5_model.decoder.block.0.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.0.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.0.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.0.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.0.layer.1.layer_norm.weight', 't5_model.decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.0.layer.2.layer_norm.weight', 't5_model.decoder.block.1.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.1.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.1.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.1.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.1.layer.0.layer_norm.weight', 't5_model.decoder.block.1.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.1.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.1.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.1.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.1.layer.1.layer_norm.weight', 't5_model.decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.1.layer.2.layer_norm.weight', 't5_model.decoder.block.2.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.2.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.2.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.2.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.2.layer.0.layer_norm.weight', 't5_model.decoder.block.2.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.2.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.2.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.2.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.2.layer.1.layer_norm.weight', 't5_model.decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.2.layer.2.layer_norm.weight', 't5_model.decoder.block.3.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.3.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.3.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.3.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.3.layer.0.layer_norm.weight', 't5_model.decoder.block.3.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.3.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.3.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.3.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.3.layer.1.layer_norm.weight', 't5_model.decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.3.layer.2.layer_norm.weight', 't5_model.decoder.block.4.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.4.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.4.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.4.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.4.layer.0.layer_norm.weight', 't5_model.decoder.block.4.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.4.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.4.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.4.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.4.layer.1.layer_norm.weight', 't5_model.decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.4.layer.2.layer_norm.weight', 't5_model.decoder.block.5.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.5.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.5.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.5.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.5.layer.0.layer_norm.weight', 't5_model.decoder.block.5.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.5.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.5.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.5.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.5.layer.1.layer_norm.weight', 't5_model.decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.5.layer.2.layer_norm.weight', 't5_model.decoder.block.6.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.6.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.6.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.6.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.6.layer.0.layer_norm.weight', 't5_model.decoder.block.6.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.6.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.6.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.6.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.6.layer.1.layer_norm.weight', 't5_model.decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.6.layer.2.layer_norm.weight', 't5_model.decoder.block.7.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.7.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.7.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.7.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.7.layer.0.layer_norm.weight', 't5_model.decoder.block.7.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.7.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.7.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.7.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.7.layer.1.layer_norm.weight', 't5_model.decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.7.layer.2.layer_norm.weight', 't5_model.decoder.block.8.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.8.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.8.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.8.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.8.layer.0.layer_norm.weight', 't5_model.decoder.block.8.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.8.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.8.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.8.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.8.layer.1.layer_norm.weight', 't5_model.decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.8.layer.2.layer_norm.weight', 't5_model.decoder.block.9.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.9.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.9.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.9.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.9.layer.0.layer_norm.weight', 't5_model.decoder.block.9.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.9.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.9.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.9.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.9.layer.1.layer_norm.weight', 't5_model.decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.9.layer.2.layer_norm.weight', 't5_model.decoder.block.10.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.10.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.10.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.10.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.10.layer.0.layer_norm.weight', 't5_model.decoder.block.10.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.10.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.10.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.10.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.10.layer.1.layer_norm.weight', 't5_model.decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.10.layer.2.layer_norm.weight', 't5_model.decoder.block.11.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.11.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.11.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.11.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.11.layer.0.layer_norm.weight', 't5_model.decoder.block.11.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.11.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.11.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.11.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.11.layer.1.layer_norm.weight', 't5_model.decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.11.layer.2.layer_norm.weight', 't5_model.decoder.block.12.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.12.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.12.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.12.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.12.layer.0.layer_norm.weight', 't5_model.decoder.block.12.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.12.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.12.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.12.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.12.layer.1.layer_norm.weight', 't5_model.decoder.block.12.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.12.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.12.layer.2.layer_norm.weight', 't5_model.decoder.block.13.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.13.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.13.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.13.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.13.layer.0.layer_norm.weight', 't5_model.decoder.block.13.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.13.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.13.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.13.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.13.layer.1.layer_norm.weight', 't5_model.decoder.block.13.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.13.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.13.layer.2.layer_norm.weight', 't5_model.decoder.block.14.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.14.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.14.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.14.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.14.layer.0.layer_norm.weight', 't5_model.decoder.block.14.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.14.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.14.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.14.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.14.layer.1.layer_norm.weight', 't5_model.decoder.block.14.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.14.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.14.layer.2.layer_norm.weight', 't5_model.decoder.block.15.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.15.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.15.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.15.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.15.layer.0.layer_norm.weight', 't5_model.decoder.block.15.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.15.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.15.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.15.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.15.layer.1.layer_norm.weight', 't5_model.decoder.block.15.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.15.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.15.layer.2.layer_norm.weight', 't5_model.decoder.block.16.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.16.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.16.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.16.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.16.layer.0.layer_norm.weight', 't5_model.decoder.block.16.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.16.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.16.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.16.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.16.layer.1.layer_norm.weight', 't5_model.decoder.block.16.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.16.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.16.layer.2.layer_norm.weight', 't5_model.decoder.block.17.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.17.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.17.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.17.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.17.layer.0.layer_norm.weight', 't5_model.decoder.block.17.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.17.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.17.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.17.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.17.layer.1.layer_norm.weight', 't5_model.decoder.block.17.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.17.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.17.layer.2.layer_norm.weight', 't5_model.decoder.block.18.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.18.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.18.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.18.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.18.layer.0.layer_norm.weight', 't5_model.decoder.block.18.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.18.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.18.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.18.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.18.layer.1.layer_norm.weight', 't5_model.decoder.block.18.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.18.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.18.layer.2.layer_norm.weight', 't5_model.decoder.block.19.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.19.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.19.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.19.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.19.layer.0.layer_norm.weight', 't5_model.decoder.block.19.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.19.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.19.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.19.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.19.layer.1.layer_norm.weight', 't5_model.decoder.block.19.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.19.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.19.layer.2.layer_norm.weight', 't5_model.decoder.block.20.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.20.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.20.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.20.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.20.layer.0.layer_norm.weight', 't5_model.decoder.block.20.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.20.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.20.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.20.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.20.layer.1.layer_norm.weight', 't5_model.decoder.block.20.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.20.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.20.layer.2.layer_norm.weight', 't5_model.decoder.block.21.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.21.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.21.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.21.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.21.layer.0.layer_norm.weight', 't5_model.decoder.block.21.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.21.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.21.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.21.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.21.layer.1.layer_norm.weight', 't5_model.decoder.block.21.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.21.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.21.layer.2.layer_norm.weight', 't5_model.decoder.block.22.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.22.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.22.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.22.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.22.layer.0.layer_norm.weight', 't5_model.decoder.block.22.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.22.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.22.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.22.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.22.layer.1.layer_norm.weight', 't5_model.decoder.block.22.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.22.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.22.layer.2.layer_norm.weight', 't5_model.decoder.block.23.layer.0.SelfAttention.q.weight', 't5_model.decoder.block.23.layer.0.SelfAttention.k.weight', 't5_model.decoder.block.23.layer.0.SelfAttention.v.weight', 't5_model.decoder.block.23.layer.0.SelfAttention.o.weight', 't5_model.decoder.block.23.layer.0.layer_norm.weight', 't5_model.decoder.block.23.layer.1.EncDecAttention.q.weight', 't5_model.decoder.block.23.layer.1.EncDecAttention.k.weight', 't5_model.decoder.block.23.layer.1.EncDecAttention.v.weight', 't5_model.decoder.block.23.layer.1.EncDecAttention.o.weight', 't5_model.decoder.block.23.layer.1.layer_norm.weight', 't5_model.decoder.block.23.layer.2.DenseReluDense.wi_0.weight', 't5_model.decoder.block.23.layer.2.DenseReluDense.wi_1.weight', 't5_model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 't5_model.decoder.block.23.layer.2.layer_norm.weight', 't5_model.decoder.final_layer_norm.weight', 't5_model.lm_head.weight']
2023-10-29 22:07:48,826 [INFO] load checkpoint from sevila_checkpoints/sevila_pretrained.pth
2023-10-29 22:07:48,835 [INFO] Start training
2023-10-29 22:07:57,129 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-10-29 22:07:57,129 [INFO] Loaded 34132 records for train split from the dataset.
2023-10-29 22:07:57,129 [INFO] Loaded 4996 records for val split from the dataset.
2023-10-29 22:07:57,129 [INFO] Loaded 4996 records for test split from the dataset.
2023-10-29 22:07:57,155 [INFO] number of trainable parameters: 108317696
2023-10-29 22:07:57,156 [INFO] Start training epoch 0, 2133 iters per inner epoch.
2023-10-29 22:08:21,209 [INFO] Train: data epoch: [0]  [   0/2133]  eta: 14:15:00  lr: 0.000000  loss: 0.4314  data_time: 8.1165  time: 24.0509  max mem: 32485
2023-10-29 22:09:14,784 [INFO] Train: data epoch: [0]  [  50/2133]  eta: 0:52:50  lr: 0.000003  loss: 0.3323  data_time: 0.0051  time: 1.0615  max mem: 34972
2023-10-29 22:10:08,397 [INFO] Train: data epoch: [0]  [ 100/2133]  eta: 0:44:01  lr: 0.000006  loss: 0.3310  data_time: 0.0047  time: 1.0780  max mem: 34972
2023-10-29 22:11:10,408 [INFO] Train: data epoch: [0]  [ 150/2133]  eta: 0:42:17  lr: 0.000009  loss: 0.3805  data_time: 0.0068  time: 1.4781  max mem: 34972
2023-10-29 22:12:04,449 [INFO] Train: data epoch: [0]  [ 200/2133]  eta: 0:39:38  lr: 0.000012  loss: 0.3543  data_time: 0.0053  time: 1.0822  max mem: 34972
2023-10-29 22:13:02,777 [INFO] Train: data epoch: [0]  [ 250/2133]  eta: 0:38:12  lr: 0.000015  loss: 0.3289  data_time: 0.0054  time: 1.2996  max mem: 34972
2023-10-29 22:13:56,924 [INFO] Train: data epoch: [0]  [ 300/2133]  eta: 0:36:30  lr: 0.000018  loss: 0.3006  data_time: 0.0047  time: 1.0866  max mem: 34972
2023-10-29 22:14:50,994 [INFO] Train: data epoch: [0]  [ 350/2133]  eta: 0:35:02  lr: 0.000021  loss: 0.3054  data_time: 0.0054  time: 1.0776  max mem: 34972
2023-10-29 22:15:45,570 [INFO] Train: data epoch: [0]  [ 400/2133]  eta: 0:33:44  lr: 0.000024  loss: 0.3089  data_time: 0.0050  time: 1.0809  max mem: 34972
2023-10-29 22:16:40,406 [INFO] Train: data epoch: [0]  [ 450/2133]  eta: 0:32:32  lr: 0.000027  loss: 0.3187  data_time: 0.0052  time: 1.0850  max mem: 34972
2023-10-29 22:17:35,027 [INFO] Train: data epoch: [0]  [ 500/2133]  eta: 0:31:23  lr: 0.000030  loss: 0.3350  data_time: 0.0054  time: 1.0850  max mem: 34972
2023-10-29 22:18:29,199 [INFO] Train: data epoch: [0]  [ 550/2133]  eta: 0:30:15  lr: 0.000030  loss: 0.3466  data_time: 0.0047  time: 1.0789  max mem: 34972
2023-10-29 22:19:28,296 [INFO] Train: data epoch: [0]  [ 600/2133]  eta: 0:29:22  lr: 0.000030  loss: 0.3433  data_time: 0.0052  time: 1.0708  max mem: 34972
2023-10-29 22:20:22,459 [INFO] Train: data epoch: [0]  [ 650/2133]  eta: 0:28:17  lr: 0.000030  loss: 0.3395  data_time: 0.0043  time: 1.0782  max mem: 34972
2023-10-29 22:21:19,470 [INFO] Train: data epoch: [0]  [ 700/2133]  eta: 0:27:19  lr: 0.000030  loss: 0.3249  data_time: 0.0044  time: 1.0831  max mem: 34972
2023-10-29 22:22:15,428 [INFO] Train: data epoch: [0]  [ 750/2133]  eta: 0:26:20  lr: 0.000030  loss: 0.3827  data_time: 0.0088  time: 1.1080  max mem: 34972
2023-10-29 22:23:09,631 [INFO] Train: data epoch: [0]  [ 800/2133]  eta: 0:25:18  lr: 0.000030  loss: 0.3915  data_time: 0.0046  time: 1.0965  max mem: 34972
2023-10-29 22:24:03,960 [INFO] Train: data epoch: [0]  [ 850/2133]  eta: 0:24:17  lr: 0.000030  loss: 0.3181  data_time: 0.0058  time: 1.0902  max mem: 34972
2023-10-29 22:24:58,139 [INFO] Train: data epoch: [0]  [ 900/2133]  eta: 0:23:17  lr: 0.000030  loss: 0.3454  data_time: 0.0054  time: 1.0871  max mem: 34972
2023-10-29 22:25:54,893 [INFO] Train: data epoch: [0]  [ 950/2133]  eta: 0:22:20  lr: 0.000030  loss: 0.3238  data_time: 0.0046  time: 1.2113  max mem: 34972
2023-10-29 22:26:48,957 [INFO] Train: data epoch: [0]  [1000/2133]  eta: 0:21:20  lr: 0.000030  loss: 0.3191  data_time: 0.0050  time: 1.0778  max mem: 34972
2023-10-29 22:27:51,514 [INFO] Train: data epoch: [0]  [1050/2133]  eta: 0:20:30  lr: 0.000030  loss: 0.3149  data_time: 0.0053  time: 1.0724  max mem: 34972
2023-10-29 22:28:45,423 [INFO] Train: data epoch: [0]  [1100/2133]  eta: 0:19:31  lr: 0.000030  loss: 0.3055  data_time: 0.0043  time: 1.0728  max mem: 34972
2023-10-29 22:29:51,118 [INFO] Train: data epoch: [0]  [1150/2133]  eta: 0:18:42  lr: 0.000030  loss: 0.3383  data_time: 0.0046  time: 1.0738  max mem: 34972
2023-10-29 22:30:45,924 [INFO] Train: data epoch: [0]  [1200/2133]  eta: 0:17:43  lr: 0.000030  loss: 0.2949  data_time: 0.0043  time: 1.0783  max mem: 34972
2023-10-29 22:31:42,915 [INFO] Train: data epoch: [0]  [1250/2133]  eta: 0:16:46  lr: 0.000030  loss: 0.3007  data_time: 0.0050  time: 1.0754  max mem: 34972
2023-10-29 22:32:36,944 [INFO] Train: data epoch: [0]  [1300/2133]  eta: 0:15:47  lr: 0.000030  loss: 0.3238  data_time: 0.0055  time: 1.0781  max mem: 34972
2023-10-29 22:33:31,063 [INFO] Train: data epoch: [0]  [1350/2133]  eta: 0:14:48  lr: 0.000030  loss: 0.3562  data_time: 0.0054  time: 1.0797  max mem: 34972
2023-10-29 22:34:25,483 [INFO] Train: data epoch: [0]  [1400/2133]  eta: 0:13:50  lr: 0.000030  loss: 0.3087  data_time: 0.0052  time: 1.0936  max mem: 34972
2023-10-29 22:35:19,512 [INFO] Train: data epoch: [0]  [1450/2133]  eta: 0:12:53  lr: 0.000030  loss: 0.3023  data_time: 0.0052  time: 1.0794  max mem: 34972
2023-10-29 22:36:13,456 [INFO] Train: data epoch: [0]  [1500/2133]  eta: 0:11:55  lr: 0.000030  loss: 0.3530  data_time: 0.0051  time: 1.0789  max mem: 34972
2023-10-29 22:37:07,425 [INFO] Train: data epoch: [0]  [1550/2133]  eta: 0:10:57  lr: 0.000030  loss: 0.3814  data_time: 0.0056  time: 1.0829  max mem: 34972
2023-10-29 22:38:01,584 [INFO] Train: data epoch: [0]  [1600/2133]  eta: 0:10:00  lr: 0.000030  loss: 0.3756  data_time: 0.0046  time: 1.0828  max mem: 34972
2023-10-29 22:38:55,618 [INFO] Train: data epoch: [0]  [1650/2133]  eta: 0:09:03  lr: 0.000030  loss: 0.3292  data_time: 0.0052  time: 1.0805  max mem: 34972
2023-10-29 22:39:49,609 [INFO] Train: data epoch: [0]  [1700/2133]  eta: 0:08:06  lr: 0.000030  loss: 0.3517  data_time: 0.0044  time: 1.0806  max mem: 34972
2023-10-29 22:40:43,521 [INFO] Train: data epoch: [0]  [1750/2133]  eta: 0:07:10  lr: 0.000030  loss: 0.3501  data_time: 0.0048  time: 1.0800  max mem: 34972
2023-10-29 22:41:37,607 [INFO] Train: data epoch: [0]  [1800/2133]  eta: 0:06:13  lr: 0.000030  loss: 0.3169  data_time: 0.0046  time: 1.0762  max mem: 34972
2023-10-29 22:42:32,134 [INFO] Train: data epoch: [0]  [1850/2133]  eta: 0:05:17  lr: 0.000030  loss: 0.3877  data_time: 0.0057  time: 1.0962  max mem: 34972
2023-10-29 22:43:26,163 [INFO] Train: data epoch: [0]  [1900/2133]  eta: 0:04:20  lr: 0.000030  loss: 0.3099  data_time: 0.0051  time: 1.0839  max mem: 34972
2023-10-29 22:44:20,522 [INFO] Train: data epoch: [0]  [1950/2133]  eta: 0:03:24  lr: 0.000030  loss: 0.3206  data_time: 0.0054  time: 1.0928  max mem: 34972
2023-10-29 22:45:14,673 [INFO] Train: data epoch: [0]  [2000/2133]  eta: 0:02:28  lr: 0.000030  loss: 0.3411  data_time: 0.0052  time: 1.0803  max mem: 34972
2023-10-29 22:46:08,733 [INFO] Train: data epoch: [0]  [2050/2133]  eta: 0:01:32  lr: 0.000030  loss: 0.3157  data_time: 0.0047  time: 1.0837  max mem: 34972
2023-10-29 22:47:02,859 [INFO] Train: data epoch: [0]  [2100/2133]  eta: 0:00:36  lr: 0.000030  loss: 0.2778  data_time: 0.0045  time: 1.0828  max mem: 34972
2023-10-29 22:47:37,522 [INFO] Train: data epoch: [0]  [2132/2133]  eta: 0:00:01  lr: 0.000030  loss: 0.3312  data_time: 0.0238  time: 1.0854  max mem: 34972
2023-10-29 22:47:37,535 [INFO] Averaged stats: lr: 0.0000  loss: 0.3368  data_time: 0.0092
2023-10-29 22:47:37,546 [INFO] Evaluating on val.
2023-10-29 22:48:05,750 [INFO] Evaluation  [  0/625]  eta: 4:53:31    time: 28.1783  max mem: 34972
2023-10-29 22:48:37,271 [INFO] Evaluation  [ 10/625]  eta: 0:55:37    time: 5.4271  max mem: 34972
2023-10-29 22:49:05,078 [INFO] Evaluation  [ 20/625]  eta: 0:42:00    time: 2.9663  max mem: 34972
2023-10-29 22:49:31,122 [INFO] Evaluation  [ 30/625]  eta: 0:36:19    time: 2.6924  max mem: 34972
2023-10-29 22:49:57,922 [INFO] Evaluation  [ 40/625]  eta: 0:33:22    time: 2.6420  max mem: 34972
2023-10-29 22:50:23,915 [INFO] Evaluation  [ 50/625]  eta: 0:31:15    time: 2.6395  max mem: 34972
2023-10-29 22:50:50,032 [INFO] Evaluation  [ 60/625]  eta: 0:29:42    time: 2.6054  max mem: 34972
2023-10-29 22:51:16,263 [INFO] Evaluation  [ 70/625]  eta: 0:28:29    time: 2.6173  max mem: 34972
2023-10-29 22:51:42,361 [INFO] Evaluation  [ 80/625]  eta: 0:27:26    time: 2.6163  max mem: 34972
2023-10-29 22:52:09,349 [INFO] Evaluation  [ 90/625]  eta: 0:26:37    time: 2.6539  max mem: 34972
2023-10-29 22:52:35,326 [INFO] Evaluation  [100/625]  eta: 0:25:47    time: 2.6478  max mem: 34972
2023-10-29 22:53:02,019 [INFO] Evaluation  [110/625]  eta: 0:25:05    time: 2.6334  max mem: 34972
2023-10-29 22:53:28,133 [INFO] Evaluation  [120/625]  eta: 0:24:22    time: 2.6402  max mem: 34972
2023-10-29 22:53:53,935 [INFO] Evaluation  [130/625]  eta: 0:23:42    time: 2.5956  max mem: 34972
2023-10-29 22:54:19,636 [INFO] Evaluation  [140/625]  eta: 0:23:02    time: 2.5750  max mem: 34972
2023-10-29 22:54:45,646 [INFO] Evaluation  [150/625]  eta: 0:22:26    time: 2.5854  max mem: 34972
2023-10-29 22:55:11,721 [INFO] Evaluation  [160/625]  eta: 0:21:51    time: 2.6041  max mem: 34972
2023-10-29 22:55:37,555 [INFO] Evaluation  [170/625]  eta: 0:21:17    time: 2.5953  max mem: 34972
2023-10-29 22:56:03,809 [INFO] Evaluation  [180/625]  eta: 0:20:44    time: 2.6042  max mem: 34972
2023-10-29 22:56:29,714 [INFO] Evaluation  [190/625]  eta: 0:20:11    time: 2.6078  max mem: 34972
2023-10-29 22:56:55,716 [INFO] Evaluation  [200/625]  eta: 0:19:40    time: 2.5952  max mem: 34972
2023-10-29 22:57:21,560 [INFO] Evaluation  [210/625]  eta: 0:19:08    time: 2.5922  max mem: 34972
2023-10-29 22:57:47,876 [INFO] Evaluation  [220/625]  eta: 0:18:38    time: 2.6078  max mem: 34972
2023-10-29 22:58:14,327 [INFO] Evaluation  [230/625]  eta: 0:18:08    time: 2.6381  max mem: 34972
2023-10-29 22:58:40,503 [INFO] Evaluation  [240/625]  eta: 0:17:38    time: 2.6311  max mem: 34972
2023-10-29 22:59:06,675 [INFO] Evaluation  [250/625]  eta: 0:17:09    time: 2.6172  max mem: 34972
2023-10-29 22:59:32,860 [INFO] Evaluation  [260/625]  eta: 0:16:40    time: 2.6177  max mem: 34972
2023-10-29 22:59:58,858 [INFO] Evaluation  [270/625]  eta: 0:16:10    time: 2.6090  max mem: 34972
2023-10-29 23:00:24,794 [INFO] Evaluation  [280/625]  eta: 0:15:41    time: 2.5966  max mem: 34972
2023-10-29 23:00:51,015 [INFO] Evaluation  [290/625]  eta: 0:15:13    time: 2.6077  max mem: 34972
2023-10-29 23:01:16,940 [INFO] Evaluation  [300/625]  eta: 0:14:44    time: 2.6071  max mem: 34972
2023-10-29 23:01:43,361 [INFO] Evaluation  [310/625]  eta: 0:14:16    time: 2.6170  max mem: 34972
2023-10-29 23:02:09,409 [INFO] Evaluation  [320/625]  eta: 0:13:48    time: 2.6232  max mem: 34972
2023-10-29 23:02:35,594 [INFO] Evaluation  [330/625]  eta: 0:13:20    time: 2.6113  max mem: 34972
2023-10-29 23:03:01,638 [INFO] Evaluation  [340/625]  eta: 0:12:52    time: 2.6111  max mem: 34972
2023-10-29 23:03:27,732 [INFO] Evaluation  [350/625]  eta: 0:12:24    time: 2.6068  max mem: 34972
2023-10-29 23:03:53,752 [INFO] Evaluation  [360/625]  eta: 0:11:56    time: 2.6055  max mem: 34972
2023-10-29 23:04:19,873 [INFO] Evaluation  [370/625]  eta: 0:11:28    time: 2.6069  max mem: 34972
2023-10-29 23:04:45,713 [INFO] Evaluation  [380/625]  eta: 0:11:01    time: 2.5979  max mem: 34972
2023-10-29 23:05:11,810 [INFO] Evaluation  [390/625]  eta: 0:10:33    time: 2.5964  max mem: 34972
2023-10-29 23:05:37,752 [INFO] Evaluation  [400/625]  eta: 0:10:06    time: 2.6013  max mem: 34972
2023-10-29 23:06:03,691 [INFO] Evaluation  [410/625]  eta: 0:09:38    time: 2.5935  max mem: 34972
2023-10-29 23:06:29,978 [INFO] Evaluation  [420/625]  eta: 0:09:11    time: 2.6111  max mem: 34972
2023-10-29 23:06:55,794 [INFO] Evaluation  [430/625]  eta: 0:08:43    time: 2.6050  max mem: 34972
2023-10-29 23:07:22,246 [INFO] Evaluation  [440/625]  eta: 0:08:16    time: 2.6132  max mem: 34972
2023-10-29 23:07:48,211 [INFO] Evaluation  [450/625]  eta: 0:07:49    time: 2.6206  max mem: 34972
2023-10-29 23:08:14,173 [INFO] Evaluation  [460/625]  eta: 0:07:22    time: 2.5962  max mem: 34972
2023-10-29 23:08:39,908 [INFO] Evaluation  [470/625]  eta: 0:06:55    time: 2.5847  max mem: 34972
2023-10-29 23:09:05,787 [INFO] Evaluation  [480/625]  eta: 0:06:28    time: 2.5805  max mem: 34972
2023-10-29 23:09:31,956 [INFO] Evaluation  [490/625]  eta: 0:06:01    time: 2.6022  max mem: 34972
2023-10-29 23:09:58,376 [INFO] Evaluation  [500/625]  eta: 0:05:34    time: 2.6293  max mem: 34972
2023-10-29 23:10:24,218 [INFO] Evaluation  [510/625]  eta: 0:05:07    time: 2.6129  max mem: 34972
2023-10-29 23:10:50,729 [INFO] Evaluation  [520/625]  eta: 0:04:40    time: 2.6175  max mem: 34972
2023-10-29 23:11:16,453 [INFO] Evaluation  [530/625]  eta: 0:04:13    time: 2.6114  max mem: 34972
2023-10-29 23:11:44,132 [INFO] Evaluation  [540/625]  eta: 0:03:47    time: 2.6697  max mem: 34972
2023-10-29 23:12:10,734 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.7136  max mem: 34972
2023-10-29 23:12:36,895 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.6377  max mem: 34972
2023-10-29 23:13:03,041 [INFO] Evaluation  [570/625]  eta: 0:02:26    time: 2.6151  max mem: 34972
2023-10-29 23:13:28,946 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6024  max mem: 34972
2023-10-29 23:13:54,748 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5852  max mem: 34972
2023-10-29 23:14:20,834 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5941  max mem: 34972
2023-10-29 23:14:46,659 [INFO] Evaluation  [610/625]  eta: 0:00:39    time: 2.5952  max mem: 34972
2023-10-29 23:15:12,354 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5757  max mem: 34972
2023-10-29 23:15:21,777 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5317  max mem: 34972
2023-10-29 23:15:21,841 [WARNING] rank 0 starts merging results.
2023-10-29 23:15:21,894 [INFO] {'agg_metrics': 0.6371096877502002, 'total': 4996, 'CH': 62.95754026354319, 'CW': 61.278586278586275, 'TN': 56.53631284916201, 'TC': 67.11915535444946, 'DL': 87.11864406779661, 'DC': 52.54237288135594, 'DO': 76.39344262295083, 'TP': 74.07407407407408}
2023-10-29 23:15:21,936 [INFO] Saving checkpoint at epoch 0 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_best.pth.
2023-10-29 23:15:23,656 [INFO] Saving checkpoint at epoch 0 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_0.pth.
2023-10-29 23:15:25,270 [INFO] Start training
2023-10-29 23:15:25,307 [INFO] Start training epoch 1, 2133 iters per inner epoch.
2023-10-29 23:15:37,476 [INFO] Train: data epoch: [1]  [   0/2133]  eta: 7:12:33  lr: 0.000029  loss: 0.2730  data_time: 9.4379  time: 12.1677  max mem: 34972
2023-10-29 23:16:34,905 [INFO] Train: data epoch: [1]  [  50/2133]  eta: 0:47:22  lr: 0.000029  loss: 0.3064  data_time: 0.0052  time: 1.0852  max mem: 34987
2023-10-29 23:17:28,898 [INFO] Train: data epoch: [1]  [ 100/2133]  eta: 0:41:27  lr: 0.000029  loss: 0.3734  data_time: 0.0047  time: 1.0819  max mem: 34987
2023-10-29 23:18:28,257 [INFO] Train: data epoch: [1]  [ 150/2133]  eta: 0:40:02  lr: 0.000029  loss: 0.2903  data_time: 0.0044  time: 1.0775  max mem: 34987
2023-10-29 23:19:24,497 [INFO] Train: data epoch: [1]  [ 200/2133]  eta: 0:38:20  lr: 0.000029  loss: 0.3134  data_time: 0.0050  time: 1.0806  max mem: 34987
2023-10-29 23:20:19,968 [INFO] Train: data epoch: [1]  [ 250/2133]  eta: 0:36:50  lr: 0.000029  loss: 0.3285  data_time: 0.0047  time: 1.0872  max mem: 34987
2023-10-29 23:21:14,207 [INFO] Train: data epoch: [1]  [ 300/2133]  eta: 0:35:24  lr: 0.000029  loss: 0.3656  data_time: 0.0049  time: 1.0926  max mem: 34987
2023-10-29 23:22:08,534 [INFO] Train: data epoch: [1]  [ 350/2133]  eta: 0:34:08  lr: 0.000029  loss: 0.3339  data_time: 0.0051  time: 1.0919  max mem: 34987
2023-10-29 23:23:03,091 [INFO] Train: data epoch: [1]  [ 400/2133]  eta: 0:32:58  lr: 0.000029  loss: 0.3143  data_time: 0.0045  time: 1.1072  max mem: 34987
2023-10-29 23:23:57,075 [INFO] Train: data epoch: [1]  [ 450/2133]  eta: 0:31:49  lr: 0.000029  loss: 0.3634  data_time: 0.0051  time: 1.0809  max mem: 34987
2023-10-29 23:24:51,074 [INFO] Train: data epoch: [1]  [ 500/2133]  eta: 0:30:43  lr: 0.000029  loss: 0.3445  data_time: 0.0056  time: 1.0796  max mem: 34987
2023-10-29 23:25:49,148 [INFO] Train: data epoch: [1]  [ 550/2133]  eta: 0:29:52  lr: 0.000029  loss: 0.3590  data_time: 0.0052  time: 1.0742  max mem: 34987
2023-10-29 23:26:43,580 [INFO] Train: data epoch: [1]  [ 600/2133]  eta: 0:28:49  lr: 0.000029  loss: 0.3240  data_time: 0.0054  time: 1.0851  max mem: 34987
2023-10-29 23:27:40,221 [INFO] Train: data epoch: [1]  [ 650/2133]  eta: 0:27:54  lr: 0.000029  loss: 0.2689  data_time: 0.0051  time: 1.0804  max mem: 34987
2023-10-29 23:28:35,827 [INFO] Train: data epoch: [1]  [ 700/2133]  eta: 0:26:55  lr: 0.000029  loss: 0.3132  data_time: 0.0045  time: 1.0831  max mem: 34987
2023-10-29 23:29:30,070 [INFO] Train: data epoch: [1]  [ 750/2133]  eta: 0:25:55  lr: 0.000029  loss: 0.3053  data_time: 0.0047  time: 1.0834  max mem: 34987
2023-10-29 23:30:24,297 [INFO] Train: data epoch: [1]  [ 800/2133]  eta: 0:24:55  lr: 0.000029  loss: 0.3017  data_time: 0.0041  time: 1.0841  max mem: 34987
2023-10-29 23:31:18,580 [INFO] Train: data epoch: [1]  [ 850/2133]  eta: 0:23:57  lr: 0.000029  loss: 0.2886  data_time: 0.0053  time: 1.0887  max mem: 34987
2023-10-29 23:32:15,700 [INFO] Train: data epoch: [1]  [ 900/2133]  eta: 0:23:02  lr: 0.000029  loss: 0.3190  data_time: 0.0058  time: 1.2160  max mem: 34987
2023-10-29 23:33:15,992 [INFO] Train: data epoch: [1]  [ 950/2133]  eta: 0:22:11  lr: 0.000029  loss: 0.2695  data_time: 0.0071  time: 1.3978  max mem: 34987
2023-10-29 23:34:17,371 [INFO] Train: data epoch: [1]  [1000/2133]  eta: 0:21:21  lr: 0.000029  loss: 0.3120  data_time: 0.0078  time: 1.4411  max mem: 34987
2023-10-29 23:35:13,225 [INFO] Train: data epoch: [1]  [1050/2133]  eta: 0:20:23  lr: 0.000029  loss: 0.2568  data_time: 0.0055  time: 1.1753  max mem: 34987
2023-10-29 23:36:07,970 [INFO] Train: data epoch: [1]  [1100/2133]  eta: 0:19:25  lr: 0.000029  loss: 0.2846  data_time: 0.0053  time: 1.1118  max mem: 34987
2023-10-29 23:37:05,121 [INFO] Train: data epoch: [1]  [1150/2133]  eta: 0:18:30  lr: 0.000029  loss: 0.3093  data_time: 0.0055  time: 1.2291  max mem: 34987
2023-10-29 23:37:59,632 [INFO] Train: data epoch: [1]  [1200/2133]  eta: 0:17:32  lr: 0.000029  loss: 0.3333  data_time: 0.0052  time: 1.1031  max mem: 34987
2023-10-29 23:38:54,402 [INFO] Train: data epoch: [1]  [1250/2133]  eta: 0:16:34  lr: 0.000029  loss: 0.4066  data_time: 0.0045  time: 1.0966  max mem: 34987
2023-10-29 23:39:48,379 [INFO] Train: data epoch: [1]  [1300/2133]  eta: 0:15:36  lr: 0.000029  loss: 0.3120  data_time: 0.0053  time: 1.0765  max mem: 34987
2023-10-29 23:40:42,329 [INFO] Train: data epoch: [1]  [1350/2133]  eta: 0:14:39  lr: 0.000029  loss: 0.2563  data_time: 0.0043  time: 1.0762  max mem: 34987
2023-10-29 23:41:36,478 [INFO] Train: data epoch: [1]  [1400/2133]  eta: 0:13:41  lr: 0.000029  loss: 0.4675  data_time: 0.0040  time: 1.0834  max mem: 34987
2023-10-29 23:42:31,067 [INFO] Train: data epoch: [1]  [1450/2133]  eta: 0:12:45  lr: 0.000029  loss: 0.3587  data_time: 0.0046  time: 1.0862  max mem: 34987
2023-10-29 23:43:25,198 [INFO] Train: data epoch: [1]  [1500/2133]  eta: 0:11:48  lr: 0.000029  loss: 0.3368  data_time: 0.0050  time: 1.0898  max mem: 34987
2023-10-29 23:44:19,321 [INFO] Train: data epoch: [1]  [1550/2133]  eta: 0:10:51  lr: 0.000029  loss: 0.3077  data_time: 0.0052  time: 1.0834  max mem: 34987
2023-10-29 23:45:13,237 [INFO] Train: data epoch: [1]  [1600/2133]  eta: 0:09:55  lr: 0.000029  loss: 0.3767  data_time: 0.0048  time: 1.0779  max mem: 34987
2023-10-29 23:46:07,569 [INFO] Train: data epoch: [1]  [1650/2133]  eta: 0:08:58  lr: 0.000029  loss: 0.3427  data_time: 0.0043  time: 1.0893  max mem: 34987
2023-10-29 23:47:01,698 [INFO] Train: data epoch: [1]  [1700/2133]  eta: 0:08:02  lr: 0.000029  loss: 0.3462  data_time: 0.0052  time: 1.0826  max mem: 34987
2023-10-29 23:47:55,675 [INFO] Train: data epoch: [1]  [1750/2133]  eta: 0:07:06  lr: 0.000029  loss: 0.3096  data_time: 0.0052  time: 1.0789  max mem: 34987
2023-10-29 23:48:50,133 [INFO] Train: data epoch: [1]  [1800/2133]  eta: 0:06:10  lr: 0.000029  loss: 0.2857  data_time: 0.0050  time: 1.0825  max mem: 34987
2023-10-29 23:49:44,248 [INFO] Train: data epoch: [1]  [1850/2133]  eta: 0:05:14  lr: 0.000029  loss: 0.3505  data_time: 0.0051  time: 1.0801  max mem: 34987
2023-10-29 23:50:38,323 [INFO] Train: data epoch: [1]  [1900/2133]  eta: 0:04:18  lr: 0.000029  loss: 0.3732  data_time: 0.0043  time: 1.0784  max mem: 34987
2023-10-29 23:51:32,294 [INFO] Train: data epoch: [1]  [1950/2133]  eta: 0:03:23  lr: 0.000029  loss: 0.2539  data_time: 0.0047  time: 1.0813  max mem: 34987
2023-10-29 23:52:26,207 [INFO] Train: data epoch: [1]  [2000/2133]  eta: 0:02:27  lr: 0.000029  loss: 0.3311  data_time: 0.0049  time: 1.0836  max mem: 34987
2023-10-29 23:53:21,864 [INFO] Train: data epoch: [1]  [2050/2133]  eta: 0:01:32  lr: 0.000029  loss: 0.2869  data_time: 0.0046  time: 1.0871  max mem: 34987
2023-10-29 23:54:16,569 [INFO] Train: data epoch: [1]  [2100/2133]  eta: 0:00:36  lr: 0.000029  loss: 0.2681  data_time: 0.0053  time: 1.0904  max mem: 34987
2023-10-29 23:54:51,551 [INFO] Train: data epoch: [1]  [2132/2133]  eta: 0:00:01  lr: 0.000029  loss: 0.3228  data_time: 0.0219  time: 1.0934  max mem: 34987
2023-10-29 23:54:51,563 [INFO] Averaged stats: lr: 0.0000  loss: 0.3227  data_time: 0.0096
2023-10-29 23:54:51,572 [INFO] Evaluating on val.
2023-10-29 23:55:16,355 [INFO] Evaluation  [  0/625]  eta: 4:17:52    time: 24.7556  max mem: 34987
2023-10-29 23:55:48,062 [INFO] Evaluation  [ 10/625]  eta: 0:52:36    time: 5.1327  max mem: 34987
2023-10-29 23:56:14,838 [INFO] Evaluation  [ 20/625]  eta: 0:39:57    time: 2.9238  max mem: 34987
2023-10-29 23:56:40,932 [INFO] Evaluation  [ 30/625]  eta: 0:34:58    time: 2.6432  max mem: 34987
2023-10-29 23:57:07,261 [INFO] Evaluation  [ 40/625]  eta: 0:32:15    time: 2.6210  max mem: 34987
2023-10-29 23:57:33,378 [INFO] Evaluation  [ 50/625]  eta: 0:30:23    time: 2.6221  max mem: 34987
2023-10-29 23:57:59,532 [INFO] Evaluation  [ 60/625]  eta: 0:29:00    time: 2.6134  max mem: 34987
2023-10-29 23:58:25,734 [INFO] Evaluation  [ 70/625]  eta: 0:27:53    time: 2.6176  max mem: 34987
2023-10-29 23:58:51,993 [INFO] Evaluation  [ 80/625]  eta: 0:26:57    time: 2.6228  max mem: 34987
2023-10-29 23:59:18,221 [INFO] Evaluation  [ 90/625]  eta: 0:26:07    time: 2.6241  max mem: 34987
2023-10-29 23:59:44,285 [INFO] Evaluation  [100/625]  eta: 0:25:21    time: 2.6144  max mem: 34987
2023-10-30 00:00:10,485 [INFO] Evaluation  [110/625]  eta: 0:24:39    time: 2.6130  max mem: 34987
2023-10-30 00:00:36,484 [INFO] Evaluation  [120/625]  eta: 0:23:59    time: 2.6097  max mem: 34987
2023-10-30 00:01:02,341 [INFO] Evaluation  [130/625]  eta: 0:23:20    time: 2.5926  max mem: 34987
2023-10-30 00:01:28,017 [INFO] Evaluation  [140/625]  eta: 0:22:43    time: 2.5764  max mem: 34987
2023-10-30 00:01:54,050 [INFO] Evaluation  [150/625]  eta: 0:22:08    time: 2.5852  max mem: 34987
2023-10-30 00:02:20,323 [INFO] Evaluation  [160/625]  eta: 0:21:35    time: 2.6149  max mem: 34987
2023-10-30 00:02:46,199 [INFO] Evaluation  [170/625]  eta: 0:21:02    time: 2.6070  max mem: 34987
2023-10-30 00:03:13,158 [INFO] Evaluation  [180/625]  eta: 0:20:32    time: 2.6414  max mem: 34987
2023-10-30 00:03:39,273 [INFO] Evaluation  [190/625]  eta: 0:20:01    time: 2.6534  max mem: 34987
2023-10-30 00:04:05,490 [INFO] Evaluation  [200/625]  eta: 0:19:31    time: 2.6164  max mem: 34987
2023-10-30 00:04:31,424 [INFO] Evaluation  [210/625]  eta: 0:19:00    time: 2.6074  max mem: 34987
2023-10-30 00:04:58,414 [INFO] Evaluation  [220/625]  eta: 0:18:31    time: 2.6460  max mem: 34987
2023-10-30 00:05:24,670 [INFO] Evaluation  [230/625]  eta: 0:18:02    time: 2.6620  max mem: 34987
2023-10-30 00:05:50,718 [INFO] Evaluation  [240/625]  eta: 0:17:32    time: 2.6149  max mem: 34987
2023-10-30 00:06:16,774 [INFO] Evaluation  [250/625]  eta: 0:17:03    time: 2.6050  max mem: 34987
2023-10-30 00:06:42,975 [INFO] Evaluation  [260/625]  eta: 0:16:34    time: 2.6127  max mem: 34987
2023-10-30 00:07:08,951 [INFO] Evaluation  [270/625]  eta: 0:16:05    time: 2.6085  max mem: 34987
2023-10-30 00:07:34,758 [INFO] Evaluation  [280/625]  eta: 0:15:36    time: 2.5885  max mem: 34987
2023-10-30 00:08:01,346 [INFO] Evaluation  [290/625]  eta: 0:15:09    time: 2.6192  max mem: 34987
2023-10-30 00:08:27,146 [INFO] Evaluation  [300/625]  eta: 0:14:40    time: 2.6192  max mem: 34987
2023-10-30 00:08:53,657 [INFO] Evaluation  [310/625]  eta: 0:14:12    time: 2.6148  max mem: 34987
2023-10-30 00:09:19,668 [INFO] Evaluation  [320/625]  eta: 0:13:44    time: 2.6249  max mem: 34987
2023-10-30 00:09:45,769 [INFO] Evaluation  [330/625]  eta: 0:13:16    time: 2.6050  max mem: 34987
2023-10-30 00:10:11,825 [INFO] Evaluation  [340/625]  eta: 0:12:49    time: 2.6073  max mem: 34987
2023-10-30 00:10:37,896 [INFO] Evaluation  [350/625]  eta: 0:12:21    time: 2.6056  max mem: 34987
2023-10-30 00:11:04,703 [INFO] Evaluation  [360/625]  eta: 0:11:54    time: 2.6434  max mem: 34987
2023-10-30 00:11:31,137 [INFO] Evaluation  [370/625]  eta: 0:11:26    time: 2.6615  max mem: 34987
2023-10-30 00:12:09,283 [INFO] Evaluation  [380/625]  eta: 0:11:07    time: 3.2278  max mem: 34987
2023-10-30 00:12:35,902 [INFO] Evaluation  [390/625]  eta: 0:10:39    time: 3.2371  max mem: 34987
2023-10-30 00:13:04,796 [INFO] Evaluation  [400/625]  eta: 0:10:13    time: 2.7751  max mem: 34987
2023-10-30 00:13:30,427 [INFO] Evaluation  [410/625]  eta: 0:09:45    time: 2.7258  max mem: 34987
2023-10-30 00:13:57,010 [INFO] Evaluation  [420/625]  eta: 0:09:17    time: 2.6105  max mem: 34987
2023-10-30 00:14:22,938 [INFO] Evaluation  [430/625]  eta: 0:08:49    time: 2.6253  max mem: 34987
2023-10-30 00:14:49,173 [INFO] Evaluation  [440/625]  eta: 0:08:22    time: 2.6079  max mem: 34987
2023-10-30 00:15:16,190 [INFO] Evaluation  [450/625]  eta: 0:07:55    time: 2.6621  max mem: 34987
2023-10-30 00:15:41,914 [INFO] Evaluation  [460/625]  eta: 0:07:27    time: 2.6365  max mem: 34987
2023-10-30 00:16:15,094 [INFO] Evaluation  [470/625]  eta: 0:07:02    time: 2.9447  max mem: 34987
2023-10-30 00:16:40,947 [INFO] Evaluation  [480/625]  eta: 0:06:34    time: 2.9511  max mem: 34987
2023-10-30 00:17:15,153 [INFO] Evaluation  [490/625]  eta: 0:06:09    time: 3.0026  max mem: 34987
2023-10-30 00:17:41,194 [INFO] Evaluation  [500/625]  eta: 0:05:41    time: 3.0121  max mem: 34987
2023-10-30 00:18:08,087 [INFO] Evaluation  [510/625]  eta: 0:05:14    time: 2.6465  max mem: 34987
2023-10-30 00:18:34,311 [INFO] Evaluation  [520/625]  eta: 0:04:46    time: 2.6557  max mem: 34987
2023-10-30 00:19:00,018 [INFO] Evaluation  [530/625]  eta: 0:04:19    time: 2.5964  max mem: 34987
2023-10-30 00:19:26,887 [INFO] Evaluation  [540/625]  eta: 0:03:51    time: 2.6286  max mem: 34987
2023-10-30 00:19:58,157 [INFO] Evaluation  [550/625]  eta: 0:03:25    time: 2.9029  max mem: 34987
2023-10-30 00:20:25,589 [INFO] Evaluation  [560/625]  eta: 0:02:57    time: 2.9296  max mem: 34987
2023-10-30 00:20:51,631 [INFO] Evaluation  [570/625]  eta: 0:02:30    time: 2.6721  max mem: 34987
2023-10-30 00:21:27,910 [INFO] Evaluation  [580/625]  eta: 0:02:03    time: 3.1157  max mem: 34987
2023-10-30 00:22:07,655 [INFO] Evaluation  [590/625]  eta: 0:01:36    time: 3.7939  max mem: 34987
2023-10-30 00:22:34,971 [INFO] Evaluation  [600/625]  eta: 0:01:09    time: 3.3430  max mem: 34987
2023-10-30 00:23:04,613 [INFO] Evaluation  [610/625]  eta: 0:00:41    time: 2.8436  max mem: 34987
2023-10-30 00:23:30,119 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.7560  max mem: 34987
2023-10-30 00:23:39,811 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.7286  max mem: 34987
2023-10-30 00:23:39,930 [WARNING] rank 0 starts merging results.
2023-10-30 00:23:39,988 [INFO] {'agg_metrics': 0.6417133706965572, 'total': 4996, 'CH': 63.103953147877014, 'CW': 62.474012474012476, 'TN': 56.53631284916201, 'TC': 67.42081447963801, 'DL': 86.4406779661017, 'DC': 51.9774011299435, 'DO': 76.72131147540983, 'TP': 72.22222222222221}
2023-10-30 00:23:40,051 [INFO] Saving checkpoint at epoch 1 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_best.pth.
2023-10-30 00:23:45,730 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_0.pth.
2023-10-30 00:23:45,765 [INFO] Saving checkpoint at epoch 1 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_1.pth.
2023-10-30 00:23:47,539 [INFO] Start training
2023-10-30 00:23:47,576 [INFO] Start training epoch 2, 2133 iters per inner epoch.
2023-10-30 00:24:03,330 [INFO] Train: data epoch: [2]  [   0/2133]  eta: 9:19:57  lr: 0.000027  loss: 0.2858  data_time: 12.8810  time: 15.7513  max mem: 34987
2023-10-30 00:24:59,925 [INFO] Train: data epoch: [2]  [  50/2133]  eta: 0:49:14  lr: 0.000027  loss: 0.2750  data_time: 0.0049  time: 1.1138  max mem: 34987
2023-10-30 00:25:54,801 [INFO] Train: data epoch: [2]  [ 100/2133]  eta: 0:42:40  lr: 0.000027  loss: 0.2750  data_time: 0.0055  time: 1.1109  max mem: 34987
2023-10-30 00:26:50,734 [INFO] Train: data epoch: [2]  [ 150/2133]  eta: 0:40:05  lr: 0.000027  loss: 0.2800  data_time: 0.0051  time: 1.1118  max mem: 34987
2023-10-30 00:27:45,133 [INFO] Train: data epoch: [2]  [ 200/2133]  eta: 0:38:04  lr: 0.000027  loss: 0.2902  data_time: 0.0049  time: 1.0841  max mem: 34987
2023-10-30 00:28:39,661 [INFO] Train: data epoch: [2]  [ 250/2133]  eta: 0:36:31  lr: 0.000027  loss: 0.2627  data_time: 0.0047  time: 1.0899  max mem: 34987
2023-10-30 00:29:34,145 [INFO] Train: data epoch: [2]  [ 300/2133]  eta: 0:35:10  lr: 0.000027  loss: 0.3331  data_time: 0.0046  time: 1.0780  max mem: 34987
2023-10-30 00:30:28,382 [INFO] Train: data epoch: [2]  [ 350/2133]  eta: 0:33:55  lr: 0.000027  loss: 0.3162  data_time: 0.0049  time: 1.0806  max mem: 34987
2023-10-30 00:31:22,432 [INFO] Train: data epoch: [2]  [ 400/2133]  eta: 0:32:45  lr: 0.000027  loss: 0.3027  data_time: 0.0054  time: 1.0848  max mem: 34987
2023-10-30 00:32:19,361 [INFO] Train: data epoch: [2]  [ 450/2133]  eta: 0:31:49  lr: 0.000027  loss: 0.3661  data_time: 0.0049  time: 1.0891  max mem: 34987
2023-10-30 00:33:13,556 [INFO] Train: data epoch: [2]  [ 500/2133]  eta: 0:30:44  lr: 0.000027  loss: 0.3318  data_time: 0.0053  time: 1.0858  max mem: 34987
2023-10-30 00:34:07,677 [INFO] Train: data epoch: [2]  [ 550/2133]  eta: 0:29:41  lr: 0.000027  loss: 0.3133  data_time: 0.0052  time: 1.0884  max mem: 34987
2023-10-30 00:35:01,774 [INFO] Train: data epoch: [2]  [ 600/2133]  eta: 0:28:39  lr: 0.000027  loss: 0.2928  data_time: 0.0047  time: 1.0854  max mem: 34987
2023-10-30 00:35:55,952 [INFO] Train: data epoch: [2]  [ 650/2133]  eta: 0:27:39  lr: 0.000027  loss: 0.3302  data_time: 0.0049  time: 1.0883  max mem: 34987
2023-10-30 00:36:50,299 [INFO] Train: data epoch: [2]  [ 700/2133]  eta: 0:26:39  lr: 0.000027  loss: 0.2984  data_time: 0.0051  time: 1.0869  max mem: 34987
2023-10-30 00:37:44,507 [INFO] Train: data epoch: [2]  [ 750/2133]  eta: 0:25:41  lr: 0.000027  loss: 0.3414  data_time: 0.0052  time: 1.0877  max mem: 34987
2023-10-30 00:38:38,489 [INFO] Train: data epoch: [2]  [ 800/2133]  eta: 0:24:42  lr: 0.000027  loss: 0.3597  data_time: 0.0045  time: 1.0783  max mem: 34987
2023-10-30 00:39:32,895 [INFO] Train: data epoch: [2]  [ 850/2133]  eta: 0:23:45  lr: 0.000027  loss: 0.4271  data_time: 0.0053  time: 1.0831  max mem: 34987
2023-10-30 00:40:26,753 [INFO] Train: data epoch: [2]  [ 900/2133]  eta: 0:22:47  lr: 0.000027  loss: 0.3007  data_time: 0.0048  time: 1.0766  max mem: 34987
2023-10-30 00:41:20,929 [INFO] Train: data epoch: [2]  [ 950/2133]  eta: 0:21:50  lr: 0.000027  loss: 0.3032  data_time: 0.0045  time: 1.0785  max mem: 34987
2023-10-30 00:42:15,153 [INFO] Train: data epoch: [2]  [1000/2133]  eta: 0:20:53  lr: 0.000027  loss: 0.2892  data_time: 0.0051  time: 1.0889  max mem: 34987
2023-10-30 00:43:09,380 [INFO] Train: data epoch: [2]  [1050/2133]  eta: 0:19:57  lr: 0.000027  loss: 0.3736  data_time: 0.0053  time: 1.0865  max mem: 34987
2023-10-30 00:44:03,647 [INFO] Train: data epoch: [2]  [1100/2133]  eta: 0:19:00  lr: 0.000027  loss: 0.3932  data_time: 0.0046  time: 1.0888  max mem: 34987
2023-10-30 00:44:57,617 [INFO] Train: data epoch: [2]  [1150/2133]  eta: 0:18:04  lr: 0.000027  loss: 0.2920  data_time: 0.0049  time: 1.0763  max mem: 34987
2023-10-30 00:45:51,450 [INFO] Train: data epoch: [2]  [1200/2133]  eta: 0:17:08  lr: 0.000027  loss: 0.3181  data_time: 0.0047  time: 1.0767  max mem: 34987
2023-10-30 00:46:45,330 [INFO] Train: data epoch: [2]  [1250/2133]  eta: 0:16:12  lr: 0.000027  loss: 0.3195  data_time: 0.0046  time: 1.0799  max mem: 34987
2023-10-30 00:47:39,701 [INFO] Train: data epoch: [2]  [1300/2133]  eta: 0:15:16  lr: 0.000027  loss: 0.4020  data_time: 0.0040  time: 1.0868  max mem: 34987
2023-10-30 00:48:33,738 [INFO] Train: data epoch: [2]  [1350/2133]  eta: 0:14:21  lr: 0.000027  loss: 0.3210  data_time: 0.0052  time: 1.0800  max mem: 34987
2023-10-30 00:49:27,814 [INFO] Train: data epoch: [2]  [1400/2133]  eta: 0:13:25  lr: 0.000027  loss: 0.3030  data_time: 0.0051  time: 1.0775  max mem: 34987
2023-10-30 00:50:21,862 [INFO] Train: data epoch: [2]  [1450/2133]  eta: 0:12:30  lr: 0.000027  loss: 0.3388  data_time: 0.0050  time: 1.0858  max mem: 34987
2023-10-30 00:51:16,113 [INFO] Train: data epoch: [2]  [1500/2133]  eta: 0:11:35  lr: 0.000027  loss: 0.3378  data_time: 0.0051  time: 1.0807  max mem: 34987
2023-10-30 00:52:10,239 [INFO] Train: data epoch: [2]  [1550/2133]  eta: 0:10:39  lr: 0.000027  loss: 0.2701  data_time: 0.0048  time: 1.0839  max mem: 34987
2023-10-30 00:53:04,649 [INFO] Train: data epoch: [2]  [1600/2133]  eta: 0:09:44  lr: 0.000027  loss: 0.3499  data_time: 0.0050  time: 1.0915  max mem: 34987
2023-10-30 00:53:58,664 [INFO] Train: data epoch: [2]  [1650/2133]  eta: 0:08:49  lr: 0.000027  loss: 0.3414  data_time: 0.0043  time: 1.0805  max mem: 34987
2023-10-30 00:54:52,392 [INFO] Train: data epoch: [2]  [1700/2133]  eta: 0:07:54  lr: 0.000027  loss: 0.3706  data_time: 0.0047  time: 1.0708  max mem: 34987
2023-10-30 00:55:46,359 [INFO] Train: data epoch: [2]  [1750/2133]  eta: 0:06:59  lr: 0.000027  loss: 0.2646  data_time: 0.0051  time: 1.0752  max mem: 34987
2023-10-30 00:56:40,401 [INFO] Train: data epoch: [2]  [1800/2133]  eta: 0:06:04  lr: 0.000027  loss: 0.3380  data_time: 0.0048  time: 1.0813  max mem: 34987
2023-10-30 00:57:34,580 [INFO] Train: data epoch: [2]  [1850/2133]  eta: 0:05:09  lr: 0.000027  loss: 0.2944  data_time: 0.0045  time: 1.0806  max mem: 34987
2023-10-30 00:58:28,923 [INFO] Train: data epoch: [2]  [1900/2133]  eta: 0:04:15  lr: 0.000027  loss: 0.3416  data_time: 0.0053  time: 1.0872  max mem: 34987
2023-10-30 00:59:22,746 [INFO] Train: data epoch: [2]  [1950/2133]  eta: 0:03:20  lr: 0.000027  loss: 0.3266  data_time: 0.0051  time: 1.0706  max mem: 34987
2023-10-30 01:00:17,012 [INFO] Train: data epoch: [2]  [2000/2133]  eta: 0:02:25  lr: 0.000027  loss: 0.2893  data_time: 0.0047  time: 1.0901  max mem: 34987
2023-10-30 01:01:11,211 [INFO] Train: data epoch: [2]  [2050/2133]  eta: 0:01:30  lr: 0.000027  loss: 0.2882  data_time: 0.0046  time: 1.0897  max mem: 34987
2023-10-30 01:02:05,262 [INFO] Train: data epoch: [2]  [2100/2133]  eta: 0:00:36  lr: 0.000027  loss: 0.3124  data_time: 0.0051  time: 1.0779  max mem: 34987
2023-10-30 01:02:39,894 [INFO] Train: data epoch: [2]  [2132/2133]  eta: 0:00:01  lr: 0.000027  loss: 0.2728  data_time: 0.0201  time: 1.0807  max mem: 34987
2023-10-30 01:02:39,901 [INFO] Averaged stats: lr: 0.0000  loss: 0.3156  data_time: 0.0111
2023-10-30 01:02:39,907 [INFO] Evaluating on val.
2023-10-30 01:03:04,773 [INFO] Evaluation  [  0/625]  eta: 4:18:45    time: 24.8405  max mem: 34987
2023-10-30 01:03:35,874 [INFO] Evaluation  [ 10/625]  eta: 0:52:07    time: 5.0853  max mem: 34987
2023-10-30 01:04:04,595 [INFO] Evaluation  [ 20/625]  eta: 0:40:38    time: 2.9909  max mem: 34987
2023-10-30 01:04:30,520 [INFO] Evaluation  [ 30/625]  eta: 0:35:22    time: 2.7322  max mem: 34987
2023-10-30 01:04:56,719 [INFO] Evaluation  [ 40/625]  eta: 0:32:31    time: 2.6061  max mem: 34987
2023-10-30 01:05:22,510 [INFO] Evaluation  [ 50/625]  eta: 0:30:32    time: 2.5993  max mem: 34987
2023-10-30 01:05:48,472 [INFO] Evaluation  [ 60/625]  eta: 0:29:06    time: 2.5875  max mem: 34987
2023-10-30 01:06:14,597 [INFO] Evaluation  [ 70/625]  eta: 0:27:57    time: 2.6042  max mem: 34987
2023-10-30 01:06:40,616 [INFO] Evaluation  [ 80/625]  eta: 0:26:59    time: 2.6070  max mem: 34987
2023-10-30 01:07:06,572 [INFO] Evaluation  [ 90/625]  eta: 0:26:07    time: 2.5986  max mem: 34987
2023-10-30 01:07:32,409 [INFO] Evaluation  [100/625]  eta: 0:25:20    time: 2.5895  max mem: 34987
2023-10-30 01:07:58,618 [INFO] Evaluation  [110/625]  eta: 0:24:38    time: 2.6021  max mem: 34987
2023-10-30 01:08:24,534 [INFO] Evaluation  [120/625]  eta: 0:23:58    time: 2.6061  max mem: 34987
2023-10-30 01:08:50,123 [INFO] Evaluation  [130/625]  eta: 0:23:18    time: 2.5751  max mem: 34987
2023-10-30 01:09:15,686 [INFO] Evaluation  [140/625]  eta: 0:22:41    time: 2.5575  max mem: 34987
2023-10-30 01:09:41,570 [INFO] Evaluation  [150/625]  eta: 0:22:06    time: 2.5722  max mem: 34987
2023-10-30 01:10:07,616 [INFO] Evaluation  [160/625]  eta: 0:21:32    time: 2.5964  max mem: 34987
2023-10-30 01:10:33,328 [INFO] Evaluation  [170/625]  eta: 0:20:59    time: 2.5877  max mem: 34987
2023-10-30 01:10:59,557 [INFO] Evaluation  [180/625]  eta: 0:20:28    time: 2.5968  max mem: 34987
2023-10-30 01:11:25,573 [INFO] Evaluation  [190/625]  eta: 0:19:57    time: 2.6120  max mem: 34987
2023-10-30 01:11:51,510 [INFO] Evaluation  [200/625]  eta: 0:19:26    time: 2.5975  max mem: 34987
2023-10-30 01:12:17,359 [INFO] Evaluation  [210/625]  eta: 0:18:55    time: 2.5892  max mem: 34987
2023-10-30 01:12:43,518 [INFO] Evaluation  [220/625]  eta: 0:18:26    time: 2.6002  max mem: 34987
2023-10-30 01:13:10,027 [INFO] Evaluation  [230/625]  eta: 0:17:57    time: 2.6333  max mem: 34987
2023-10-30 01:13:35,863 [INFO] Evaluation  [240/625]  eta: 0:17:27    time: 2.6171  max mem: 34987
2023-10-30 01:14:02,068 [INFO] Evaluation  [250/625]  eta: 0:16:59    time: 2.6019  max mem: 34987
2023-10-30 01:14:28,182 [INFO] Evaluation  [260/625]  eta: 0:16:30    time: 2.6158  max mem: 34987
2023-10-30 01:14:54,052 [INFO] Evaluation  [270/625]  eta: 0:16:01    time: 2.5990  max mem: 34987
2023-10-30 01:15:19,767 [INFO] Evaluation  [280/625]  eta: 0:15:32    time: 2.5791  max mem: 34987
2023-10-30 01:15:45,839 [INFO] Evaluation  [290/625]  eta: 0:15:04    time: 2.5892  max mem: 34987
2023-10-30 01:16:11,625 [INFO] Evaluation  [300/625]  eta: 0:14:36    time: 2.5927  max mem: 34987
2023-10-30 01:16:37,716 [INFO] Evaluation  [310/625]  eta: 0:14:08    time: 2.5937  max mem: 34987
2023-10-30 01:17:03,470 [INFO] Evaluation  [320/625]  eta: 0:13:40    time: 2.5921  max mem: 34987
2023-10-30 01:17:29,395 [INFO] Evaluation  [330/625]  eta: 0:13:12    time: 2.5838  max mem: 34987
2023-10-30 01:17:55,468 [INFO] Evaluation  [340/625]  eta: 0:12:45    time: 2.5997  max mem: 34987
2023-10-30 01:18:21,731 [INFO] Evaluation  [350/625]  eta: 0:12:17    time: 2.6166  max mem: 34987
2023-10-30 01:18:48,076 [INFO] Evaluation  [360/625]  eta: 0:11:50    time: 2.6303  max mem: 34987
2023-10-30 01:19:14,279 [INFO] Evaluation  [370/625]  eta: 0:11:23    time: 2.6272  max mem: 34987
2023-10-30 01:19:40,039 [INFO] Evaluation  [380/625]  eta: 0:10:55    time: 2.5980  max mem: 34987
2023-10-30 01:20:05,869 [INFO] Evaluation  [390/625]  eta: 0:10:28    time: 2.5794  max mem: 34987
2023-10-30 01:20:31,779 [INFO] Evaluation  [400/625]  eta: 0:10:01    time: 2.5868  max mem: 34987
2023-10-30 01:20:57,655 [INFO] Evaluation  [410/625]  eta: 0:09:34    time: 2.5892  max mem: 34987
2023-10-30 01:21:23,908 [INFO] Evaluation  [420/625]  eta: 0:09:07    time: 2.6063  max mem: 34987
2023-10-30 01:21:49,803 [INFO] Evaluation  [430/625]  eta: 0:08:40    time: 2.6072  max mem: 34987
2023-10-30 01:22:16,173 [INFO] Evaluation  [440/625]  eta: 0:08:13    time: 2.6130  max mem: 34987
2023-10-30 01:22:42,388 [INFO] Evaluation  [450/625]  eta: 0:07:46    time: 2.6289  max mem: 34987
2023-10-30 01:23:08,437 [INFO] Evaluation  [460/625]  eta: 0:07:19    time: 2.6129  max mem: 34987
2023-10-30 01:23:34,147 [INFO] Evaluation  [470/625]  eta: 0:06:52    time: 2.5878  max mem: 34987
2023-10-30 01:24:00,419 [INFO] Evaluation  [480/625]  eta: 0:06:25    time: 2.5987  max mem: 34987
2023-10-30 01:24:26,343 [INFO] Evaluation  [490/625]  eta: 0:05:59    time: 2.6093  max mem: 34987
2023-10-30 01:24:52,709 [INFO] Evaluation  [500/625]  eta: 0:05:32    time: 2.6142  max mem: 34987
2023-10-30 01:25:18,546 [INFO] Evaluation  [510/625]  eta: 0:05:05    time: 2.6097  max mem: 34987
2023-10-30 01:25:44,732 [INFO] Evaluation  [520/625]  eta: 0:04:39    time: 2.6005  max mem: 34987
2023-10-30 01:26:10,897 [INFO] Evaluation  [530/625]  eta: 0:04:12    time: 2.6173  max mem: 34987
2023-10-30 01:26:37,326 [INFO] Evaluation  [540/625]  eta: 0:03:45    time: 2.6295  max mem: 34987
2023-10-30 01:27:08,441 [INFO] Evaluation  [550/625]  eta: 0:03:19    time: 2.8761  max mem: 34987
2023-10-30 01:27:34,335 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.8494  max mem: 34987
2023-10-30 01:28:01,199 [INFO] Evaluation  [570/625]  eta: 0:02:26    time: 2.6377  max mem: 34987
2023-10-30 01:28:27,156 [INFO] Evaluation  [580/625]  eta: 0:01:59    time: 2.6408  max mem: 34987
2023-10-30 01:28:52,973 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5885  max mem: 34987
2023-10-30 01:29:19,311 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.6074  max mem: 34987
2023-10-30 01:29:45,032 [INFO] Evaluation  [610/625]  eta: 0:00:39    time: 2.6026  max mem: 34987
2023-10-30 01:30:10,705 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5695  max mem: 34987
2023-10-30 01:30:20,310 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5336  max mem: 34987
2023-10-30 01:30:20,363 [WARNING] rank 0 starts merging results.
2023-10-30 01:30:20,423 [INFO] {'agg_metrics': 0.6395116092874299, 'total': 4996, 'CH': 63.250366032210835, 'CW': 62.00623700623701, 'TN': 56.75977653631284, 'TC': 67.72247360482655, 'DL': 86.4406779661017, 'DC': 50.847457627118644, 'DO': 75.40983606557377, 'TP': 70.37037037037037}
2023-10-30 01:30:20,425 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_1.pth.
2023-10-30 01:30:20,563 [INFO] Saving checkpoint at epoch 2 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_2.pth.
2023-10-30 01:30:22,312 [INFO] Start training
2023-10-30 01:30:22,348 [INFO] Start training epoch 3, 2133 iters per inner epoch.
2023-10-30 01:30:34,148 [INFO] Train: data epoch: [3]  [   0/2133]  eta: 6:59:24  lr: 0.000024  loss: 0.3176  data_time: 9.7179  time: 11.7976  max mem: 34987
2023-10-30 01:31:30,813 [INFO] Train: data epoch: [3]  [  50/2133]  eta: 0:46:36  lr: 0.000024  loss: 0.3034  data_time: 0.0045  time: 1.0733  max mem: 34987
2023-10-30 01:32:25,189 [INFO] Train: data epoch: [3]  [ 100/2133]  eta: 0:41:12  lr: 0.000024  loss: 0.3574  data_time: 0.0050  time: 1.0876  max mem: 34987
2023-10-30 01:33:19,104 [INFO] Train: data epoch: [3]  [ 150/2133]  eta: 0:38:41  lr: 0.000024  loss: 0.2929  data_time: 0.0049  time: 1.0774  max mem: 34987
2023-10-30 01:34:13,679 [INFO] Train: data epoch: [3]  [ 200/2133]  eta: 0:37:04  lr: 0.000024  loss: 0.3084  data_time: 0.0058  time: 1.1050  max mem: 34987
2023-10-30 01:35:11,471 [INFO] Train: data epoch: [3]  [ 250/2133]  eta: 0:36:08  lr: 0.000024  loss: 0.3314  data_time: 0.0051  time: 1.2666  max mem: 34987
2023-10-30 01:36:05,580 [INFO] Train: data epoch: [3]  [ 300/2133]  eta: 0:34:50  lr: 0.000024  loss: 0.3454  data_time: 0.0049  time: 1.0969  max mem: 34987
2023-10-30 01:37:02,640 [INFO] Train: data epoch: [3]  [ 350/2133]  eta: 0:33:53  lr: 0.000024  loss: 0.3231  data_time: 0.0047  time: 1.2189  max mem: 34987
2023-10-30 01:37:57,117 [INFO] Train: data epoch: [3]  [ 400/2133]  eta: 0:32:45  lr: 0.000024  loss: 0.2487  data_time: 0.0050  time: 1.1056  max mem: 34987
2023-10-30 01:38:50,838 [INFO] Train: data epoch: [3]  [ 450/2133]  eta: 0:31:37  lr: 0.000024  loss: 0.2858  data_time: 0.0051  time: 1.0748  max mem: 34987
2023-10-30 01:39:45,594 [INFO] Train: data epoch: [3]  [ 500/2133]  eta: 0:30:35  lr: 0.000024  loss: 0.3490  data_time: 0.0047  time: 1.0802  max mem: 34987
2023-10-30 01:40:39,757 [INFO] Train: data epoch: [3]  [ 550/2133]  eta: 0:29:33  lr: 0.000024  loss: 0.3929  data_time: 0.0051  time: 1.0786  max mem: 34987
2023-10-30 01:41:34,025 [INFO] Train: data epoch: [3]  [ 600/2133]  eta: 0:28:33  lr: 0.000024  loss: 0.3292  data_time: 0.0044  time: 1.0861  max mem: 34987
2023-10-30 01:42:28,077 [INFO] Train: data epoch: [3]  [ 650/2133]  eta: 0:27:33  lr: 0.000024  loss: 0.3377  data_time: 0.0046  time: 1.0785  max mem: 34987
2023-10-30 01:43:24,673 [INFO] Train: data epoch: [3]  [ 700/2133]  eta: 0:26:39  lr: 0.000024  loss: 0.3336  data_time: 0.0053  time: 1.0840  max mem: 34987
2023-10-30 01:44:18,556 [INFO] Train: data epoch: [3]  [ 750/2133]  eta: 0:25:39  lr: 0.000024  loss: 0.2753  data_time: 0.0048  time: 1.0794  max mem: 34987
2023-10-30 01:45:18,357 [INFO] Train: data epoch: [3]  [ 800/2133]  eta: 0:24:51  lr: 0.000024  loss: 0.3056  data_time: 0.0063  time: 1.3535  max mem: 34987
2023-10-30 01:46:16,746 [INFO] Train: data epoch: [3]  [ 850/2133]  eta: 0:23:58  lr: 0.000024  loss: 0.3283  data_time: 0.0054  time: 1.3006  max mem: 34987
2023-10-30 01:47:13,621 [INFO] Train: data epoch: [3]  [ 900/2133]  eta: 0:23:03  lr: 0.000024  loss: 0.3762  data_time: 0.0048  time: 1.2272  max mem: 34987
2023-10-30 01:48:10,587 [INFO] Train: data epoch: [3]  [ 950/2133]  eta: 0:22:08  lr: 0.000024  loss: 0.2916  data_time: 0.0053  time: 1.2252  max mem: 34987
2023-10-30 01:49:04,313 [INFO] Train: data epoch: [3]  [1000/2133]  eta: 0:21:09  lr: 0.000024  loss: 0.2770  data_time: 0.0046  time: 1.0727  max mem: 34987
2023-10-30 01:49:58,356 [INFO] Train: data epoch: [3]  [1050/2133]  eta: 0:20:11  lr: 0.000024  loss: 0.3602  data_time: 0.0051  time: 1.0836  max mem: 34987
2023-10-30 01:50:52,499 [INFO] Train: data epoch: [3]  [1100/2133]  eta: 0:19:14  lr: 0.000024  loss: 0.3511  data_time: 0.0046  time: 1.0851  max mem: 34987
2023-10-30 01:51:46,893 [INFO] Train: data epoch: [3]  [1150/2133]  eta: 0:18:16  lr: 0.000024  loss: 0.3201  data_time: 0.0045  time: 1.0756  max mem: 34987
2023-10-30 01:52:41,037 [INFO] Train: data epoch: [3]  [1200/2133]  eta: 0:17:19  lr: 0.000024  loss: 0.2939  data_time: 0.0055  time: 1.0843  max mem: 34987
2023-10-30 01:53:35,177 [INFO] Train: data epoch: [3]  [1250/2133]  eta: 0:16:23  lr: 0.000024  loss: 0.2785  data_time: 0.0049  time: 1.0812  max mem: 34987
2023-10-30 01:54:29,182 [INFO] Train: data epoch: [3]  [1300/2133]  eta: 0:15:26  lr: 0.000024  loss: 0.3081  data_time: 0.0046  time: 1.0833  max mem: 34987
2023-10-30 01:55:23,786 [INFO] Train: data epoch: [3]  [1350/2133]  eta: 0:14:30  lr: 0.000024  loss: 0.3215  data_time: 0.0048  time: 1.0837  max mem: 34987
2023-10-30 01:56:17,929 [INFO] Train: data epoch: [3]  [1400/2133]  eta: 0:13:33  lr: 0.000024  loss: 0.3051  data_time: 0.0041  time: 1.0869  max mem: 34987
2023-10-30 01:57:11,944 [INFO] Train: data epoch: [3]  [1450/2133]  eta: 0:12:37  lr: 0.000024  loss: 0.3639  data_time: 0.0045  time: 1.0821  max mem: 34987
2023-10-30 01:58:05,700 [INFO] Train: data epoch: [3]  [1500/2133]  eta: 0:11:41  lr: 0.000024  loss: 0.3063  data_time: 0.0046  time: 1.0781  max mem: 34987
2023-10-30 01:58:59,908 [INFO] Train: data epoch: [3]  [1550/2133]  eta: 0:10:45  lr: 0.000024  loss: 0.2632  data_time: 0.0052  time: 1.0861  max mem: 34987
2023-10-30 01:59:54,009 [INFO] Train: data epoch: [3]  [1600/2133]  eta: 0:09:49  lr: 0.000024  loss: 0.2933  data_time: 0.0051  time: 1.0760  max mem: 34987
2023-10-30 02:00:48,103 [INFO] Train: data epoch: [3]  [1650/2133]  eta: 0:08:54  lr: 0.000024  loss: 0.3150  data_time: 0.0051  time: 1.0833  max mem: 34987
2023-10-30 02:01:42,311 [INFO] Train: data epoch: [3]  [1700/2133]  eta: 0:07:58  lr: 0.000024  loss: 0.3262  data_time: 0.0053  time: 1.0823  max mem: 34987
2023-10-30 02:02:36,321 [INFO] Train: data epoch: [3]  [1750/2133]  eta: 0:07:03  lr: 0.000024  loss: 0.2627  data_time: 0.0054  time: 1.0797  max mem: 34987
2023-10-30 02:03:30,586 [INFO] Train: data epoch: [3]  [1800/2133]  eta: 0:06:07  lr: 0.000024  loss: 0.2952  data_time: 0.0051  time: 1.0918  max mem: 34987
2023-10-30 02:04:25,990 [INFO] Train: data epoch: [3]  [1850/2133]  eta: 0:05:12  lr: 0.000024  loss: 0.3964  data_time: 0.0052  time: 1.0849  max mem: 34987
2023-10-30 02:05:20,087 [INFO] Train: data epoch: [3]  [1900/2133]  eta: 0:04:17  lr: 0.000024  loss: 0.3122  data_time: 0.0048  time: 1.0835  max mem: 34987
2023-10-30 02:06:13,994 [INFO] Train: data epoch: [3]  [1950/2133]  eta: 0:03:21  lr: 0.000024  loss: 0.2982  data_time: 0.0043  time: 1.0775  max mem: 34987
2023-10-30 02:07:08,260 [INFO] Train: data epoch: [3]  [2000/2133]  eta: 0:02:26  lr: 0.000024  loss: 0.2842  data_time: 0.0056  time: 1.0823  max mem: 34987
2023-10-30 02:08:02,317 [INFO] Train: data epoch: [3]  [2050/2133]  eta: 0:01:31  lr: 0.000024  loss: 0.3002  data_time: 0.0048  time: 1.0821  max mem: 34987
2023-10-30 02:08:56,410 [INFO] Train: data epoch: [3]  [2100/2133]  eta: 0:00:36  lr: 0.000024  loss: 0.2961  data_time: 0.0050  time: 1.0820  max mem: 34987
2023-10-30 02:09:30,979 [INFO] Train: data epoch: [3]  [2132/2133]  eta: 0:00:01  lr: 0.000024  loss: 0.2753  data_time: 0.0174  time: 1.0822  max mem: 34987
2023-10-30 02:09:30,989 [INFO] Averaged stats: lr: 0.0000  loss: 0.3111  data_time: 0.0096
2023-10-30 02:09:30,998 [INFO] Evaluating on val.
2023-10-30 02:09:54,621 [INFO] Evaluation  [  0/625]  eta: 4:05:49    time: 23.5985  max mem: 34987
2023-10-30 02:10:26,450 [INFO] Evaluation  [ 10/625]  eta: 0:51:38    time: 5.0387  max mem: 34987
2023-10-30 02:10:55,447 [INFO] Evaluation  [ 20/625]  eta: 0:40:32    time: 3.0411  max mem: 34987
2023-10-30 02:11:21,530 [INFO] Evaluation  [ 30/625]  eta: 0:35:20    time: 2.7538  max mem: 34987
2023-10-30 02:11:47,692 [INFO] Evaluation  [ 40/625]  eta: 0:32:29    time: 2.6121  max mem: 34987
2023-10-30 02:12:13,501 [INFO] Evaluation  [ 50/625]  eta: 0:30:31    time: 2.5984  max mem: 34987
2023-10-30 02:12:39,458 [INFO] Evaluation  [ 60/625]  eta: 0:29:05    time: 2.5881  max mem: 34987
2023-10-30 02:13:05,618 [INFO] Evaluation  [ 70/625]  eta: 0:27:57    time: 2.6057  max mem: 34987
2023-10-30 02:13:31,747 [INFO] Evaluation  [ 80/625]  eta: 0:26:59    time: 2.6143  max mem: 34987
2023-10-30 02:13:57,682 [INFO] Evaluation  [ 90/625]  eta: 0:26:07    time: 2.6030  max mem: 34987
2023-10-30 02:14:23,536 [INFO] Evaluation  [100/625]  eta: 0:25:20    time: 2.5893  max mem: 34987
2023-10-30 02:14:49,692 [INFO] Evaluation  [110/625]  eta: 0:24:38    time: 2.6004  max mem: 34987
2023-10-30 02:15:15,972 [INFO] Evaluation  [120/625]  eta: 0:23:59    time: 2.6216  max mem: 34987
2023-10-30 02:15:41,707 [INFO] Evaluation  [130/625]  eta: 0:23:20    time: 2.6006  max mem: 34987
2023-10-30 02:16:07,341 [INFO] Evaluation  [140/625]  eta: 0:22:43    time: 2.5683  max mem: 34987
2023-10-30 02:16:33,308 [INFO] Evaluation  [150/625]  eta: 0:22:08    time: 2.5799  max mem: 34987
2023-10-30 02:16:59,305 [INFO] Evaluation  [160/625]  eta: 0:21:34    time: 2.5980  max mem: 34987
2023-10-30 02:17:24,954 [INFO] Evaluation  [170/625]  eta: 0:21:00    time: 2.5822  max mem: 34987
2023-10-30 02:17:51,142 [INFO] Evaluation  [180/625]  eta: 0:20:29    time: 2.5917  max mem: 34987
2023-10-30 02:18:17,065 [INFO] Evaluation  [190/625]  eta: 0:19:57    time: 2.6054  max mem: 34987
2023-10-30 02:18:42,881 [INFO] Evaluation  [200/625]  eta: 0:19:26    time: 2.5868  max mem: 34987
2023-10-30 02:19:08,692 [INFO] Evaluation  [210/625]  eta: 0:18:56    time: 2.5812  max mem: 34987
2023-10-30 02:19:34,759 [INFO] Evaluation  [220/625]  eta: 0:18:26    time: 2.5938  max mem: 34987
2023-10-30 02:20:01,102 [INFO] Evaluation  [230/625]  eta: 0:17:57    time: 2.6203  max mem: 34987
2023-10-30 02:20:26,959 [INFO] Evaluation  [240/625]  eta: 0:17:27    time: 2.6099  max mem: 34987
2023-10-30 02:20:53,000 [INFO] Evaluation  [250/625]  eta: 0:16:58    time: 2.5947  max mem: 34987
2023-10-30 02:21:19,075 [INFO] Evaluation  [260/625]  eta: 0:16:30    time: 2.6056  max mem: 34987
2023-10-30 02:21:44,929 [INFO] Evaluation  [270/625]  eta: 0:16:01    time: 2.5963  max mem: 34987
2023-10-30 02:22:10,643 [INFO] Evaluation  [280/625]  eta: 0:15:32    time: 2.5782  max mem: 34987
2023-10-30 02:22:36,841 [INFO] Evaluation  [290/625]  eta: 0:15:04    time: 2.5954  max mem: 34987
2023-10-30 02:23:02,599 [INFO] Evaluation  [300/625]  eta: 0:14:36    time: 2.5976  max mem: 34987
2023-10-30 02:23:28,685 [INFO] Evaluation  [310/625]  eta: 0:14:08    time: 2.5921  max mem: 34987
2023-10-30 02:23:54,439 [INFO] Evaluation  [320/625]  eta: 0:13:40    time: 2.5919  max mem: 34987
2023-10-30 02:24:20,393 [INFO] Evaluation  [330/625]  eta: 0:13:12    time: 2.5852  max mem: 34987
2023-10-30 02:24:46,379 [INFO] Evaluation  [340/625]  eta: 0:12:44    time: 2.5968  max mem: 34987
2023-10-30 02:25:12,514 [INFO] Evaluation  [350/625]  eta: 0:12:17    time: 2.6059  max mem: 34987
2023-10-30 02:25:38,839 [INFO] Evaluation  [360/625]  eta: 0:11:50    time: 2.6229  max mem: 34987
2023-10-30 02:26:05,023 [INFO] Evaluation  [370/625]  eta: 0:11:23    time: 2.6253  max mem: 34987
2023-10-30 02:26:30,775 [INFO] Evaluation  [380/625]  eta: 0:10:55    time: 2.5966  max mem: 34987
2023-10-30 02:26:56,667 [INFO] Evaluation  [390/625]  eta: 0:10:28    time: 2.5820  max mem: 34987
2023-10-30 02:27:22,543 [INFO] Evaluation  [400/625]  eta: 0:10:01    time: 2.5882  max mem: 34987
2023-10-30 02:27:48,484 [INFO] Evaluation  [410/625]  eta: 0:09:34    time: 2.5907  max mem: 34987
2023-10-30 02:28:14,737 [INFO] Evaluation  [420/625]  eta: 0:09:07    time: 2.6095  max mem: 34987
2023-10-30 02:28:40,626 [INFO] Evaluation  [430/625]  eta: 0:08:40    time: 2.6070  max mem: 34987
2023-10-30 02:29:06,973 [INFO] Evaluation  [440/625]  eta: 0:08:13    time: 2.6116  max mem: 34987
2023-10-30 02:29:32,960 [INFO] Evaluation  [450/625]  eta: 0:07:46    time: 2.6163  max mem: 34987
2023-10-30 02:29:58,870 [INFO] Evaluation  [460/625]  eta: 0:07:19    time: 2.5945  max mem: 34987
2023-10-30 02:30:24,548 [INFO] Evaluation  [470/625]  eta: 0:06:52    time: 2.5792  max mem: 34987
2023-10-30 02:30:50,224 [INFO] Evaluation  [480/625]  eta: 0:06:25    time: 2.5675  max mem: 34987
2023-10-30 02:31:16,272 [INFO] Evaluation  [490/625]  eta: 0:05:58    time: 2.5858  max mem: 34987
2023-10-30 02:31:42,566 [INFO] Evaluation  [500/625]  eta: 0:05:32    time: 2.6165  max mem: 34987
2023-10-30 02:32:13,657 [INFO] Evaluation  [510/625]  eta: 0:05:06    time: 2.8686  max mem: 34987
2023-10-30 02:32:39,981 [INFO] Evaluation  [520/625]  eta: 0:04:39    time: 2.8703  max mem: 34987
2023-10-30 02:33:06,413 [INFO] Evaluation  [530/625]  eta: 0:04:13    time: 2.6376  max mem: 34987
2023-10-30 02:33:33,212 [INFO] Evaluation  [540/625]  eta: 0:03:46    time: 2.6613  max mem: 34987
2023-10-30 02:34:00,607 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.7088  max mem: 34987
2023-10-30 02:34:26,341 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.6555  max mem: 34987
2023-10-30 02:34:52,524 [INFO] Evaluation  [570/625]  eta: 0:02:26    time: 2.5957  max mem: 34987
2023-10-30 02:35:18,442 [INFO] Evaluation  [580/625]  eta: 0:01:59    time: 2.6048  max mem: 34987
2023-10-30 02:35:44,159 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5815  max mem: 34987
2023-10-30 02:36:10,259 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5907  max mem: 34987
2023-10-30 02:36:35,945 [INFO] Evaluation  [610/625]  eta: 0:00:39    time: 2.5891  max mem: 34987
2023-10-30 02:37:01,590 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5664  max mem: 34987
2023-10-30 02:37:11,078 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5293  max mem: 34987
2023-10-30 02:37:11,134 [WARNING] rank 0 starts merging results.
2023-10-30 02:37:11,184 [INFO] {'agg_metrics': 0.6377101681345076, 'total': 4996, 'CH': 63.689604685212295, 'CW': 62.16216216216216, 'TN': 55.418994413407816, 'TC': 66.81749622926093, 'DL': 86.77966101694915, 'DC': 51.41242937853108, 'DO': 76.0655737704918, 'TP': 68.51851851851852}
2023-10-30 02:37:11,186 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_2.pth.
2023-10-30 02:37:11,317 [INFO] Saving checkpoint at epoch 3 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_3.pth.
2023-10-30 02:37:13,118 [INFO] Start training
2023-10-30 02:37:13,155 [INFO] Start training epoch 4, 2133 iters per inner epoch.
2023-10-30 02:37:25,473 [INFO] Train: data epoch: [4]  [   0/2133]  eta: 7:17:52  lr: 0.000020  loss: 0.3077  data_time: 10.6074  time: 12.3172  max mem: 34987
2023-10-30 02:38:22,415 [INFO] Train: data epoch: [4]  [  50/2133]  eta: 0:47:08  lr: 0.000020  loss: 0.2754  data_time: 0.0045  time: 1.0803  max mem: 34987
2023-10-30 02:39:17,051 [INFO] Train: data epoch: [4]  [ 100/2133]  eta: 0:41:33  lr: 0.000020  loss: 0.2455  data_time: 0.0051  time: 1.0809  max mem: 34987
2023-10-30 02:40:12,889 [INFO] Train: data epoch: [4]  [ 150/2133]  eta: 0:39:20  lr: 0.000020  loss: 0.3770  data_time: 0.0059  time: 1.1744  max mem: 34987
2023-10-30 02:41:08,075 [INFO] Train: data epoch: [4]  [ 200/2133]  eta: 0:37:39  lr: 0.000020  loss: 0.2774  data_time: 0.0053  time: 1.1354  max mem: 34987
2023-10-30 02:42:02,266 [INFO] Train: data epoch: [4]  [ 250/2133]  eta: 0:36:08  lr: 0.000020  loss: 0.2647  data_time: 0.0046  time: 1.0840  max mem: 34987
2023-10-30 02:42:59,255 [INFO] Train: data epoch: [4]  [ 300/2133]  eta: 0:35:07  lr: 0.000020  loss: 0.3043  data_time: 0.0048  time: 1.2344  max mem: 34987
2023-10-30 02:43:53,385 [INFO] Train: data epoch: [4]  [ 350/2133]  eta: 0:33:52  lr: 0.000020  loss: 0.2552  data_time: 0.0046  time: 1.0814  max mem: 34987
2023-10-30 02:44:47,539 [INFO] Train: data epoch: [4]  [ 400/2133]  eta: 0:32:43  lr: 0.000020  loss: 0.3545  data_time: 0.0052  time: 1.0889  max mem: 34987
2023-10-30 02:45:41,978 [INFO] Train: data epoch: [4]  [ 450/2133]  eta: 0:31:38  lr: 0.000020  loss: 0.2986  data_time: 0.0047  time: 1.0857  max mem: 34987
2023-10-30 02:46:36,274 [INFO] Train: data epoch: [4]  [ 500/2133]  eta: 0:30:35  lr: 0.000020  loss: 0.3446  data_time: 0.0054  time: 1.0868  max mem: 34987
2023-10-30 02:47:30,300 [INFO] Train: data epoch: [4]  [ 550/2133]  eta: 0:29:32  lr: 0.000020  loss: 0.3259  data_time: 0.0055  time: 1.0767  max mem: 34987
2023-10-30 02:48:24,118 [INFO] Train: data epoch: [4]  [ 600/2133]  eta: 0:28:31  lr: 0.000020  loss: 0.2973  data_time: 0.0052  time: 1.0758  max mem: 34987
2023-10-30 02:49:20,739 [INFO] Train: data epoch: [4]  [ 650/2133]  eta: 0:27:37  lr: 0.000020  loss: 0.3611  data_time: 0.0047  time: 1.0772  max mem: 34987
2023-10-30 02:50:14,650 [INFO] Train: data epoch: [4]  [ 700/2133]  eta: 0:26:37  lr: 0.000020  loss: 0.2886  data_time: 0.0051  time: 1.0716  max mem: 34987
2023-10-30 02:51:13,487 [INFO] Train: data epoch: [4]  [ 750/2133]  eta: 0:25:47  lr: 0.000020  loss: 0.3356  data_time: 0.0063  time: 1.3226  max mem: 34987
2023-10-30 02:52:11,083 [INFO] Train: data epoch: [4]  [ 800/2133]  eta: 0:24:54  lr: 0.000020  loss: 0.3774  data_time: 0.0045  time: 1.2596  max mem: 34987
2023-10-30 02:53:07,218 [INFO] Train: data epoch: [4]  [ 850/2133]  eta: 0:23:58  lr: 0.000020  loss: 0.3231  data_time: 0.0053  time: 1.1888  max mem: 34987
2023-10-30 02:54:03,776 [INFO] Train: data epoch: [4]  [ 900/2133]  eta: 0:23:02  lr: 0.000020  loss: 0.2999  data_time: 0.0065  time: 1.2054  max mem: 34987
2023-10-30 02:54:57,650 [INFO] Train: data epoch: [4]  [ 950/2133]  eta: 0:22:04  lr: 0.000020  loss: 0.3164  data_time: 0.0051  time: 1.0755  max mem: 34987
2023-10-30 02:55:51,730 [INFO] Train: data epoch: [4]  [1000/2133]  eta: 0:21:06  lr: 0.000020  loss: 0.2976  data_time: 0.0047  time: 1.0834  max mem: 34987
2023-10-30 02:56:45,996 [INFO] Train: data epoch: [4]  [1050/2133]  eta: 0:20:08  lr: 0.000020  loss: 0.2812  data_time: 0.0048  time: 1.0835  max mem: 34987
2023-10-30 02:57:40,670 [INFO] Train: data epoch: [4]  [1100/2133]  eta: 0:19:11  lr: 0.000020  loss: 0.3521  data_time: 0.0047  time: 1.0888  max mem: 34987
2023-10-30 02:58:34,740 [INFO] Train: data epoch: [4]  [1150/2133]  eta: 0:18:14  lr: 0.000020  loss: 0.3052  data_time: 0.0050  time: 1.0768  max mem: 34987
2023-10-30 02:59:28,867 [INFO] Train: data epoch: [4]  [1200/2133]  eta: 0:17:17  lr: 0.000020  loss: 0.3176  data_time: 0.0049  time: 1.0854  max mem: 34987
2023-10-30 03:00:22,819 [INFO] Train: data epoch: [4]  [1250/2133]  eta: 0:16:20  lr: 0.000020  loss: 0.3809  data_time: 0.0049  time: 1.0780  max mem: 34987
2023-10-30 03:01:17,103 [INFO] Train: data epoch: [4]  [1300/2133]  eta: 0:15:24  lr: 0.000020  loss: 0.2978  data_time: 0.0047  time: 1.0955  max mem: 34987
2023-10-30 03:02:11,053 [INFO] Train: data epoch: [4]  [1350/2133]  eta: 0:14:28  lr: 0.000020  loss: 0.3161  data_time: 0.0052  time: 1.0749  max mem: 34987
2023-10-30 03:03:04,924 [INFO] Train: data epoch: [4]  [1400/2133]  eta: 0:13:31  lr: 0.000020  loss: 0.3599  data_time: 0.0046  time: 1.0778  max mem: 34987
2023-10-30 03:03:59,031 [INFO] Train: data epoch: [4]  [1450/2133]  eta: 0:12:35  lr: 0.000020  loss: 0.2956  data_time: 0.0049  time: 1.0834  max mem: 34987
2023-10-30 03:04:53,105 [INFO] Train: data epoch: [4]  [1500/2133]  eta: 0:11:39  lr: 0.000020  loss: 0.2818  data_time: 0.0040  time: 1.0787  max mem: 34987
2023-10-30 03:05:47,070 [INFO] Train: data epoch: [4]  [1550/2133]  eta: 0:10:44  lr: 0.000020  loss: 0.2833  data_time: 0.0049  time: 1.0815  max mem: 34987
2023-10-30 03:06:41,138 [INFO] Train: data epoch: [4]  [1600/2133]  eta: 0:09:48  lr: 0.000020  loss: 0.2764  data_time: 0.0050  time: 1.0802  max mem: 34987
2023-10-30 03:07:36,582 [INFO] Train: data epoch: [4]  [1650/2133]  eta: 0:08:53  lr: 0.000020  loss: 0.2497  data_time: 0.0044  time: 1.0890  max mem: 34987
2023-10-30 03:08:30,797 [INFO] Train: data epoch: [4]  [1700/2133]  eta: 0:07:57  lr: 0.000020  loss: 0.3051  data_time: 0.0047  time: 1.0824  max mem: 34987
2023-10-30 03:09:24,964 [INFO] Train: data epoch: [4]  [1750/2133]  eta: 0:07:02  lr: 0.000020  loss: 0.3377  data_time: 0.0045  time: 1.0794  max mem: 34987
2023-10-30 03:10:19,155 [INFO] Train: data epoch: [4]  [1800/2133]  eta: 0:06:07  lr: 0.000020  loss: 0.2826  data_time: 0.0046  time: 1.0874  max mem: 34987
2023-10-30 03:11:13,096 [INFO] Train: data epoch: [4]  [1850/2133]  eta: 0:05:11  lr: 0.000020  loss: 0.3717  data_time: 0.0046  time: 1.0801  max mem: 34987
2023-10-30 03:12:07,337 [INFO] Train: data epoch: [4]  [1900/2133]  eta: 0:04:16  lr: 0.000020  loss: 0.3308  data_time: 0.0049  time: 1.0854  max mem: 34987
2023-10-30 03:13:01,343 [INFO] Train: data epoch: [4]  [1950/2133]  eta: 0:03:21  lr: 0.000020  loss: 0.3016  data_time: 0.0045  time: 1.0789  max mem: 34987
2023-10-30 03:13:55,602 [INFO] Train: data epoch: [4]  [2000/2133]  eta: 0:02:26  lr: 0.000020  loss: 0.3512  data_time: 0.0046  time: 1.0855  max mem: 34987
2023-10-30 03:14:49,432 [INFO] Train: data epoch: [4]  [2050/2133]  eta: 0:01:31  lr: 0.000020  loss: 0.3262  data_time: 0.0047  time: 1.0796  max mem: 34987
2023-10-30 03:15:43,424 [INFO] Train: data epoch: [4]  [2100/2133]  eta: 0:00:36  lr: 0.000020  loss: 0.3020  data_time: 0.0049  time: 1.0769  max mem: 34987
2023-10-30 03:16:18,027 [INFO] Train: data epoch: [4]  [2132/2133]  eta: 0:00:01  lr: 0.000020  loss: 0.3240  data_time: 0.0175  time: 1.0799  max mem: 34987
2023-10-30 03:16:18,037 [INFO] Averaged stats: lr: 0.0000  loss: 0.3062  data_time: 0.0101
2023-10-30 03:16:18,046 [INFO] Evaluating on val.
2023-10-30 03:16:41,969 [INFO] Evaluation  [  0/625]  eta: 4:08:55    time: 23.8968  max mem: 34987
2023-10-30 03:17:13,718 [INFO] Evaluation  [ 10/625]  eta: 0:51:50    time: 5.0585  max mem: 34987
2023-10-30 03:17:42,465 [INFO] Evaluation  [ 20/625]  eta: 0:40:31    time: 3.0246  max mem: 34987
2023-10-30 03:18:08,355 [INFO] Evaluation  [ 30/625]  eta: 0:35:16    time: 2.7317  max mem: 34987
2023-10-30 03:18:34,678 [INFO] Evaluation  [ 40/625]  eta: 0:32:29    time: 2.6105  max mem: 34987
2023-10-30 03:19:00,571 [INFO] Evaluation  [ 50/625]  eta: 0:30:32    time: 2.6107  max mem: 34987
2023-10-30 03:19:26,583 [INFO] Evaluation  [ 60/625]  eta: 0:29:05    time: 2.5951  max mem: 34987
2023-10-30 03:19:52,998 [INFO] Evaluation  [ 70/625]  eta: 0:27:59    time: 2.6212  max mem: 34987
2023-10-30 03:20:19,079 [INFO] Evaluation  [ 80/625]  eta: 0:27:01    time: 2.6246  max mem: 34987
2023-10-30 03:20:45,076 [INFO] Evaluation  [ 90/625]  eta: 0:26:09    time: 2.6037  max mem: 34987
2023-10-30 03:21:10,997 [INFO] Evaluation  [100/625]  eta: 0:25:22    time: 2.5958  max mem: 34987
2023-10-30 03:21:37,182 [INFO] Evaluation  [110/625]  eta: 0:24:40    time: 2.6052  max mem: 34987
2023-10-30 03:22:03,166 [INFO] Evaluation  [120/625]  eta: 0:24:00    time: 2.6083  max mem: 34987
2023-10-30 03:22:28,839 [INFO] Evaluation  [130/625]  eta: 0:23:20    time: 2.5827  max mem: 34987
2023-10-30 03:22:54,436 [INFO] Evaluation  [140/625]  eta: 0:22:43    time: 2.5633  max mem: 34987
2023-10-30 03:23:20,291 [INFO] Evaluation  [150/625]  eta: 0:22:08    time: 2.5724  max mem: 34987
2023-10-30 03:23:46,297 [INFO] Evaluation  [160/625]  eta: 0:21:34    time: 2.5929  max mem: 34987
2023-10-30 03:24:12,023 [INFO] Evaluation  [170/625]  eta: 0:21:01    time: 2.5865  max mem: 34987
2023-10-30 03:24:38,259 [INFO] Evaluation  [180/625]  eta: 0:20:29    time: 2.5979  max mem: 34987
2023-10-30 03:25:04,253 [INFO] Evaluation  [190/625]  eta: 0:19:58    time: 2.6113  max mem: 34987
2023-10-30 03:25:30,233 [INFO] Evaluation  [200/625]  eta: 0:19:27    time: 2.5985  max mem: 34987
2023-10-30 03:25:56,055 [INFO] Evaluation  [210/625]  eta: 0:18:56    time: 2.5899  max mem: 34987
2023-10-30 03:26:22,152 [INFO] Evaluation  [220/625]  eta: 0:18:26    time: 2.5958  max mem: 34987
2023-10-30 03:26:48,430 [INFO] Evaluation  [230/625]  eta: 0:17:57    time: 2.6186  max mem: 34987
2023-10-30 03:27:14,350 [INFO] Evaluation  [240/625]  eta: 0:17:28    time: 2.6097  max mem: 34987
2023-10-30 03:27:40,600 [INFO] Evaluation  [250/625]  eta: 0:16:59    time: 2.6082  max mem: 34987
2023-10-30 03:28:06,934 [INFO] Evaluation  [260/625]  eta: 0:16:31    time: 2.6289  max mem: 34987
2023-10-30 03:28:32,728 [INFO] Evaluation  [270/625]  eta: 0:16:02    time: 2.6062  max mem: 34987
2023-10-30 03:28:58,484 [INFO] Evaluation  [280/625]  eta: 0:15:33    time: 2.5773  max mem: 34987
2023-10-30 03:29:24,407 [INFO] Evaluation  [290/625]  eta: 0:15:05    time: 2.5838  max mem: 34987
2023-10-30 03:29:50,203 [INFO] Evaluation  [300/625]  eta: 0:14:36    time: 2.5858  max mem: 34987
2023-10-30 03:30:20,497 [INFO] Evaluation  [310/625]  eta: 0:14:13    time: 2.8040  max mem: 34987
2023-10-30 03:30:46,314 [INFO] Evaluation  [320/625]  eta: 0:13:44    time: 2.8048  max mem: 34987
2023-10-30 03:31:12,326 [INFO] Evaluation  [330/625]  eta: 0:13:16    time: 2.5911  max mem: 34987
2023-10-30 03:31:38,348 [INFO] Evaluation  [340/625]  eta: 0:12:49    time: 2.6015  max mem: 34987
2023-10-30 03:32:04,858 [INFO] Evaluation  [350/625]  eta: 0:12:21    time: 2.6263  max mem: 34987
2023-10-30 03:32:30,809 [INFO] Evaluation  [360/625]  eta: 0:11:54    time: 2.6227  max mem: 34987
2023-10-30 03:32:57,163 [INFO] Evaluation  [370/625]  eta: 0:11:26    time: 2.6150  max mem: 34987
2023-10-30 03:33:22,919 [INFO] Evaluation  [380/625]  eta: 0:10:58    time: 2.6052  max mem: 34987
2023-10-30 03:33:48,810 [INFO] Evaluation  [390/625]  eta: 0:10:31    time: 2.5822  max mem: 34987
2023-10-30 03:34:14,663 [INFO] Evaluation  [400/625]  eta: 0:10:04    time: 2.5870  max mem: 34987
2023-10-30 03:34:40,549 [INFO] Evaluation  [410/625]  eta: 0:09:36    time: 2.5868  max mem: 34987
2023-10-30 03:35:06,832 [INFO] Evaluation  [420/625]  eta: 0:09:09    time: 2.6081  max mem: 34987
2023-10-30 03:35:32,835 [INFO] Evaluation  [430/625]  eta: 0:08:42    time: 2.6140  max mem: 34987
2023-10-30 03:35:59,197 [INFO] Evaluation  [440/625]  eta: 0:08:15    time: 2.6180  max mem: 34987
2023-10-30 03:36:25,178 [INFO] Evaluation  [450/625]  eta: 0:07:48    time: 2.6169  max mem: 34987
2023-10-30 03:36:51,083 [INFO] Evaluation  [460/625]  eta: 0:07:21    time: 2.5941  max mem: 34987
2023-10-30 03:37:16,905 [INFO] Evaluation  [470/625]  eta: 0:06:54    time: 2.5862  max mem: 34987
2023-10-30 03:37:42,832 [INFO] Evaluation  [480/625]  eta: 0:06:27    time: 2.5873  max mem: 34987
2023-10-30 03:38:09,079 [INFO] Evaluation  [490/625]  eta: 0:06:00    time: 2.6085  max mem: 34987
2023-10-30 03:38:35,531 [INFO] Evaluation  [500/625]  eta: 0:05:33    time: 2.6348  max mem: 34987
2023-10-30 03:39:02,943 [INFO] Evaluation  [510/625]  eta: 0:05:07    time: 2.6930  max mem: 34987
2023-10-30 03:39:29,290 [INFO] Evaluation  [520/625]  eta: 0:04:40    time: 2.6878  max mem: 34987
2023-10-30 03:39:56,180 [INFO] Evaluation  [530/625]  eta: 0:04:13    time: 2.6609  max mem: 34987
2023-10-30 03:40:22,599 [INFO] Evaluation  [540/625]  eta: 0:03:46    time: 2.6644  max mem: 34987
2023-10-30 03:40:49,082 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.6448  max mem: 34987
2023-10-30 03:41:15,033 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.6214  max mem: 34987
2023-10-30 03:41:41,159 [INFO] Evaluation  [570/625]  eta: 0:02:26    time: 2.6035  max mem: 34987
2023-10-30 03:42:09,282 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.7121  max mem: 34987
2023-10-30 03:42:35,024 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.6929  max mem: 34987
2023-10-30 03:43:01,112 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5913  max mem: 34987
2023-10-30 03:43:26,879 [INFO] Evaluation  [610/625]  eta: 0:00:39    time: 2.5925  max mem: 34987
2023-10-30 03:43:52,442 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5663  max mem: 34987
2023-10-30 03:44:01,874 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5245  max mem: 34987
2023-10-30 03:44:01,933 [WARNING] rank 0 starts merging results.
2023-10-30 03:44:02,150 [INFO] {'agg_metrics': 0.638310648518815, 'total': 4996, 'CH': 62.3718887262079, 'CW': 62.11018711018711, 'TN': 56.31284916201117, 'TC': 67.42081447963801, 'DL': 87.11864406779661, 'DC': 50.282485875706215, 'DO': 76.72131147540983, 'TP': 68.51851851851852}
2023-10-30 03:44:02,152 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_3.pth.
2023-10-30 03:44:02,288 [INFO] Saving checkpoint at epoch 4 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_4.pth.
2023-10-30 03:44:04,146 [INFO] Start training
2023-10-30 03:44:04,182 [INFO] Start training epoch 5, 2133 iters per inner epoch.
2023-10-30 03:44:15,971 [INFO] Train: data epoch: [5]  [   0/2133]  eta: 6:59:03  lr: 0.000015  loss: 0.3396  data_time: 9.5741  time: 11.7880  max mem: 34987
2023-10-30 03:45:14,066 [INFO] Train: data epoch: [5]  [  50/2133]  eta: 0:47:34  lr: 0.000015  loss: 0.3549  data_time: 0.0048  time: 1.1043  max mem: 34987
2023-10-30 03:46:07,977 [INFO] Train: data epoch: [5]  [ 100/2133]  eta: 0:41:31  lr: 0.000015  loss: 0.3389  data_time: 0.0058  time: 1.0810  max mem: 34987
2023-10-30 03:47:01,950 [INFO] Train: data epoch: [5]  [ 150/2133]  eta: 0:38:54  lr: 0.000015  loss: 0.3432  data_time: 0.0053  time: 1.0821  max mem: 34987
2023-10-30 03:47:56,101 [INFO] Train: data epoch: [5]  [ 200/2133]  eta: 0:37:10  lr: 0.000015  loss: 0.3496  data_time: 0.0050  time: 1.0816  max mem: 34987
2023-10-30 03:48:50,243 [INFO] Train: data epoch: [5]  [ 250/2133]  eta: 0:35:45  lr: 0.000015  loss: 0.3326  data_time: 0.0050  time: 1.0808  max mem: 34987
2023-10-30 03:49:46,654 [INFO] Train: data epoch: [5]  [ 300/2133]  eta: 0:34:45  lr: 0.000015  loss: 0.2750  data_time: 0.0051  time: 1.0787  max mem: 34987
2023-10-30 03:50:40,659 [INFO] Train: data epoch: [5]  [ 350/2133]  eta: 0:33:33  lr: 0.000015  loss: 0.2776  data_time: 0.0049  time: 1.0805  max mem: 34987
2023-10-30 03:51:39,517 [INFO] Train: data epoch: [5]  [ 400/2133]  eta: 0:32:47  lr: 0.000015  loss: 0.3171  data_time: 0.0050  time: 1.0798  max mem: 34987
2023-10-30 03:52:40,023 [INFO] Train: data epoch: [5]  [ 450/2133]  eta: 0:32:04  lr: 0.000015  loss: 0.3544  data_time: 0.0049  time: 1.0716  max mem: 34987
2023-10-30 03:53:37,254 [INFO] Train: data epoch: [5]  [ 500/2133]  eta: 0:31:07  lr: 0.000015  loss: 0.3084  data_time: 0.0054  time: 1.0800  max mem: 34987
2023-10-30 03:54:31,069 [INFO] Train: data epoch: [5]  [ 550/2133]  eta: 0:30:00  lr: 0.000015  loss: 0.2846  data_time: 0.0048  time: 1.0786  max mem: 34987
2023-10-30 03:55:24,921 [INFO] Train: data epoch: [5]  [ 600/2133]  eta: 0:28:56  lr: 0.000015  loss: 0.3423  data_time: 0.0043  time: 1.0759  max mem: 34987
2023-10-30 03:56:19,263 [INFO] Train: data epoch: [5]  [ 650/2133]  eta: 0:27:54  lr: 0.000015  loss: 0.2958  data_time: 0.0052  time: 1.0822  max mem: 34987
2023-10-30 03:57:13,536 [INFO] Train: data epoch: [5]  [ 700/2133]  eta: 0:26:53  lr: 0.000015  loss: 0.2718  data_time: 0.0050  time: 1.0869  max mem: 34987
2023-10-30 03:58:07,750 [INFO] Train: data epoch: [5]  [ 750/2133]  eta: 0:25:53  lr: 0.000015  loss: 0.3249  data_time: 0.0050  time: 1.0852  max mem: 34987
2023-10-30 03:59:01,993 [INFO] Train: data epoch: [5]  [ 800/2133]  eta: 0:24:54  lr: 0.000015  loss: 0.2979  data_time: 0.0043  time: 1.0915  max mem: 34987
2023-10-30 03:59:56,242 [INFO] Train: data epoch: [5]  [ 850/2133]  eta: 0:23:55  lr: 0.000015  loss: 0.2284  data_time: 0.0044  time: 1.0925  max mem: 34987
2023-10-30 04:00:50,033 [INFO] Train: data epoch: [5]  [ 900/2133]  eta: 0:22:56  lr: 0.000015  loss: 0.2631  data_time: 0.0049  time: 1.0708  max mem: 34987
2023-10-30 04:01:44,023 [INFO] Train: data epoch: [5]  [ 950/2133]  eta: 0:21:58  lr: 0.000015  loss: 0.2653  data_time: 0.0048  time: 1.0808  max mem: 34987
2023-10-30 04:02:38,219 [INFO] Train: data epoch: [5]  [1000/2133]  eta: 0:21:00  lr: 0.000015  loss: 0.3159  data_time: 0.0048  time: 1.0879  max mem: 34987
2023-10-30 04:03:32,118 [INFO] Train: data epoch: [5]  [1050/2133]  eta: 0:20:03  lr: 0.000015  loss: 0.3083  data_time: 0.0047  time: 1.0739  max mem: 34987
2023-10-30 04:04:26,177 [INFO] Train: data epoch: [5]  [1100/2133]  eta: 0:19:06  lr: 0.000015  loss: 0.3251  data_time: 0.0051  time: 1.0821  max mem: 34987
2023-10-30 04:05:20,287 [INFO] Train: data epoch: [5]  [1150/2133]  eta: 0:18:09  lr: 0.000015  loss: 0.2382  data_time: 0.0052  time: 1.0758  max mem: 34987
2023-10-30 04:06:15,748 [INFO] Train: data epoch: [5]  [1200/2133]  eta: 0:17:14  lr: 0.000015  loss: 0.2728  data_time: 0.0046  time: 1.1468  max mem: 34987
2023-10-30 04:07:09,789 [INFO] Train: data epoch: [5]  [1250/2133]  eta: 0:16:17  lr: 0.000015  loss: 0.2942  data_time: 0.0048  time: 1.0832  max mem: 34987
2023-10-30 04:08:03,938 [INFO] Train: data epoch: [5]  [1300/2133]  eta: 0:15:21  lr: 0.000015  loss: 0.3463  data_time: 0.0054  time: 1.0834  max mem: 34987
2023-10-30 04:08:58,193 [INFO] Train: data epoch: [5]  [1350/2133]  eta: 0:14:25  lr: 0.000015  loss: 0.3160  data_time: 0.0048  time: 1.0859  max mem: 34987
2023-10-30 04:09:52,241 [INFO] Train: data epoch: [5]  [1400/2133]  eta: 0:13:29  lr: 0.000015  loss: 0.3467  data_time: 0.0048  time: 1.0794  max mem: 34987
2023-10-30 04:10:46,303 [INFO] Train: data epoch: [5]  [1450/2133]  eta: 0:12:34  lr: 0.000015  loss: 0.2606  data_time: 0.0048  time: 1.0801  max mem: 34987
2023-10-30 04:11:40,489 [INFO] Train: data epoch: [5]  [1500/2133]  eta: 0:11:38  lr: 0.000015  loss: 0.3007  data_time: 0.0055  time: 1.0768  max mem: 34987
2023-10-30 04:12:34,894 [INFO] Train: data epoch: [5]  [1550/2133]  eta: 0:10:43  lr: 0.000015  loss: 0.2965  data_time: 0.0042  time: 1.1001  max mem: 34987
2023-10-30 04:13:28,981 [INFO] Train: data epoch: [5]  [1600/2133]  eta: 0:09:47  lr: 0.000015  loss: 0.2857  data_time: 0.0051  time: 1.0807  max mem: 34987
2023-10-30 04:14:23,134 [INFO] Train: data epoch: [5]  [1650/2133]  eta: 0:08:52  lr: 0.000015  loss: 0.2643  data_time: 0.0054  time: 1.0761  max mem: 34987
2023-10-30 04:15:17,172 [INFO] Train: data epoch: [5]  [1700/2133]  eta: 0:07:56  lr: 0.000015  loss: 0.3366  data_time: 0.0050  time: 1.0826  max mem: 34987
2023-10-30 04:16:11,268 [INFO] Train: data epoch: [5]  [1750/2133]  eta: 0:07:01  lr: 0.000015  loss: 0.2471  data_time: 0.0052  time: 1.0789  max mem: 34987
2023-10-30 04:17:05,650 [INFO] Train: data epoch: [5]  [1800/2133]  eta: 0:06:06  lr: 0.000015  loss: 0.3107  data_time: 0.0047  time: 1.0908  max mem: 34987
2023-10-30 04:17:59,681 [INFO] Train: data epoch: [5]  [1850/2133]  eta: 0:05:11  lr: 0.000015  loss: 0.3125  data_time: 0.0051  time: 1.0769  max mem: 34987
2023-10-30 04:18:53,800 [INFO] Train: data epoch: [5]  [1900/2133]  eta: 0:04:16  lr: 0.000015  loss: 0.2881  data_time: 0.0050  time: 1.0811  max mem: 34987
2023-10-30 04:19:48,040 [INFO] Train: data epoch: [5]  [1950/2133]  eta: 0:03:21  lr: 0.000015  loss: 0.2605  data_time: 0.0047  time: 1.0787  max mem: 34987
2023-10-30 04:20:42,158 [INFO] Train: data epoch: [5]  [2000/2133]  eta: 0:02:26  lr: 0.000015  loss: 0.2696  data_time: 0.0041  time: 1.0795  max mem: 34987
2023-10-30 04:21:36,587 [INFO] Train: data epoch: [5]  [2050/2133]  eta: 0:01:31  lr: 0.000015  loss: 0.3534  data_time: 0.0051  time: 1.0844  max mem: 34987
2023-10-30 04:22:30,657 [INFO] Train: data epoch: [5]  [2100/2133]  eta: 0:00:36  lr: 0.000015  loss: 0.3122  data_time: 0.0046  time: 1.0752  max mem: 34987
2023-10-30 04:23:05,215 [INFO] Train: data epoch: [5]  [2132/2133]  eta: 0:00:01  lr: 0.000015  loss: 0.3515  data_time: 0.0173  time: 1.0789  max mem: 34987
2023-10-30 04:23:05,225 [INFO] Averaged stats: lr: 0.0000  loss: 0.3031  data_time: 0.0095
2023-10-30 04:23:05,235 [INFO] Evaluating on val.
2023-10-30 04:23:29,458 [INFO] Evaluation  [  0/625]  eta: 4:12:03    time: 24.1971  max mem: 34987
2023-10-30 04:23:59,064 [INFO] Evaluation  [ 10/625]  eta: 0:50:07    time: 4.8910  max mem: 34987
2023-10-30 04:24:28,549 [INFO] Evaluation  [ 20/625]  eta: 0:39:59    time: 2.9543  max mem: 34987
2023-10-30 04:24:54,933 [INFO] Evaluation  [ 30/625]  eta: 0:35:04    time: 2.7932  max mem: 34987
2023-10-30 04:25:21,124 [INFO] Evaluation  [ 40/625]  eta: 0:32:18    time: 2.6286  max mem: 34987
2023-10-30 04:25:46,909 [INFO] Evaluation  [ 50/625]  eta: 0:30:22    time: 2.5986  max mem: 34987
2023-10-30 04:26:13,004 [INFO] Evaluation  [ 60/625]  eta: 0:28:58    time: 2.5938  max mem: 34987
2023-10-30 04:26:39,164 [INFO] Evaluation  [ 70/625]  eta: 0:27:51    time: 2.6125  max mem: 34987
2023-10-30 04:27:05,303 [INFO] Evaluation  [ 80/625]  eta: 0:26:54    time: 2.6147  max mem: 34987
2023-10-30 04:27:31,353 [INFO] Evaluation  [ 90/625]  eta: 0:26:04    time: 2.6093  max mem: 34987
2023-10-30 04:27:57,369 [INFO] Evaluation  [100/625]  eta: 0:25:18    time: 2.6031  max mem: 34987
2023-10-30 04:28:23,447 [INFO] Evaluation  [110/625]  eta: 0:24:36    time: 2.6045  max mem: 34987
2023-10-30 04:28:49,530 [INFO] Evaluation  [120/625]  eta: 0:23:56    time: 2.6079  max mem: 34987
2023-10-30 04:29:19,448 [INFO] Evaluation  [130/625]  eta: 0:23:33    time: 2.7997  max mem: 34987
2023-10-30 04:29:44,939 [INFO] Evaluation  [140/625]  eta: 0:22:54    time: 2.7700  max mem: 34987
2023-10-30 04:30:10,783 [INFO] Evaluation  [150/625]  eta: 0:22:18    time: 2.5663  max mem: 34987
2023-10-30 04:30:36,692 [INFO] Evaluation  [160/625]  eta: 0:21:43    time: 2.5869  max mem: 34987
2023-10-30 04:31:02,523 [INFO] Evaluation  [170/625]  eta: 0:21:09    time: 2.5865  max mem: 34987
2023-10-30 04:31:28,811 [INFO] Evaluation  [180/625]  eta: 0:20:37    time: 2.6058  max mem: 34987
2023-10-30 04:31:54,847 [INFO] Evaluation  [190/625]  eta: 0:20:06    time: 2.6160  max mem: 34987
2023-10-30 04:32:20,678 [INFO] Evaluation  [200/625]  eta: 0:19:34    time: 2.5931  max mem: 34987
2023-10-30 04:32:46,926 [INFO] Evaluation  [210/625]  eta: 0:19:03    time: 2.6037  max mem: 34987
2023-10-30 04:33:13,365 [INFO] Evaluation  [220/625]  eta: 0:18:34    time: 2.6341  max mem: 34987
2023-10-30 04:33:39,643 [INFO] Evaluation  [230/625]  eta: 0:18:04    time: 2.6356  max mem: 34987
2023-10-30 04:34:05,494 [INFO] Evaluation  [240/625]  eta: 0:17:34    time: 2.6063  max mem: 34987
2023-10-30 04:34:31,546 [INFO] Evaluation  [250/625]  eta: 0:17:05    time: 2.5950  max mem: 34987
2023-10-30 04:34:57,650 [INFO] Evaluation  [260/625]  eta: 0:16:36    time: 2.6075  max mem: 34987
2023-10-30 04:35:23,441 [INFO] Evaluation  [270/625]  eta: 0:16:06    time: 2.5944  max mem: 34987
2023-10-30 04:35:49,290 [INFO] Evaluation  [280/625]  eta: 0:15:37    time: 2.5818  max mem: 34987
2023-10-30 04:36:15,345 [INFO] Evaluation  [290/625]  eta: 0:15:09    time: 2.5950  max mem: 34987
2023-10-30 04:36:41,022 [INFO] Evaluation  [300/625]  eta: 0:14:40    time: 2.5864  max mem: 34987
2023-10-30 04:37:07,413 [INFO] Evaluation  [310/625]  eta: 0:14:12    time: 2.6032  max mem: 34987
2023-10-30 04:37:33,395 [INFO] Evaluation  [320/625]  eta: 0:13:44    time: 2.6185  max mem: 34987
2023-10-30 04:38:00,637 [INFO] Evaluation  [330/625]  eta: 0:13:17    time: 2.6609  max mem: 34987
2023-10-30 04:38:26,542 [INFO] Evaluation  [340/625]  eta: 0:12:49    time: 2.6571  max mem: 34987
2023-10-30 04:38:52,869 [INFO] Evaluation  [350/625]  eta: 0:12:22    time: 2.6114  max mem: 34987
2023-10-30 04:39:20,049 [INFO] Evaluation  [360/625]  eta: 0:11:55    time: 2.6751  max mem: 34987
2023-10-30 04:39:46,384 [INFO] Evaluation  [370/625]  eta: 0:11:28    time: 2.6754  max mem: 34987
2023-10-30 04:40:12,122 [INFO] Evaluation  [380/625]  eta: 0:11:00    time: 2.6034  max mem: 34987
2023-10-30 04:40:37,967 [INFO] Evaluation  [390/625]  eta: 0:10:32    time: 2.5790  max mem: 34987
2023-10-30 04:41:06,749 [INFO] Evaluation  [400/625]  eta: 0:10:06    time: 2.7309  max mem: 34987
2023-10-30 04:41:32,493 [INFO] Evaluation  [410/625]  eta: 0:09:39    time: 2.7258  max mem: 34987
2023-10-30 04:41:58,769 [INFO] Evaluation  [420/625]  eta: 0:09:11    time: 2.6007  max mem: 34987
2023-10-30 04:42:24,663 [INFO] Evaluation  [430/625]  eta: 0:08:44    time: 2.6083  max mem: 34987
2023-10-30 04:42:50,952 [INFO] Evaluation  [440/625]  eta: 0:08:17    time: 2.6090  max mem: 34987
2023-10-30 04:43:17,209 [INFO] Evaluation  [450/625]  eta: 0:07:50    time: 2.6271  max mem: 34987
2023-10-30 04:43:43,053 [INFO] Evaluation  [460/625]  eta: 0:07:22    time: 2.6049  max mem: 34987
2023-10-30 04:44:08,776 [INFO] Evaluation  [470/625]  eta: 0:06:55    time: 2.5782  max mem: 34987
2023-10-30 04:44:34,608 [INFO] Evaluation  [480/625]  eta: 0:06:28    time: 2.5776  max mem: 34987
2023-10-30 04:45:01,386 [INFO] Evaluation  [490/625]  eta: 0:06:01    time: 2.6303  max mem: 34987
2023-10-30 04:45:27,742 [INFO] Evaluation  [500/625]  eta: 0:05:34    time: 2.6565  max mem: 34987
2023-10-30 04:45:53,648 [INFO] Evaluation  [510/625]  eta: 0:05:07    time: 2.6129  max mem: 34987
2023-10-30 04:46:19,885 [INFO] Evaluation  [520/625]  eta: 0:04:41    time: 2.6070  max mem: 34987
2023-10-30 04:46:45,630 [INFO] Evaluation  [530/625]  eta: 0:04:14    time: 2.5989  max mem: 34987
2023-10-30 04:47:12,035 [INFO] Evaluation  [540/625]  eta: 0:03:47    time: 2.6073  max mem: 34987
2023-10-30 04:47:38,458 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.6412  max mem: 34987
2023-10-30 04:48:04,263 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.6113  max mem: 34987
2023-10-30 04:48:30,346 [INFO] Evaluation  [570/625]  eta: 0:02:26    time: 2.5942  max mem: 34987
2023-10-30 04:48:57,670 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6698  max mem: 34987
2023-10-30 04:49:23,580 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.6602  max mem: 34987
2023-10-30 04:49:49,522 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5915  max mem: 34987
2023-10-30 04:50:15,227 [INFO] Evaluation  [610/625]  eta: 0:00:40    time: 2.5822  max mem: 34987
2023-10-30 04:50:40,855 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5665  max mem: 34987
2023-10-30 04:50:50,263 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5244  max mem: 34987
2023-10-30 04:50:50,323 [WARNING] rank 0 starts merging results.
2023-10-30 04:50:50,374 [INFO] {'agg_metrics': 0.6343074459567654, 'total': 4996, 'CH': 62.811127379209374, 'CW': 61.590436590436596, 'TN': 55.977653631284916, 'TC': 67.11915535444946, 'DL': 86.77966101694915, 'DC': 49.717514124293785, 'DO': 74.75409836065575, 'TP': 68.51851851851852}
2023-10-30 04:50:50,376 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_4.pth.
2023-10-30 04:50:50,511 [INFO] Saving checkpoint at epoch 5 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_5.pth.
2023-10-30 04:50:52,385 [INFO] Start training
2023-10-30 04:50:52,426 [INFO] Start training epoch 6, 2133 iters per inner epoch.
2023-10-30 04:51:10,550 [INFO] Train: data epoch: [6]  [   0/2133]  eta: 10:44:12  lr: 0.000010  loss: 0.2382  data_time: 15.9463  time: 18.1211  max mem: 34987
2023-10-30 04:52:14,131 [INFO] Train: data epoch: [6]  [  50/2133]  eta: 0:55:36  lr: 0.000010  loss: 0.3032  data_time: 0.0055  time: 1.4512  max mem: 34987
2023-10-30 04:53:11,247 [INFO] Train: data epoch: [6]  [ 100/2133]  eta: 0:46:34  lr: 0.000010  loss: 0.3331  data_time: 0.0049  time: 1.2434  max mem: 34987
2023-10-30 04:54:05,041 [INFO] Train: data epoch: [6]  [ 150/2133]  eta: 0:42:09  lr: 0.000010  loss: 0.2980  data_time: 0.0046  time: 1.0757  max mem: 34987
2023-10-30 04:54:59,245 [INFO] Train: data epoch: [6]  [ 200/2133]  eta: 0:39:33  lr: 0.000010  loss: 0.3111  data_time: 0.0055  time: 1.0869  max mem: 34987
2023-10-30 04:55:53,523 [INFO] Train: data epoch: [6]  [ 250/2133]  eta: 0:37:38  lr: 0.000010  loss: 0.2563  data_time: 0.0049  time: 1.0849  max mem: 34987
2023-10-30 04:56:47,908 [INFO] Train: data epoch: [6]  [ 300/2133]  eta: 0:36:04  lr: 0.000010  loss: 0.3285  data_time: 0.0046  time: 1.0899  max mem: 34987
2023-10-30 04:57:42,463 [INFO] Train: data epoch: [6]  [ 350/2133]  eta: 0:34:42  lr: 0.000010  loss: 0.3155  data_time: 0.0044  time: 1.0869  max mem: 34987
2023-10-30 04:58:36,523 [INFO] Train: data epoch: [6]  [ 400/2133]  eta: 0:33:25  lr: 0.000010  loss: 0.3171  data_time: 0.0044  time: 1.0820  max mem: 34987
2023-10-30 04:59:30,804 [INFO] Train: data epoch: [6]  [ 450/2133]  eta: 0:32:14  lr: 0.000010  loss: 0.3335  data_time: 0.0052  time: 1.0834  max mem: 34987
2023-10-30 05:00:24,857 [INFO] Train: data epoch: [6]  [ 500/2133]  eta: 0:31:05  lr: 0.000010  loss: 0.3115  data_time: 0.0040  time: 1.0840  max mem: 34987
2023-10-30 05:01:18,900 [INFO] Train: data epoch: [6]  [ 550/2133]  eta: 0:29:59  lr: 0.000010  loss: 0.2523  data_time: 0.0047  time: 1.0786  max mem: 34987
2023-10-30 05:02:13,123 [INFO] Train: data epoch: [6]  [ 600/2133]  eta: 0:28:56  lr: 0.000010  loss: 0.2934  data_time: 0.0052  time: 1.0856  max mem: 34987
2023-10-30 05:03:07,366 [INFO] Train: data epoch: [6]  [ 650/2133]  eta: 0:27:54  lr: 0.000010  loss: 0.3229  data_time: 0.0040  time: 1.0866  max mem: 34987
2023-10-30 05:04:01,417 [INFO] Train: data epoch: [6]  [ 700/2133]  eta: 0:26:52  lr: 0.000010  loss: 0.2993  data_time: 0.0046  time: 1.0811  max mem: 34987
2023-10-30 05:04:55,362 [INFO] Train: data epoch: [6]  [ 750/2133]  eta: 0:25:52  lr: 0.000010  loss: 0.2906  data_time: 0.0046  time: 1.0789  max mem: 34987
2023-10-30 05:05:50,751 [INFO] Train: data epoch: [6]  [ 800/2133]  eta: 0:24:54  lr: 0.000010  loss: 0.2646  data_time: 0.0046  time: 1.0874  max mem: 34987
2023-10-30 05:06:44,837 [INFO] Train: data epoch: [6]  [ 850/2133]  eta: 0:23:55  lr: 0.000010  loss: 0.2533  data_time: 0.0049  time: 1.0794  max mem: 34987
2023-10-30 05:07:38,966 [INFO] Train: data epoch: [6]  [ 900/2133]  eta: 0:22:57  lr: 0.000010  loss: 0.3334  data_time: 0.0042  time: 1.0821  max mem: 34987
2023-10-30 05:08:32,936 [INFO] Train: data epoch: [6]  [ 950/2133]  eta: 0:21:59  lr: 0.000010  loss: 0.2944  data_time: 0.0045  time: 1.0782  max mem: 34987
2023-10-30 05:09:27,214 [INFO] Train: data epoch: [6]  [1000/2133]  eta: 0:21:01  lr: 0.000010  loss: 0.3311  data_time: 0.0046  time: 1.0858  max mem: 34987
2023-10-30 05:10:21,373 [INFO] Train: data epoch: [6]  [1050/2133]  eta: 0:20:04  lr: 0.000010  loss: 0.2697  data_time: 0.0043  time: 1.0861  max mem: 34987
2023-10-30 05:11:15,483 [INFO] Train: data epoch: [6]  [1100/2133]  eta: 0:19:07  lr: 0.000010  loss: 0.3151  data_time: 0.0051  time: 1.0794  max mem: 34987
2023-10-30 05:12:09,413 [INFO] Train: data epoch: [6]  [1150/2133]  eta: 0:18:10  lr: 0.000010  loss: 0.3218  data_time: 0.0052  time: 1.0854  max mem: 34987
2023-10-30 05:13:03,478 [INFO] Train: data epoch: [6]  [1200/2133]  eta: 0:17:13  lr: 0.000010  loss: 0.3851  data_time: 0.0045  time: 1.0780  max mem: 34987
2023-10-30 05:13:57,607 [INFO] Train: data epoch: [6]  [1250/2133]  eta: 0:16:17  lr: 0.000010  loss: 0.2458  data_time: 0.0048  time: 1.0856  max mem: 34987
2023-10-30 05:14:51,451 [INFO] Train: data epoch: [6]  [1300/2133]  eta: 0:15:21  lr: 0.000010  loss: 0.3105  data_time: 0.0048  time: 1.0716  max mem: 34987
2023-10-30 05:15:45,656 [INFO] Train: data epoch: [6]  [1350/2133]  eta: 0:14:25  lr: 0.000010  loss: 0.3111  data_time: 0.0044  time: 1.0772  max mem: 34987
2023-10-30 05:16:39,493 [INFO] Train: data epoch: [6]  [1400/2133]  eta: 0:13:29  lr: 0.000010  loss: 0.3181  data_time: 0.0052  time: 1.0746  max mem: 34987
2023-10-30 05:17:33,361 [INFO] Train: data epoch: [6]  [1450/2133]  eta: 0:12:33  lr: 0.000010  loss: 0.2935  data_time: 0.0048  time: 1.0761  max mem: 34987
2023-10-30 05:18:27,320 [INFO] Train: data epoch: [6]  [1500/2133]  eta: 0:11:37  lr: 0.000010  loss: 0.4038  data_time: 0.0052  time: 1.0830  max mem: 34987
2023-10-30 05:19:21,599 [INFO] Train: data epoch: [6]  [1550/2133]  eta: 0:10:42  lr: 0.000010  loss: 0.2996  data_time: 0.0058  time: 1.0817  max mem: 34987
2023-10-30 05:20:15,674 [INFO] Train: data epoch: [6]  [1600/2133]  eta: 0:09:46  lr: 0.000010  loss: 0.3340  data_time: 0.0044  time: 1.0830  max mem: 34987
2023-10-30 05:21:09,780 [INFO] Train: data epoch: [6]  [1650/2133]  eta: 0:08:51  lr: 0.000010  loss: 0.3219  data_time: 0.0045  time: 1.0847  max mem: 34987
2023-10-30 05:22:03,774 [INFO] Train: data epoch: [6]  [1700/2133]  eta: 0:07:56  lr: 0.000010  loss: 0.2716  data_time: 0.0049  time: 1.0798  max mem: 34987
2023-10-30 05:22:58,175 [INFO] Train: data epoch: [6]  [1750/2133]  eta: 0:07:01  lr: 0.000010  loss: 0.2798  data_time: 0.0051  time: 1.0878  max mem: 34987
2023-10-30 05:23:52,048 [INFO] Train: data epoch: [6]  [1800/2133]  eta: 0:06:06  lr: 0.000010  loss: 0.2151  data_time: 0.0045  time: 1.0793  max mem: 34987
2023-10-30 05:24:46,309 [INFO] Train: data epoch: [6]  [1850/2133]  eta: 0:05:10  lr: 0.000010  loss: 0.3195  data_time: 0.0048  time: 1.0849  max mem: 34987
2023-10-30 05:25:40,753 [INFO] Train: data epoch: [6]  [1900/2133]  eta: 0:04:15  lr: 0.000010  loss: 0.2979  data_time: 0.0051  time: 1.0929  max mem: 34987
2023-10-30 05:26:35,167 [INFO] Train: data epoch: [6]  [1950/2133]  eta: 0:03:20  lr: 0.000010  loss: 0.2996  data_time: 0.0047  time: 1.0872  max mem: 34987
2023-10-30 05:27:29,229 [INFO] Train: data epoch: [6]  [2000/2133]  eta: 0:02:26  lr: 0.000010  loss: 0.2570  data_time: 0.0051  time: 1.0776  max mem: 34987
2023-10-30 05:28:28,918 [INFO] Train: data epoch: [6]  [2050/2133]  eta: 0:01:31  lr: 0.000010  loss: 0.2859  data_time: 0.0049  time: 1.0779  max mem: 34987
2023-10-30 05:29:23,663 [INFO] Train: data epoch: [6]  [2100/2133]  eta: 0:00:36  lr: 0.000010  loss: 0.3830  data_time: 0.0048  time: 1.0821  max mem: 34987
2023-10-30 05:29:58,486 [INFO] Train: data epoch: [6]  [2132/2133]  eta: 0:00:01  lr: 0.000010  loss: 0.2798  data_time: 0.0185  time: 1.0819  max mem: 34987
2023-10-30 05:29:58,498 [INFO] Averaged stats: lr: 0.0000  loss: 0.2995  data_time: 0.0125
2023-10-30 05:29:58,511 [INFO] Evaluating on val.
2023-10-30 05:30:20,156 [INFO] Evaluation  [  0/625]  eta: 3:45:11    time: 21.6188  max mem: 34987
2023-10-30 05:30:52,348 [INFO] Evaluation  [ 10/625]  eta: 0:50:08    time: 4.8916  max mem: 34987
2023-10-30 05:31:20,158 [INFO] Evaluation  [ 20/625]  eta: 0:39:11    time: 2.9997  max mem: 34987
2023-10-30 05:31:46,307 [INFO] Evaluation  [ 30/625]  eta: 0:34:28    time: 2.6976  max mem: 34987
2023-10-30 05:32:12,866 [INFO] Evaluation  [ 40/625]  eta: 0:31:56    time: 2.6353  max mem: 34987
2023-10-30 05:32:38,853 [INFO] Evaluation  [ 50/625]  eta: 0:30:07    time: 2.6271  max mem: 34987
2023-10-30 05:33:04,997 [INFO] Evaluation  [ 60/625]  eta: 0:28:46    time: 2.6063  max mem: 34987
2023-10-30 05:33:31,141 [INFO] Evaluation  [ 70/625]  eta: 0:27:41    time: 2.6143  max mem: 34987
2023-10-30 05:33:57,280 [INFO] Evaluation  [ 80/625]  eta: 0:26:46    time: 2.6139  max mem: 34987
2023-10-30 05:34:23,351 [INFO] Evaluation  [ 90/625]  eta: 0:25:56    time: 2.6102  max mem: 34987
2023-10-30 05:34:49,330 [INFO] Evaluation  [100/625]  eta: 0:25:11    time: 2.6023  max mem: 34987
2023-10-30 05:35:15,585 [INFO] Evaluation  [110/625]  eta: 0:24:30    time: 2.6114  max mem: 34987
2023-10-30 05:35:41,612 [INFO] Evaluation  [120/625]  eta: 0:23:51    time: 2.6138  max mem: 34987
2023-10-30 05:36:08,985 [INFO] Evaluation  [130/625]  eta: 0:23:19    time: 2.6696  max mem: 34987
2023-10-30 05:36:34,601 [INFO] Evaluation  [140/625]  eta: 0:22:42    time: 2.6492  max mem: 34987
2023-10-30 05:37:00,774 [INFO] Evaluation  [150/625]  eta: 0:22:08    time: 2.5891  max mem: 34987
2023-10-30 05:37:26,904 [INFO] Evaluation  [160/625]  eta: 0:21:34    time: 2.6147  max mem: 34987
2023-10-30 05:37:52,734 [INFO] Evaluation  [170/625]  eta: 0:21:01    time: 2.5977  max mem: 34987
2023-10-30 05:38:18,937 [INFO] Evaluation  [180/625]  eta: 0:20:30    time: 2.6015  max mem: 34987
2023-10-30 05:38:44,910 [INFO] Evaluation  [190/625]  eta: 0:19:58    time: 2.6086  max mem: 34987
2023-10-30 05:39:13,257 [INFO] Evaluation  [200/625]  eta: 0:19:32    time: 2.7154  max mem: 34987
2023-10-30 05:39:39,030 [INFO] Evaluation  [210/625]  eta: 0:19:01    time: 2.7053  max mem: 34987
2023-10-30 05:40:05,089 [INFO] Evaluation  [220/625]  eta: 0:18:31    time: 2.5910  max mem: 34987
2023-10-30 05:40:31,071 [INFO] Evaluation  [230/625]  eta: 0:18:01    time: 2.6016  max mem: 34987
2023-10-30 05:40:57,047 [INFO] Evaluation  [240/625]  eta: 0:17:31    time: 2.5978  max mem: 34987
2023-10-30 05:41:23,114 [INFO] Evaluation  [250/625]  eta: 0:17:02    time: 2.6020  max mem: 34987
2023-10-30 05:41:49,127 [INFO] Evaluation  [260/625]  eta: 0:16:33    time: 2.6039  max mem: 34987
2023-10-30 05:42:15,644 [INFO] Evaluation  [270/625]  eta: 0:16:05    time: 2.6263  max mem: 34987
2023-10-30 05:42:41,608 [INFO] Evaluation  [280/625]  eta: 0:15:36    time: 2.6238  max mem: 34987
2023-10-30 05:43:07,782 [INFO] Evaluation  [290/625]  eta: 0:15:08    time: 2.6067  max mem: 34987
2023-10-30 05:43:33,570 [INFO] Evaluation  [300/625]  eta: 0:14:39    time: 2.5980  max mem: 34987
2023-10-30 05:43:59,693 [INFO] Evaluation  [310/625]  eta: 0:14:11    time: 2.5954  max mem: 34987
2023-10-30 05:44:25,706 [INFO] Evaluation  [320/625]  eta: 0:13:43    time: 2.6065  max mem: 34987
2023-10-30 05:44:51,656 [INFO] Evaluation  [330/625]  eta: 0:13:15    time: 2.5979  max mem: 34987
2023-10-30 05:45:20,073 [INFO] Evaluation  [340/625]  eta: 0:12:50    time: 2.7162  max mem: 34987
2023-10-30 05:45:46,406 [INFO] Evaluation  [350/625]  eta: 0:12:22    time: 2.7353  max mem: 34987
2023-10-30 05:46:12,379 [INFO] Evaluation  [360/625]  eta: 0:11:54    time: 2.6151  max mem: 34987
2023-10-30 05:46:38,749 [INFO] Evaluation  [370/625]  eta: 0:11:27    time: 2.6170  max mem: 34987
2023-10-30 05:47:04,556 [INFO] Evaluation  [380/625]  eta: 0:10:59    time: 2.6087  max mem: 34987
2023-10-30 05:47:30,439 [INFO] Evaluation  [390/625]  eta: 0:10:32    time: 2.5843  max mem: 34987
2023-10-30 05:48:01,063 [INFO] Evaluation  [400/625]  eta: 0:10:07    time: 2.8233  max mem: 34987
2023-10-30 05:48:27,135 [INFO] Evaluation  [410/625]  eta: 0:09:39    time: 2.8321  max mem: 34987
2023-10-30 05:48:53,380 [INFO] Evaluation  [420/625]  eta: 0:09:12    time: 2.6150  max mem: 34987
2023-10-30 05:49:24,817 [INFO] Evaluation  [430/625]  eta: 0:08:47    time: 2.8838  max mem: 34987
2023-10-30 05:49:51,078 [INFO] Evaluation  [440/625]  eta: 0:08:20    time: 2.8845  max mem: 34987
2023-10-30 05:50:20,520 [INFO] Evaluation  [450/625]  eta: 0:07:54    time: 2.7849  max mem: 34987
2023-10-30 05:50:46,375 [INFO] Evaluation  [460/625]  eta: 0:07:26    time: 2.7645  max mem: 34987
2023-10-30 05:51:12,172 [INFO] Evaluation  [470/625]  eta: 0:06:59    time: 2.5824  max mem: 34987
2023-10-30 05:51:37,938 [INFO] Evaluation  [480/625]  eta: 0:06:31    time: 2.5779  max mem: 34987
2023-10-30 05:52:04,076 [INFO] Evaluation  [490/625]  eta: 0:06:04    time: 2.5949  max mem: 34987
2023-10-30 05:52:30,479 [INFO] Evaluation  [500/625]  eta: 0:05:37    time: 2.6269  max mem: 34987
2023-10-30 05:52:56,343 [INFO] Evaluation  [510/625]  eta: 0:05:10    time: 2.6132  max mem: 34987
2023-10-30 05:53:22,656 [INFO] Evaluation  [520/625]  eta: 0:04:42    time: 2.6086  max mem: 34987
2023-10-30 05:53:48,562 [INFO] Evaluation  [530/625]  eta: 0:04:15    time: 2.6107  max mem: 34987
2023-10-30 05:54:15,069 [INFO] Evaluation  [540/625]  eta: 0:03:48    time: 2.6205  max mem: 34987
2023-10-30 05:54:41,608 [INFO] Evaluation  [550/625]  eta: 0:03:21    time: 2.6521  max mem: 34987
2023-10-30 05:55:07,411 [INFO] Evaluation  [560/625]  eta: 0:02:54    time: 2.6169  max mem: 34987
2023-10-30 05:55:33,547 [INFO] Evaluation  [570/625]  eta: 0:02:27    time: 2.5968  max mem: 34987
2023-10-30 05:55:59,548 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6066  max mem: 34987
2023-10-30 05:56:25,321 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5884  max mem: 34987
2023-10-30 05:56:51,414 [INFO] Evaluation  [600/625]  eta: 0:01:07    time: 2.5931  max mem: 34987
2023-10-30 05:57:17,299 [INFO] Evaluation  [610/625]  eta: 0:00:40    time: 2.5986  max mem: 34987
2023-10-30 05:57:43,025 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5803  max mem: 34987
2023-10-30 05:57:52,607 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5418  max mem: 34987
2023-10-30 05:57:52,690 [WARNING] rank 0 starts merging results.
2023-10-30 05:57:52,748 [INFO] {'agg_metrics': 0.6423138510808647, 'total': 4996, 'CH': 63.98243045387994, 'CW': 62.31808731808732, 'TN': 57.20670391061452, 'TC': 66.66666666666666, 'DL': 86.4406779661017, 'DC': 51.41242937853108, 'DO': 77.04918032786885, 'TP': 70.37037037037037}
2023-10-30 05:57:52,796 [INFO] Saving checkpoint at epoch 6 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_best.pth.
2023-10-30 05:57:55,827 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_5.pth.
2023-10-30 05:57:55,987 [INFO] Saving checkpoint at epoch 6 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_6.pth.
2023-10-30 05:57:58,863 [INFO] Start training
2023-10-30 05:57:58,904 [INFO] Start training epoch 7, 2133 iters per inner epoch.
2023-10-30 05:58:11,695 [INFO] Train: data epoch: [7]  [   0/2133]  eta: 7:34:31  lr: 0.000006  loss: 0.2461  data_time: 10.5681  time: 12.7854  max mem: 34987
2023-10-30 05:59:07,937 [INFO] Train: data epoch: [7]  [  50/2133]  eta: 0:46:57  lr: 0.000006  loss: 0.3868  data_time: 0.0050  time: 1.0895  max mem: 34987
2023-10-30 06:00:03,401 [INFO] Train: data epoch: [7]  [ 100/2133]  eta: 0:41:44  lr: 0.000006  loss: 0.3103  data_time: 0.0049  time: 1.1357  max mem: 34987
2023-10-30 06:00:57,789 [INFO] Train: data epoch: [7]  [ 150/2133]  eta: 0:39:08  lr: 0.000006  loss: 0.2498  data_time: 0.0055  time: 1.0890  max mem: 34987
2023-10-30 06:01:52,177 [INFO] Train: data epoch: [7]  [ 200/2133]  eta: 0:37:22  lr: 0.000006  loss: 0.2933  data_time: 0.0046  time: 1.0854  max mem: 34987
2023-10-30 06:02:46,702 [INFO] Train: data epoch: [7]  [ 250/2133]  eta: 0:35:58  lr: 0.000006  loss: 0.2795  data_time: 0.0045  time: 1.0938  max mem: 34987
2023-10-30 06:03:41,379 [INFO] Train: data epoch: [7]  [ 300/2133]  eta: 0:34:45  lr: 0.000006  loss: 0.2945  data_time: 0.0048  time: 1.0895  max mem: 34987
2023-10-30 06:04:35,693 [INFO] Train: data epoch: [7]  [ 350/2133]  eta: 0:33:35  lr: 0.000006  loss: 0.3308  data_time: 0.0045  time: 1.0856  max mem: 34987
2023-10-30 06:05:29,853 [INFO] Train: data epoch: [7]  [ 400/2133]  eta: 0:32:28  lr: 0.000006  loss: 0.2583  data_time: 0.0051  time: 1.0852  max mem: 34987
2023-10-30 06:06:24,149 [INFO] Train: data epoch: [7]  [ 450/2133]  eta: 0:31:25  lr: 0.000006  loss: 0.2821  data_time: 0.0051  time: 1.0858  max mem: 34987
2023-10-30 06:07:18,569 [INFO] Train: data epoch: [7]  [ 500/2133]  eta: 0:30:23  lr: 0.000006  loss: 0.3036  data_time: 0.0052  time: 1.0944  max mem: 34987
2023-10-30 06:08:13,037 [INFO] Train: data epoch: [7]  [ 550/2133]  eta: 0:29:24  lr: 0.000006  loss: 0.4040  data_time: 0.0049  time: 1.0852  max mem: 34987
2023-10-30 06:09:07,364 [INFO] Train: data epoch: [7]  [ 600/2133]  eta: 0:28:24  lr: 0.000006  loss: 0.3421  data_time: 0.0049  time: 1.0831  max mem: 34987
2023-10-30 06:10:01,790 [INFO] Train: data epoch: [7]  [ 650/2133]  eta: 0:27:26  lr: 0.000006  loss: 0.3143  data_time: 0.0054  time: 1.0895  max mem: 34987
2023-10-30 06:10:56,410 [INFO] Train: data epoch: [7]  [ 700/2133]  eta: 0:26:29  lr: 0.000006  loss: 0.2776  data_time: 0.0050  time: 1.0906  max mem: 34987
2023-10-30 06:11:51,290 [INFO] Train: data epoch: [7]  [ 750/2133]  eta: 0:25:32  lr: 0.000006  loss: 0.2999  data_time: 0.0046  time: 1.0992  max mem: 34987
2023-10-30 06:12:46,152 [INFO] Train: data epoch: [7]  [ 800/2133]  eta: 0:24:36  lr: 0.000006  loss: 0.2458  data_time: 0.0040  time: 1.0983  max mem: 34987
2023-10-30 06:13:40,469 [INFO] Train: data epoch: [7]  [ 850/2133]  eta: 0:23:39  lr: 0.000006  loss: 0.3576  data_time: 0.0050  time: 1.0943  max mem: 34987
2023-10-30 06:14:34,523 [INFO] Train: data epoch: [7]  [ 900/2133]  eta: 0:22:42  lr: 0.000006  loss: 0.3197  data_time: 0.0052  time: 1.0820  max mem: 34987
2023-10-30 06:15:28,745 [INFO] Train: data epoch: [7]  [ 950/2133]  eta: 0:21:45  lr: 0.000006  loss: 0.2566  data_time: 0.0052  time: 1.0841  max mem: 34987
2023-10-30 06:16:22,871 [INFO] Train: data epoch: [7]  [1000/2133]  eta: 0:20:49  lr: 0.000006  loss: 0.3366  data_time: 0.0053  time: 1.0808  max mem: 34987
2023-10-30 06:17:16,883 [INFO] Train: data epoch: [7]  [1050/2133]  eta: 0:19:53  lr: 0.000006  loss: 0.3098  data_time: 0.0064  time: 1.0821  max mem: 34987
2023-10-30 06:18:11,037 [INFO] Train: data epoch: [7]  [1100/2133]  eta: 0:18:57  lr: 0.000006  loss: 0.3364  data_time: 0.0044  time: 1.0800  max mem: 34987
2023-10-30 06:19:05,093 [INFO] Train: data epoch: [7]  [1150/2133]  eta: 0:18:01  lr: 0.000006  loss: 0.3280  data_time: 0.0052  time: 1.0825  max mem: 34987
2023-10-30 06:19:59,675 [INFO] Train: data epoch: [7]  [1200/2133]  eta: 0:17:05  lr: 0.000006  loss: 0.2885  data_time: 0.0046  time: 1.0935  max mem: 34987
2023-10-30 06:20:54,060 [INFO] Train: data epoch: [7]  [1250/2133]  eta: 0:16:10  lr: 0.000006  loss: 0.2820  data_time: 0.0048  time: 1.0863  max mem: 34987
2023-10-30 06:21:48,631 [INFO] Train: data epoch: [7]  [1300/2133]  eta: 0:15:15  lr: 0.000006  loss: 0.3987  data_time: 0.0056  time: 1.0877  max mem: 34987
2023-10-30 06:22:43,003 [INFO] Train: data epoch: [7]  [1350/2133]  eta: 0:14:20  lr: 0.000006  loss: 0.2973  data_time: 0.0049  time: 1.0968  max mem: 34987
2023-10-30 06:23:37,149 [INFO] Train: data epoch: [7]  [1400/2133]  eta: 0:13:24  lr: 0.000006  loss: 0.2907  data_time: 0.0046  time: 1.0804  max mem: 34987
2023-10-30 06:24:31,388 [INFO] Train: data epoch: [7]  [1450/2133]  eta: 0:12:29  lr: 0.000006  loss: 0.2995  data_time: 0.0047  time: 1.0821  max mem: 34987
2023-10-30 06:25:25,614 [INFO] Train: data epoch: [7]  [1500/2133]  eta: 0:11:34  lr: 0.000006  loss: 0.2261  data_time: 0.0054  time: 1.0832  max mem: 34987
2023-10-30 06:26:19,967 [INFO] Train: data epoch: [7]  [1550/2133]  eta: 0:10:39  lr: 0.000006  loss: 0.3549  data_time: 0.0050  time: 1.0828  max mem: 34987
2023-10-30 06:27:14,522 [INFO] Train: data epoch: [7]  [1600/2133]  eta: 0:09:44  lr: 0.000006  loss: 0.2983  data_time: 0.0051  time: 1.0915  max mem: 34987
2023-10-30 06:28:08,838 [INFO] Train: data epoch: [7]  [1650/2133]  eta: 0:08:49  lr: 0.000006  loss: 0.2343  data_time: 0.0049  time: 1.0844  max mem: 34987
2023-10-30 06:29:05,677 [INFO] Train: data epoch: [7]  [1700/2133]  eta: 0:07:55  lr: 0.000006  loss: 0.2651  data_time: 0.0062  time: 1.2116  max mem: 34987
2023-10-30 06:30:01,554 [INFO] Train: data epoch: [7]  [1750/2133]  eta: 0:07:00  lr: 0.000006  loss: 0.2228  data_time: 0.0050  time: 1.1452  max mem: 34987
2023-10-30 06:30:56,350 [INFO] Train: data epoch: [7]  [1800/2133]  eta: 0:06:05  lr: 0.000006  loss: 0.2465  data_time: 0.0048  time: 1.0978  max mem: 34987
2023-10-30 06:31:50,738 [INFO] Train: data epoch: [7]  [1850/2133]  eta: 0:05:10  lr: 0.000006  loss: 0.3087  data_time: 0.0050  time: 1.0859  max mem: 34987
2023-10-30 06:32:45,243 [INFO] Train: data epoch: [7]  [1900/2133]  eta: 0:04:15  lr: 0.000006  loss: 0.2956  data_time: 0.0050  time: 1.0886  max mem: 34987
2023-10-30 06:33:39,535 [INFO] Train: data epoch: [7]  [1950/2133]  eta: 0:03:20  lr: 0.000006  loss: 0.2628  data_time: 0.0047  time: 1.0828  max mem: 34987
2023-10-30 06:34:34,126 [INFO] Train: data epoch: [7]  [2000/2133]  eta: 0:02:25  lr: 0.000006  loss: 0.2568  data_time: 0.0052  time: 1.0833  max mem: 34987
2023-10-30 06:35:28,607 [INFO] Train: data epoch: [7]  [2050/2133]  eta: 0:01:31  lr: 0.000006  loss: 0.2789  data_time: 0.0050  time: 1.0895  max mem: 34987
2023-10-30 06:36:23,113 [INFO] Train: data epoch: [7]  [2100/2133]  eta: 0:00:36  lr: 0.000006  loss: 0.3107  data_time: 0.0042  time: 1.0838  max mem: 34987
2023-10-30 06:36:58,096 [INFO] Train: data epoch: [7]  [2132/2133]  eta: 0:00:01  lr: 0.000006  loss: 0.3107  data_time: 0.0261  time: 1.0931  max mem: 34987
2023-10-30 06:36:58,105 [INFO] Averaged stats: lr: 0.0000  loss: 0.2956  data_time: 0.0101
2023-10-30 06:36:58,117 [INFO] Evaluating on val.
2023-10-30 06:37:22,065 [INFO] Evaluation  [  0/625]  eta: 4:09:09    time: 23.9197  max mem: 34987
2023-10-30 06:37:52,984 [INFO] Evaluation  [ 10/625]  eta: 0:51:05    time: 4.9851  max mem: 34987
2023-10-30 06:38:20,942 [INFO] Evaluation  [ 20/625]  eta: 0:39:45    time: 2.9434  max mem: 34987
2023-10-30 06:38:46,932 [INFO] Evaluation  [ 30/625]  eta: 0:34:47    time: 2.6970  max mem: 34987
2023-10-30 06:39:14,517 [INFO] Evaluation  [ 40/625]  eta: 0:32:25    time: 2.6783  max mem: 34987
2023-10-30 06:39:40,519 [INFO] Evaluation  [ 50/625]  eta: 0:30:30    time: 2.6789  max mem: 34987
2023-10-30 06:40:07,250 [INFO] Evaluation  [ 60/625]  eta: 0:29:11    time: 2.6365  max mem: 34987
2023-10-30 06:40:33,400 [INFO] Evaluation  [ 70/625]  eta: 0:28:02    time: 2.6439  max mem: 34987
2023-10-30 06:40:59,566 [INFO] Evaluation  [ 80/625]  eta: 0:27:04    time: 2.6155  max mem: 34987
2023-10-30 06:41:25,720 [INFO] Evaluation  [ 90/625]  eta: 0:26:12    time: 2.6157  max mem: 34987
2023-10-30 06:41:51,741 [INFO] Evaluation  [100/625]  eta: 0:25:25    time: 2.6086  max mem: 34987
2023-10-30 06:42:17,822 [INFO] Evaluation  [110/625]  eta: 0:24:43    time: 2.6050  max mem: 34987
2023-10-30 06:42:43,663 [INFO] Evaluation  [120/625]  eta: 0:24:01    time: 2.5959  max mem: 34987
2023-10-30 06:43:12,194 [INFO] Evaluation  [130/625]  eta: 0:23:33    time: 2.7180  max mem: 34987
2023-10-30 06:43:37,893 [INFO] Evaluation  [140/625]  eta: 0:22:54    time: 2.7109  max mem: 34987
2023-10-30 06:44:03,791 [INFO] Evaluation  [150/625]  eta: 0:22:18    time: 2.5796  max mem: 34987
2023-10-30 06:44:29,828 [INFO] Evaluation  [160/625]  eta: 0:21:44    time: 2.5965  max mem: 34987
2023-10-30 06:44:55,909 [INFO] Evaluation  [170/625]  eta: 0:21:11    time: 2.6057  max mem: 34987
2023-10-30 06:45:22,191 [INFO] Evaluation  [180/625]  eta: 0:20:39    time: 2.6178  max mem: 34987
2023-10-30 06:45:48,211 [INFO] Evaluation  [190/625]  eta: 0:20:07    time: 2.6147  max mem: 34987
2023-10-30 06:46:14,320 [INFO] Evaluation  [200/625]  eta: 0:19:35    time: 2.6063  max mem: 34987
2023-10-30 06:46:40,178 [INFO] Evaluation  [210/625]  eta: 0:19:04    time: 2.5982  max mem: 34987
2023-10-30 06:47:06,306 [INFO] Evaluation  [220/625]  eta: 0:18:34    time: 2.5991  max mem: 34987
2023-10-30 06:47:32,370 [INFO] Evaluation  [230/625]  eta: 0:18:04    time: 2.6094  max mem: 34987
2023-10-30 06:47:58,403 [INFO] Evaluation  [240/625]  eta: 0:17:34    time: 2.6047  max mem: 34987
2023-10-30 06:48:24,397 [INFO] Evaluation  [250/625]  eta: 0:17:05    time: 2.6012  max mem: 34987
2023-10-30 06:48:50,435 [INFO] Evaluation  [260/625]  eta: 0:16:36    time: 2.6014  max mem: 34987
2023-10-30 06:49:16,386 [INFO] Evaluation  [270/625]  eta: 0:16:06    time: 2.5993  max mem: 34987
2023-10-30 06:49:42,230 [INFO] Evaluation  [280/625]  eta: 0:15:38    time: 2.5896  max mem: 34987
2023-10-30 06:50:08,409 [INFO] Evaluation  [290/625]  eta: 0:15:09    time: 2.6010  max mem: 34987
2023-10-30 06:50:34,201 [INFO] Evaluation  [300/625]  eta: 0:14:41    time: 2.5984  max mem: 34987
2023-10-30 06:51:02,203 [INFO] Evaluation  [310/625]  eta: 0:14:14    time: 2.6894  max mem: 34987
2023-10-30 06:51:27,965 [INFO] Evaluation  [320/625]  eta: 0:13:46    time: 2.6879  max mem: 34987
2023-10-30 06:51:54,000 [INFO] Evaluation  [330/625]  eta: 0:13:18    time: 2.5897  max mem: 34987
2023-10-30 06:52:20,158 [INFO] Evaluation  [340/625]  eta: 0:12:50    time: 2.6095  max mem: 34987
2023-10-30 06:52:46,534 [INFO] Evaluation  [350/625]  eta: 0:12:22    time: 2.6266  max mem: 34987
2023-10-30 06:53:12,570 [INFO] Evaluation  [360/625]  eta: 0:11:55    time: 2.6204  max mem: 34987
2023-10-30 06:53:38,672 [INFO] Evaluation  [370/625]  eta: 0:11:27    time: 2.6067  max mem: 34987
2023-10-30 06:54:08,294 [INFO] Evaluation  [380/625]  eta: 0:11:02    time: 2.7851  max mem: 34987
2023-10-30 06:54:34,181 [INFO] Evaluation  [390/625]  eta: 0:10:34    time: 2.7743  max mem: 34987
2023-10-30 06:55:04,610 [INFO] Evaluation  [400/625]  eta: 0:10:09    time: 2.8155  max mem: 34987
2023-10-30 06:55:30,538 [INFO] Evaluation  [410/625]  eta: 0:09:41    time: 2.8175  max mem: 34987
2023-10-30 06:55:59,132 [INFO] Evaluation  [420/625]  eta: 0:09:15    time: 2.7253  max mem: 34987
2023-10-30 06:56:25,084 [INFO] Evaluation  [430/625]  eta: 0:08:47    time: 2.7263  max mem: 34987
2023-10-30 06:56:51,422 [INFO] Evaluation  [440/625]  eta: 0:08:20    time: 2.6141  max mem: 34987
2023-10-30 06:57:17,575 [INFO] Evaluation  [450/625]  eta: 0:07:53    time: 2.6244  max mem: 34987
2023-10-30 06:57:43,467 [INFO] Evaluation  [460/625]  eta: 0:07:25    time: 2.6021  max mem: 34987
2023-10-30 06:58:09,288 [INFO] Evaluation  [470/625]  eta: 0:06:58    time: 2.5855  max mem: 34987
2023-10-30 06:58:35,062 [INFO] Evaluation  [480/625]  eta: 0:06:30    time: 2.5795  max mem: 34987
2023-10-30 06:59:01,310 [INFO] Evaluation  [490/625]  eta: 0:06:03    time: 2.6009  max mem: 34987
2023-10-30 06:59:27,833 [INFO] Evaluation  [500/625]  eta: 0:05:36    time: 2.6384  max mem: 34987
2023-10-30 06:59:53,743 [INFO] Evaluation  [510/625]  eta: 0:05:09    time: 2.6215  max mem: 34987
2023-10-30 07:00:19,989 [INFO] Evaluation  [520/625]  eta: 0:04:42    time: 2.6076  max mem: 34987
2023-10-30 07:00:45,706 [INFO] Evaluation  [530/625]  eta: 0:04:15    time: 2.5980  max mem: 34987
2023-10-30 07:01:12,131 [INFO] Evaluation  [540/625]  eta: 0:03:48    time: 2.6069  max mem: 34987
2023-10-30 07:01:38,656 [INFO] Evaluation  [550/625]  eta: 0:03:21    time: 2.6473  max mem: 34987
2023-10-30 07:02:04,566 [INFO] Evaluation  [560/625]  eta: 0:02:54    time: 2.6215  max mem: 34987
2023-10-30 07:02:30,684 [INFO] Evaluation  [570/625]  eta: 0:02:27    time: 2.6011  max mem: 34987
2023-10-30 07:02:56,664 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6048  max mem: 34987
2023-10-30 07:03:22,479 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5896  max mem: 34987
2023-10-30 07:03:48,442 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5887  max mem: 34987
2023-10-30 07:04:14,331 [INFO] Evaluation  [610/625]  eta: 0:00:40    time: 2.5924  max mem: 34987
2023-10-30 07:04:40,055 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5805  max mem: 34987
2023-10-30 07:04:49,656 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5433  max mem: 34987
2023-10-30 07:04:49,734 [WARNING] rank 0 starts merging results.
2023-10-30 07:04:49,789 [INFO] {'agg_metrics': 0.6401120896717374, 'total': 4996, 'CH': 63.250366032210835, 'CW': 62.21413721413721, 'TN': 56.87150837988827, 'TC': 66.66666666666666, 'DL': 86.77966101694915, 'DC': 51.41242937853108, 'DO': 76.0655737704918, 'TP': 72.22222222222221}
2023-10-30 07:04:49,790 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_6.pth.
2023-10-30 07:04:49,833 [INFO] Saving checkpoint at epoch 7 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_7.pth.
2023-10-30 07:04:51,927 [INFO] Start training
2023-10-30 07:04:51,965 [INFO] Start training epoch 8, 2133 iters per inner epoch.
2023-10-30 07:05:04,435 [INFO] Train: data epoch: [8]  [   0/2133]  eta: 7:23:14  lr: 0.000003  loss: 0.2739  data_time: 10.3118  time: 12.4679  max mem: 34987
2023-10-30 07:06:01,265 [INFO] Train: data epoch: [8]  [  50/2133]  eta: 0:47:10  lr: 0.000003  loss: 0.2541  data_time: 0.0043  time: 1.0850  max mem: 34987
2023-10-30 07:06:55,524 [INFO] Train: data epoch: [8]  [ 100/2133]  eta: 0:41:26  lr: 0.000003  loss: 0.3132  data_time: 0.0050  time: 1.0866  max mem: 34987
2023-10-30 07:07:49,838 [INFO] Train: data epoch: [8]  [ 150/2133]  eta: 0:38:55  lr: 0.000003  loss: 0.2858  data_time: 0.0049  time: 1.0808  max mem: 34987
2023-10-30 07:08:45,036 [INFO] Train: data epoch: [8]  [ 200/2133]  eta: 0:37:21  lr: 0.000003  loss: 0.2927  data_time: 0.0053  time: 1.0886  max mem: 34987
2023-10-30 07:09:39,363 [INFO] Train: data epoch: [8]  [ 250/2133]  eta: 0:35:55  lr: 0.000003  loss: 0.2494  data_time: 0.0051  time: 1.0932  max mem: 34987
2023-10-30 07:10:33,805 [INFO] Train: data epoch: [8]  [ 300/2133]  eta: 0:34:41  lr: 0.000003  loss: 0.3794  data_time: 0.0054  time: 1.0872  max mem: 34987
2023-10-30 07:11:28,062 [INFO] Train: data epoch: [8]  [ 350/2133]  eta: 0:33:31  lr: 0.000003  loss: 0.2557  data_time: 0.0051  time: 1.0879  max mem: 34987
2023-10-30 07:12:22,575 [INFO] Train: data epoch: [8]  [ 400/2133]  eta: 0:32:27  lr: 0.000003  loss: 0.3466  data_time: 0.0054  time: 1.0904  max mem: 34987
2023-10-30 07:13:17,028 [INFO] Train: data epoch: [8]  [ 450/2133]  eta: 0:31:24  lr: 0.000003  loss: 0.2610  data_time: 0.0053  time: 1.0883  max mem: 34987
2023-10-30 07:14:11,376 [INFO] Train: data epoch: [8]  [ 500/2133]  eta: 0:30:23  lr: 0.000003  loss: 0.3594  data_time: 0.0050  time: 1.0818  max mem: 34987
2023-10-30 07:15:05,671 [INFO] Train: data epoch: [8]  [ 550/2133]  eta: 0:29:23  lr: 0.000003  loss: 0.2975  data_time: 0.0050  time: 1.0869  max mem: 34987
2023-10-30 07:16:00,219 [INFO] Train: data epoch: [8]  [ 600/2133]  eta: 0:28:24  lr: 0.000003  loss: 0.2967  data_time: 0.0049  time: 1.0887  max mem: 34987
2023-10-30 07:16:54,575 [INFO] Train: data epoch: [8]  [ 650/2133]  eta: 0:27:26  lr: 0.000003  loss: 0.2677  data_time: 0.0047  time: 1.0823  max mem: 34987
2023-10-30 07:17:48,923 [INFO] Train: data epoch: [8]  [ 700/2133]  eta: 0:26:28  lr: 0.000003  loss: 0.2377  data_time: 0.0050  time: 1.0849  max mem: 34987
2023-10-30 07:18:43,422 [INFO] Train: data epoch: [8]  [ 750/2133]  eta: 0:25:31  lr: 0.000003  loss: 0.3210  data_time: 0.0050  time: 1.0888  max mem: 34987
2023-10-30 07:19:37,603 [INFO] Train: data epoch: [8]  [ 800/2133]  eta: 0:24:33  lr: 0.000003  loss: 0.2830  data_time: 0.0054  time: 1.0875  max mem: 34987
2023-10-30 07:20:31,802 [INFO] Train: data epoch: [8]  [ 850/2133]  eta: 0:23:36  lr: 0.000003  loss: 0.2934  data_time: 0.0052  time: 1.0875  max mem: 34987
2023-10-30 07:21:26,303 [INFO] Train: data epoch: [8]  [ 900/2133]  eta: 0:22:40  lr: 0.000003  loss: 0.2804  data_time: 0.0051  time: 1.0899  max mem: 34987
2023-10-30 07:22:20,550 [INFO] Train: data epoch: [8]  [ 950/2133]  eta: 0:21:44  lr: 0.000003  loss: 0.2269  data_time: 0.0052  time: 1.0890  max mem: 34987
2023-10-30 07:23:14,713 [INFO] Train: data epoch: [8]  [1000/2133]  eta: 0:20:48  lr: 0.000003  loss: 0.2783  data_time: 0.0052  time: 1.0792  max mem: 34987
2023-10-30 07:24:09,257 [INFO] Train: data epoch: [8]  [1050/2133]  eta: 0:19:52  lr: 0.000003  loss: 0.3532  data_time: 0.0048  time: 1.0859  max mem: 34987
2023-10-30 07:25:03,511 [INFO] Train: data epoch: [8]  [1100/2133]  eta: 0:18:56  lr: 0.000003  loss: 0.3713  data_time: 0.0046  time: 1.0795  max mem: 34987
2023-10-30 07:25:58,050 [INFO] Train: data epoch: [8]  [1150/2133]  eta: 0:18:01  lr: 0.000003  loss: 0.2567  data_time: 0.0051  time: 1.0935  max mem: 34987
2023-10-30 07:26:52,532 [INFO] Train: data epoch: [8]  [1200/2133]  eta: 0:17:05  lr: 0.000003  loss: 0.3118  data_time: 0.0051  time: 1.0866  max mem: 34987
2023-10-30 07:27:46,940 [INFO] Train: data epoch: [8]  [1250/2133]  eta: 0:16:10  lr: 0.000003  loss: 0.2596  data_time: 0.0048  time: 1.0915  max mem: 34987
2023-10-30 07:28:41,235 [INFO] Train: data epoch: [8]  [1300/2133]  eta: 0:15:15  lr: 0.000003  loss: 0.3427  data_time: 0.0051  time: 1.0880  max mem: 34987
2023-10-30 07:29:37,714 [INFO] Train: data epoch: [8]  [1350/2133]  eta: 0:14:21  lr: 0.000003  loss: 0.3721  data_time: 0.0053  time: 1.0844  max mem: 34987
2023-10-30 07:30:33,476 [INFO] Train: data epoch: [8]  [1400/2133]  eta: 0:13:26  lr: 0.000003  loss: 0.2900  data_time: 0.0046  time: 1.0832  max mem: 34987
2023-10-30 07:31:27,245 [INFO] Train: data epoch: [8]  [1450/2133]  eta: 0:12:30  lr: 0.000003  loss: 0.2847  data_time: 0.0049  time: 1.0697  max mem: 34987
2023-10-30 07:32:21,273 [INFO] Train: data epoch: [8]  [1500/2133]  eta: 0:11:35  lr: 0.000003  loss: 0.3057  data_time: 0.0050  time: 1.0783  max mem: 34987
2023-10-30 07:33:15,135 [INFO] Train: data epoch: [8]  [1550/2133]  eta: 0:10:40  lr: 0.000003  loss: 0.2889  data_time: 0.0054  time: 1.0857  max mem: 34987
2023-10-30 07:34:09,028 [INFO] Train: data epoch: [8]  [1600/2133]  eta: 0:09:44  lr: 0.000003  loss: 0.2785  data_time: 0.0047  time: 1.0736  max mem: 34987
2023-10-30 07:35:02,742 [INFO] Train: data epoch: [8]  [1650/2133]  eta: 0:08:49  lr: 0.000003  loss: 0.3511  data_time: 0.0044  time: 1.0687  max mem: 34987
2023-10-30 07:35:56,354 [INFO] Train: data epoch: [8]  [1700/2133]  eta: 0:07:54  lr: 0.000003  loss: 0.3117  data_time: 0.0048  time: 1.0712  max mem: 34987
2023-10-30 07:36:49,986 [INFO] Train: data epoch: [8]  [1750/2133]  eta: 0:06:59  lr: 0.000003  loss: 0.3216  data_time: 0.0046  time: 1.0663  max mem: 34987
2023-10-30 07:37:45,127 [INFO] Train: data epoch: [8]  [1800/2133]  eta: 0:06:04  lr: 0.000003  loss: 0.3672  data_time: 0.0045  time: 1.0719  max mem: 34987
2023-10-30 07:38:39,009 [INFO] Train: data epoch: [8]  [1850/2133]  eta: 0:05:09  lr: 0.000003  loss: 0.2636  data_time: 0.0046  time: 1.0769  max mem: 34987
2023-10-30 07:39:33,022 [INFO] Train: data epoch: [8]  [1900/2133]  eta: 0:04:15  lr: 0.000003  loss: 0.3641  data_time: 0.0044  time: 1.0757  max mem: 34987
2023-10-30 07:40:27,022 [INFO] Train: data epoch: [8]  [1950/2133]  eta: 0:03:20  lr: 0.000003  loss: 0.2395  data_time: 0.0045  time: 1.0814  max mem: 34987
2023-10-30 07:41:20,623 [INFO] Train: data epoch: [8]  [2000/2133]  eta: 0:02:25  lr: 0.000003  loss: 0.2993  data_time: 0.0050  time: 1.0730  max mem: 34987
2023-10-30 07:42:14,973 [INFO] Train: data epoch: [8]  [2050/2133]  eta: 0:01:30  lr: 0.000003  loss: 0.2955  data_time: 0.0045  time: 1.0869  max mem: 34987
2023-10-30 07:43:11,002 [INFO] Train: data epoch: [8]  [2100/2133]  eta: 0:00:36  lr: 0.000003  loss: 0.3052  data_time: 0.0052  time: 1.1899  max mem: 34987
2023-10-30 07:43:45,648 [INFO] Train: data epoch: [8]  [2132/2133]  eta: 0:00:01  lr: 0.000003  loss: 0.2455  data_time: 0.0236  time: 1.0850  max mem: 34987
2023-10-30 07:43:45,658 [INFO] Averaged stats: lr: 0.0000  loss: 0.2929  data_time: 0.0100
2023-10-30 07:43:45,669 [INFO] Evaluating on val.
2023-10-30 07:44:08,852 [INFO] Evaluation  [  0/625]  eta: 4:01:12    time: 23.1567  max mem: 34987
2023-10-30 07:44:40,750 [INFO] Evaluation  [ 10/625]  eta: 0:51:17    time: 5.0048  max mem: 34987
2023-10-30 07:45:08,980 [INFO] Evaluation  [ 20/625]  eta: 0:39:59    time: 3.0062  max mem: 34987
2023-10-30 07:45:34,942 [INFO] Evaluation  [ 30/625]  eta: 0:34:56    time: 2.7094  max mem: 34987
2023-10-30 07:46:01,213 [INFO] Evaluation  [ 40/625]  eta: 0:32:13    time: 2.6113  max mem: 34987
2023-10-30 07:46:27,152 [INFO] Evaluation  [ 50/625]  eta: 0:30:20    time: 2.6101  max mem: 34987
2023-10-30 07:46:53,339 [INFO] Evaluation  [ 60/625]  eta: 0:28:57    time: 2.6061  max mem: 34987
2023-10-30 07:47:19,595 [INFO] Evaluation  [ 70/625]  eta: 0:27:51    time: 2.6220  max mem: 34987
2023-10-30 07:47:45,761 [INFO] Evaluation  [ 80/625]  eta: 0:26:55    time: 2.6210  max mem: 34987
2023-10-30 07:48:11,820 [INFO] Evaluation  [ 90/625]  eta: 0:26:04    time: 2.6111  max mem: 34987
2023-10-30 07:48:37,784 [INFO] Evaluation  [100/625]  eta: 0:25:18    time: 2.6010  max mem: 34987
2023-10-30 07:49:03,695 [INFO] Evaluation  [110/625]  eta: 0:24:35    time: 2.5936  max mem: 34987
2023-10-30 07:49:29,505 [INFO] Evaluation  [120/625]  eta: 0:23:54    time: 2.5859  max mem: 34987
2023-10-30 07:49:55,303 [INFO] Evaluation  [130/625]  eta: 0:23:16    time: 2.5802  max mem: 34987
2023-10-30 07:50:21,053 [INFO] Evaluation  [140/625]  eta: 0:22:39    time: 2.5772  max mem: 34987
2023-10-30 07:50:47,179 [INFO] Evaluation  [150/625]  eta: 0:22:05    time: 2.5936  max mem: 34987
2023-10-30 07:51:14,863 [INFO] Evaluation  [160/625]  eta: 0:21:37    time: 2.6902  max mem: 34987
2023-10-30 07:51:40,749 [INFO] Evaluation  [170/625]  eta: 0:21:03    time: 2.6782  max mem: 34987
2023-10-30 07:52:06,970 [INFO] Evaluation  [180/625]  eta: 0:20:32    time: 2.6052  max mem: 34987
2023-10-30 07:52:33,034 [INFO] Evaluation  [190/625]  eta: 0:20:00    time: 2.6141  max mem: 34987
2023-10-30 07:52:59,114 [INFO] Evaluation  [200/625]  eta: 0:19:30    time: 2.6070  max mem: 34987
2023-10-30 07:53:24,996 [INFO] Evaluation  [210/625]  eta: 0:18:59    time: 2.5979  max mem: 34987
2023-10-30 07:53:51,197 [INFO] Evaluation  [220/625]  eta: 0:18:29    time: 2.6040  max mem: 34987
2023-10-30 07:54:20,985 [INFO] Evaluation  [230/625]  eta: 0:18:06    time: 2.7992  max mem: 34987
2023-10-30 07:54:46,816 [INFO] Evaluation  [240/625]  eta: 0:17:36    time: 2.7807  max mem: 34987
2023-10-30 07:55:17,937 [INFO] Evaluation  [250/625]  eta: 0:17:14    time: 2.8474  max mem: 34987
2023-10-30 07:55:43,839 [INFO] Evaluation  [260/625]  eta: 0:16:44    time: 2.8509  max mem: 34987
2023-10-30 07:56:12,225 [INFO] Evaluation  [270/625]  eta: 0:16:17    time: 2.7139  max mem: 34987
2023-10-30 07:56:38,024 [INFO] Evaluation  [280/625]  eta: 0:15:48    time: 2.7088  max mem: 34987
2023-10-30 07:57:04,123 [INFO] Evaluation  [290/625]  eta: 0:15:19    time: 2.5947  max mem: 34987
2023-10-30 07:57:29,922 [INFO] Evaluation  [300/625]  eta: 0:14:49    time: 2.5948  max mem: 34987
2023-10-30 07:57:56,035 [INFO] Evaluation  [310/625]  eta: 0:14:21    time: 2.5954  max mem: 34987
2023-10-30 07:58:21,888 [INFO] Evaluation  [320/625]  eta: 0:13:52    time: 2.5981  max mem: 34987
2023-10-30 07:58:47,834 [INFO] Evaluation  [330/625]  eta: 0:13:23    time: 2.5898  max mem: 34987
2023-10-30 07:59:13,873 [INFO] Evaluation  [340/625]  eta: 0:12:55    time: 2.5991  max mem: 34987
2023-10-30 07:59:39,920 [INFO] Evaluation  [350/625]  eta: 0:12:27    time: 2.6042  max mem: 34987
2023-10-30 08:00:06,399 [INFO] Evaluation  [360/625]  eta: 0:11:59    time: 2.6261  max mem: 34987
2023-10-30 08:00:32,474 [INFO] Evaluation  [370/625]  eta: 0:11:31    time: 2.6275  max mem: 34987
2023-10-30 08:00:58,186 [INFO] Evaluation  [380/625]  eta: 0:11:03    time: 2.5892  max mem: 34987
2023-10-30 08:01:24,052 [INFO] Evaluation  [390/625]  eta: 0:10:36    time: 2.5787  max mem: 34987
2023-10-30 08:01:49,815 [INFO] Evaluation  [400/625]  eta: 0:10:08    time: 2.5813  max mem: 34987
2023-10-30 08:02:15,688 [INFO] Evaluation  [410/625]  eta: 0:09:40    time: 2.5816  max mem: 34987
2023-10-30 08:02:41,987 [INFO] Evaluation  [420/625]  eta: 0:09:13    time: 2.6084  max mem: 34987
2023-10-30 08:03:08,096 [INFO] Evaluation  [430/625]  eta: 0:08:45    time: 2.6201  max mem: 34987
2023-10-30 08:03:34,457 [INFO] Evaluation  [440/625]  eta: 0:08:18    time: 2.6232  max mem: 34987
2023-10-30 08:04:00,397 [INFO] Evaluation  [450/625]  eta: 0:07:51    time: 2.6149  max mem: 34987
2023-10-30 08:04:26,259 [INFO] Evaluation  [460/625]  eta: 0:07:23    time: 2.5899  max mem: 34987
2023-10-30 08:04:52,023 [INFO] Evaluation  [470/625]  eta: 0:06:56    time: 2.5811  max mem: 34987
2023-10-30 08:05:17,839 [INFO] Evaluation  [480/625]  eta: 0:06:29    time: 2.5789  max mem: 34987
2023-10-30 08:05:43,904 [INFO] Evaluation  [490/625]  eta: 0:06:02    time: 2.5939  max mem: 34987
2023-10-30 08:06:10,497 [INFO] Evaluation  [500/625]  eta: 0:05:35    time: 2.6327  max mem: 34987
2023-10-30 08:06:36,341 [INFO] Evaluation  [510/625]  eta: 0:05:08    time: 2.6216  max mem: 34987
2023-10-30 08:07:02,628 [INFO] Evaluation  [520/625]  eta: 0:04:41    time: 2.6064  max mem: 34987
2023-10-30 08:07:28,365 [INFO] Evaluation  [530/625]  eta: 0:04:14    time: 2.6011  max mem: 34987
2023-10-30 08:07:54,735 [INFO] Evaluation  [540/625]  eta: 0:03:47    time: 2.6052  max mem: 34987
2023-10-30 08:08:21,375 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.6503  max mem: 34987
2023-10-30 08:08:47,242 [INFO] Evaluation  [560/625]  eta: 0:02:53    time: 2.6252  max mem: 34987
2023-10-30 08:09:13,370 [INFO] Evaluation  [570/625]  eta: 0:02:27    time: 2.5995  max mem: 34987
2023-10-30 08:09:39,247 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6000  max mem: 34987
2023-10-30 08:10:05,067 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5847  max mem: 34987
2023-10-30 08:10:31,094 [INFO] Evaluation  [600/625]  eta: 0:01:06    time: 2.5922  max mem: 34987
2023-10-30 08:10:57,477 [INFO] Evaluation  [610/625]  eta: 0:00:40    time: 2.6200  max mem: 34987
2023-10-30 08:11:23,150 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.6018  max mem: 34987
2023-10-30 08:11:32,755 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5649  max mem: 34987
2023-10-30 08:11:32,831 [WARNING] rank 0 starts merging results.
2023-10-30 08:11:32,886 [INFO] {'agg_metrics': 0.6393114491593275, 'total': 4996, 'CH': 63.103953147877014, 'CW': 61.79833679833679, 'TN': 56.98324022346368, 'TC': 67.42081447963801, 'DL': 87.11864406779661, 'DC': 51.41242937853108, 'DO': 76.39344262295083, 'TP': 66.66666666666666}
2023-10-30 08:11:32,888 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_7.pth.
2023-10-30 08:11:33,051 [INFO] Saving checkpoint at epoch 8 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_8.pth.
2023-10-30 08:11:34,857 [INFO] Start training
2023-10-30 08:11:34,897 [INFO] Start training epoch 9, 2133 iters per inner epoch.
2023-10-30 08:11:46,438 [INFO] Train: data epoch: [9]  [   0/2133]  eta: 6:50:14  lr: 0.000001  loss: 0.2785  data_time: 9.3905  time: 11.5399  max mem: 34987
2023-10-30 08:12:43,665 [INFO] Train: data epoch: [9]  [  50/2133]  eta: 0:46:48  lr: 0.000001  loss: 0.2594  data_time: 0.0045  time: 1.0836  max mem: 34987
2023-10-30 08:13:37,880 [INFO] Train: data epoch: [9]  [ 100/2133]  eta: 0:41:15  lr: 0.000001  loss: 0.3045  data_time: 0.0047  time: 1.0879  max mem: 34987
2023-10-30 08:14:32,112 [INFO] Train: data epoch: [9]  [ 150/2133]  eta: 0:38:47  lr: 0.000001  loss: 0.2463  data_time: 0.0051  time: 1.0825  max mem: 34987
2023-10-30 08:15:26,177 [INFO] Train: data epoch: [9]  [ 200/2133]  eta: 0:37:04  lr: 0.000001  loss: 0.2941  data_time: 0.0046  time: 1.0831  max mem: 34987
2023-10-30 08:16:20,095 [INFO] Train: data epoch: [9]  [ 250/2133]  eta: 0:35:39  lr: 0.000001  loss: 0.2533  data_time: 0.0047  time: 1.0746  max mem: 34987
2023-10-30 08:17:14,169 [INFO] Train: data epoch: [9]  [ 300/2133]  eta: 0:34:25  lr: 0.000001  loss: 0.3195  data_time: 0.0047  time: 1.0808  max mem: 34987
2023-10-30 08:18:08,325 [INFO] Train: data epoch: [9]  [ 350/2133]  eta: 0:33:18  lr: 0.000001  loss: 0.2809  data_time: 0.0048  time: 1.0822  max mem: 34987
2023-10-30 08:19:02,495 [INFO] Train: data epoch: [9]  [ 400/2133]  eta: 0:32:14  lr: 0.000001  loss: 0.3313  data_time: 0.0051  time: 1.0817  max mem: 34987
2023-10-30 08:19:56,533 [INFO] Train: data epoch: [9]  [ 450/2133]  eta: 0:31:11  lr: 0.000001  loss: 0.2404  data_time: 0.0050  time: 1.0860  max mem: 34987
2023-10-30 08:20:50,571 [INFO] Train: data epoch: [9]  [ 500/2133]  eta: 0:30:11  lr: 0.000001  loss: 0.3197  data_time: 0.0047  time: 1.0849  max mem: 34987
2023-10-30 08:21:44,763 [INFO] Train: data epoch: [9]  [ 550/2133]  eta: 0:29:12  lr: 0.000001  loss: 0.3269  data_time: 0.0050  time: 1.0776  max mem: 34987
2023-10-30 08:22:39,046 [INFO] Train: data epoch: [9]  [ 600/2133]  eta: 0:28:14  lr: 0.000001  loss: 0.3050  data_time: 0.0049  time: 1.0838  max mem: 34987
2023-10-30 08:23:33,523 [INFO] Train: data epoch: [9]  [ 650/2133]  eta: 0:27:16  lr: 0.000001  loss: 0.3212  data_time: 0.0052  time: 1.0849  max mem: 34987
2023-10-30 08:24:27,813 [INFO] Train: data epoch: [9]  [ 700/2133]  eta: 0:26:19  lr: 0.000001  loss: 0.2904  data_time: 0.0047  time: 1.0791  max mem: 34987
2023-10-30 08:25:22,101 [INFO] Train: data epoch: [9]  [ 750/2133]  eta: 0:25:23  lr: 0.000001  loss: 0.3702  data_time: 0.0046  time: 1.0864  max mem: 34987
2023-10-30 08:26:16,385 [INFO] Train: data epoch: [9]  [ 800/2133]  eta: 0:24:26  lr: 0.000001  loss: 0.2725  data_time: 0.0054  time: 1.0921  max mem: 34987
2023-10-30 08:27:10,634 [INFO] Train: data epoch: [9]  [ 850/2133]  eta: 0:23:30  lr: 0.000001  loss: 0.2326  data_time: 0.0049  time: 1.0778  max mem: 34987
2023-10-30 08:28:06,938 [INFO] Train: data epoch: [9]  [ 900/2133]  eta: 0:22:37  lr: 0.000001  loss: 0.2659  data_time: 0.0063  time: 1.1886  max mem: 34987
2023-10-30 08:29:02,668 [INFO] Train: data epoch: [9]  [ 950/2133]  eta: 0:21:43  lr: 0.000001  loss: 0.3354  data_time: 0.0060  time: 1.1621  max mem: 34987
2023-10-30 08:29:57,134 [INFO] Train: data epoch: [9]  [1000/2133]  eta: 0:20:47  lr: 0.000001  loss: 0.3338  data_time: 0.0049  time: 1.0855  max mem: 34987
2023-10-30 08:30:51,682 [INFO] Train: data epoch: [9]  [1050/2133]  eta: 0:19:51  lr: 0.000001  loss: 0.3438  data_time: 0.0050  time: 1.0915  max mem: 34987
2023-10-30 08:31:46,476 [INFO] Train: data epoch: [9]  [1100/2133]  eta: 0:18:56  lr: 0.000001  loss: 0.2550  data_time: 0.0051  time: 1.0919  max mem: 34987
2023-10-30 08:32:41,151 [INFO] Train: data epoch: [9]  [1150/2133]  eta: 0:18:01  lr: 0.000001  loss: 0.2830  data_time: 0.0050  time: 1.0940  max mem: 34987
2023-10-30 08:33:35,808 [INFO] Train: data epoch: [9]  [1200/2133]  eta: 0:17:06  lr: 0.000001  loss: 0.2677  data_time: 0.0060  time: 1.0869  max mem: 34987
2023-10-30 08:34:30,178 [INFO] Train: data epoch: [9]  [1250/2133]  eta: 0:16:10  lr: 0.000001  loss: 0.2521  data_time: 0.0057  time: 1.0904  max mem: 34987
2023-10-30 08:35:24,258 [INFO] Train: data epoch: [9]  [1300/2133]  eta: 0:15:15  lr: 0.000001  loss: 0.2736  data_time: 0.0043  time: 1.0729  max mem: 34987
2023-10-30 08:36:19,711 [INFO] Train: data epoch: [9]  [1350/2133]  eta: 0:14:20  lr: 0.000001  loss: 0.3119  data_time: 0.0060  time: 1.1043  max mem: 34987
2023-10-30 08:37:13,811 [INFO] Train: data epoch: [9]  [1400/2133]  eta: 0:13:25  lr: 0.000001  loss: 0.2376  data_time: 0.0053  time: 1.0853  max mem: 34987
2023-10-30 08:38:08,626 [INFO] Train: data epoch: [9]  [1450/2133]  eta: 0:12:30  lr: 0.000001  loss: 0.2899  data_time: 0.0047  time: 1.1133  max mem: 34987
2023-10-30 08:39:02,884 [INFO] Train: data epoch: [9]  [1500/2133]  eta: 0:11:34  lr: 0.000001  loss: 0.3167  data_time: 0.0046  time: 1.0905  max mem: 34987
2023-10-30 08:39:56,967 [INFO] Train: data epoch: [9]  [1550/2133]  eta: 0:10:39  lr: 0.000001  loss: 0.3109  data_time: 0.0055  time: 1.0831  max mem: 34987
2023-10-30 08:40:51,013 [INFO] Train: data epoch: [9]  [1600/2133]  eta: 0:09:44  lr: 0.000001  loss: 0.3024  data_time: 0.0046  time: 1.0835  max mem: 34987
2023-10-30 08:41:47,322 [INFO] Train: data epoch: [9]  [1650/2133]  eta: 0:08:50  lr: 0.000001  loss: 0.3406  data_time: 0.0052  time: 1.0801  max mem: 34987
2023-10-30 08:42:41,708 [INFO] Train: data epoch: [9]  [1700/2133]  eta: 0:07:55  lr: 0.000001  loss: 0.3205  data_time: 0.0055  time: 1.0893  max mem: 34987
2023-10-30 08:43:35,927 [INFO] Train: data epoch: [9]  [1750/2133]  eta: 0:07:00  lr: 0.000001  loss: 0.3511  data_time: 0.0044  time: 1.0902  max mem: 34987
2023-10-30 08:44:30,567 [INFO] Train: data epoch: [9]  [1800/2133]  eta: 0:06:05  lr: 0.000001  loss: 0.2815  data_time: 0.0049  time: 1.0915  max mem: 34987
2023-10-30 08:45:24,758 [INFO] Train: data epoch: [9]  [1850/2133]  eta: 0:05:10  lr: 0.000001  loss: 0.2865  data_time: 0.0046  time: 1.0775  max mem: 34987
2023-10-30 08:46:18,876 [INFO] Train: data epoch: [9]  [1900/2133]  eta: 0:04:15  lr: 0.000001  loss: 0.2637  data_time: 0.0059  time: 1.0802  max mem: 34987
2023-10-30 08:47:12,832 [INFO] Train: data epoch: [9]  [1950/2133]  eta: 0:03:20  lr: 0.000001  loss: 0.3210  data_time: 0.0049  time: 1.0820  max mem: 34987
2023-10-30 08:48:06,679 [INFO] Train: data epoch: [9]  [2000/2133]  eta: 0:02:25  lr: 0.000001  loss: 0.3327  data_time: 0.0047  time: 1.0720  max mem: 34987
2023-10-30 08:49:00,632 [INFO] Train: data epoch: [9]  [2050/2133]  eta: 0:01:30  lr: 0.000001  loss: 0.2478  data_time: 0.0049  time: 1.0809  max mem: 34987
2023-10-30 08:49:54,544 [INFO] Train: data epoch: [9]  [2100/2133]  eta: 0:00:36  lr: 0.000001  loss: 0.3213  data_time: 0.0043  time: 1.0784  max mem: 34987
2023-10-30 08:50:31,042 [INFO] Train: data epoch: [9]  [2132/2133]  eta: 0:00:01  lr: 0.000001  loss: 0.2952  data_time: 0.0168  time: 1.0819  max mem: 34987
2023-10-30 08:50:31,054 [INFO] Averaged stats: lr: 0.0000  loss: 0.2913  data_time: 0.0095
2023-10-30 08:50:31,066 [INFO] Evaluating on val.
2023-10-30 08:50:52,960 [INFO] Evaluation  [  0/625]  eta: 3:47:47    time: 21.8673  max mem: 34987
2023-10-30 08:51:23,467 [INFO] Evaluation  [ 10/625]  eta: 0:48:48    time: 4.7612  max mem: 34987
2023-10-30 08:51:52,517 [INFO] Evaluation  [ 20/625]  eta: 0:39:05    time: 2.9777  max mem: 34987
2023-10-30 08:52:22,741 [INFO] Evaluation  [ 30/625]  eta: 0:35:42    time: 2.9629  max mem: 34987
2023-10-30 08:52:48,973 [INFO] Evaluation  [ 40/625]  eta: 0:32:47    time: 2.8220  max mem: 34987
2023-10-30 08:53:20,534 [INFO] Evaluation  [ 50/625]  eta: 0:31:50    time: 2.8892  max mem: 34987
2023-10-30 08:53:46,575 [INFO] Evaluation  [ 60/625]  eta: 0:30:10    time: 2.8797  max mem: 34987
2023-10-30 08:54:15,522 [INFO] Evaluation  [ 70/625]  eta: 0:29:14    time: 2.7490  max mem: 34987
2023-10-30 08:54:41,541 [INFO] Evaluation  [ 80/625]  eta: 0:28:04    time: 2.7479  max mem: 34987
2023-10-30 08:55:07,785 [INFO] Evaluation  [ 90/625]  eta: 0:27:06    time: 2.6130  max mem: 34987
2023-10-30 08:55:33,855 [INFO] Evaluation  [100/625]  eta: 0:26:13    time: 2.6155  max mem: 34987
2023-10-30 08:55:59,935 [INFO] Evaluation  [110/625]  eta: 0:25:25    time: 2.6073  max mem: 34987
2023-10-30 08:56:26,069 [INFO] Evaluation  [120/625]  eta: 0:24:41    time: 2.6105  max mem: 34987
2023-10-30 08:56:51,821 [INFO] Evaluation  [130/625]  eta: 0:23:58    time: 2.5941  max mem: 34987
2023-10-30 08:57:17,525 [INFO] Evaluation  [140/625]  eta: 0:23:17    time: 2.5726  max mem: 34987
2023-10-30 08:57:43,621 [INFO] Evaluation  [150/625]  eta: 0:22:40    time: 2.5899  max mem: 34987
2023-10-30 08:58:09,657 [INFO] Evaluation  [160/625]  eta: 0:22:04    time: 2.6065  max mem: 34987
2023-10-30 08:58:35,320 [INFO] Evaluation  [170/625]  eta: 0:21:28    time: 2.5848  max mem: 34987
2023-10-30 08:59:01,596 [INFO] Evaluation  [180/625]  eta: 0:20:54    time: 2.5968  max mem: 34987
2023-10-30 08:59:27,579 [INFO] Evaluation  [190/625]  eta: 0:20:21    time: 2.6128  max mem: 34987
2023-10-30 08:59:53,366 [INFO] Evaluation  [200/625]  eta: 0:19:48    time: 2.5883  max mem: 34987
2023-10-30 09:00:19,346 [INFO] Evaluation  [210/625]  eta: 0:19:16    time: 2.5881  max mem: 34987
2023-10-30 09:00:45,429 [INFO] Evaluation  [220/625]  eta: 0:18:45    time: 2.6030  max mem: 34987
2023-10-30 09:01:11,936 [INFO] Evaluation  [230/625]  eta: 0:18:15    time: 2.6294  max mem: 34987
2023-10-30 09:01:38,001 [INFO] Evaluation  [240/625]  eta: 0:17:45    time: 2.6284  max mem: 34987
2023-10-30 09:02:04,220 [INFO] Evaluation  [250/625]  eta: 0:17:15    time: 2.6140  max mem: 34987
2023-10-30 09:02:30,384 [INFO] Evaluation  [260/625]  eta: 0:16:45    time: 2.6190  max mem: 34987
2023-10-30 09:02:56,345 [INFO] Evaluation  [270/625]  eta: 0:16:16    time: 2.6060  max mem: 34987
2023-10-30 09:03:22,774 [INFO] Evaluation  [280/625]  eta: 0:15:47    time: 2.6191  max mem: 34987
2023-10-30 09:03:48,981 [INFO] Evaluation  [290/625]  eta: 0:15:18    time: 2.6314  max mem: 34987
2023-10-30 09:04:14,888 [INFO] Evaluation  [300/625]  eta: 0:14:49    time: 2.6055  max mem: 34987
2023-10-30 09:04:41,097 [INFO] Evaluation  [310/625]  eta: 0:14:20    time: 2.6056  max mem: 34987
2023-10-30 09:05:07,113 [INFO] Evaluation  [320/625]  eta: 0:13:52    time: 2.6110  max mem: 34987
2023-10-30 09:05:33,198 [INFO] Evaluation  [330/625]  eta: 0:13:23    time: 2.6047  max mem: 34987
2023-10-30 09:05:59,267 [INFO] Evaluation  [340/625]  eta: 0:12:55    time: 2.6074  max mem: 34987
2023-10-30 09:06:25,554 [INFO] Evaluation  [350/625]  eta: 0:12:27    time: 2.6176  max mem: 34987
2023-10-30 09:06:51,480 [INFO] Evaluation  [360/625]  eta: 0:11:59    time: 2.6104  max mem: 34987
2023-10-30 09:07:17,643 [INFO] Evaluation  [370/625]  eta: 0:11:31    time: 2.6042  max mem: 34987
2023-10-30 09:07:43,451 [INFO] Evaluation  [380/625]  eta: 0:11:03    time: 2.5984  max mem: 34987
2023-10-30 09:08:09,344 [INFO] Evaluation  [390/625]  eta: 0:10:35    time: 2.5848  max mem: 34987
2023-10-30 09:08:35,162 [INFO] Evaluation  [400/625]  eta: 0:10:08    time: 2.5853  max mem: 34987
2023-10-30 09:09:01,008 [INFO] Evaluation  [410/625]  eta: 0:09:40    time: 2.5830  max mem: 34987
2023-10-30 09:09:27,422 [INFO] Evaluation  [420/625]  eta: 0:09:13    time: 2.6128  max mem: 34987
2023-10-30 09:09:53,502 [INFO] Evaluation  [430/625]  eta: 0:08:45    time: 2.6245  max mem: 34987
2023-10-30 09:10:19,847 [INFO] Evaluation  [440/625]  eta: 0:08:18    time: 2.6210  max mem: 34987
2023-10-30 09:10:45,828 [INFO] Evaluation  [450/625]  eta: 0:07:51    time: 2.6162  max mem: 34987
2023-10-30 09:11:11,670 [INFO] Evaluation  [460/625]  eta: 0:07:23    time: 2.5910  max mem: 34987
2023-10-30 09:11:37,453 [INFO] Evaluation  [470/625]  eta: 0:06:56    time: 2.5811  max mem: 34987
2023-10-30 09:12:03,262 [INFO] Evaluation  [480/625]  eta: 0:06:29    time: 2.5793  max mem: 34987
2023-10-30 09:12:29,412 [INFO] Evaluation  [490/625]  eta: 0:06:02    time: 2.5976  max mem: 34987
2023-10-30 09:12:55,842 [INFO] Evaluation  [500/625]  eta: 0:05:35    time: 2.6288  max mem: 34987
2023-10-30 09:13:21,722 [INFO] Evaluation  [510/625]  eta: 0:05:08    time: 2.6152  max mem: 34987
2023-10-30 09:13:48,898 [INFO] Evaluation  [520/625]  eta: 0:04:41    time: 2.6526  max mem: 34987
2023-10-30 09:14:14,687 [INFO] Evaluation  [530/625]  eta: 0:04:14    time: 2.6481  max mem: 34987
2023-10-30 09:14:41,092 [INFO] Evaluation  [540/625]  eta: 0:03:47    time: 2.6096  max mem: 34987
2023-10-30 09:15:07,894 [INFO] Evaluation  [550/625]  eta: 0:03:20    time: 2.6602  max mem: 34987
2023-10-30 09:15:33,817 [INFO] Evaluation  [560/625]  eta: 0:02:54    time: 2.6361  max mem: 34987
2023-10-30 09:16:00,103 [INFO] Evaluation  [570/625]  eta: 0:02:27    time: 2.6103  max mem: 34987
2023-10-30 09:16:26,029 [INFO] Evaluation  [580/625]  eta: 0:02:00    time: 2.6104  max mem: 34987
2023-10-30 09:16:51,819 [INFO] Evaluation  [590/625]  eta: 0:01:33    time: 2.5856  max mem: 34987
2023-10-30 09:17:22,158 [INFO] Evaluation  [600/625]  eta: 0:01:07    time: 2.8059  max mem: 34987
2023-10-30 09:17:47,972 [INFO] Evaluation  [610/625]  eta: 0:00:40    time: 2.8070  max mem: 34987
2023-10-30 09:18:14,533 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.6182  max mem: 34987
2023-10-30 09:18:24,145 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5833  max mem: 34987
2023-10-30 09:18:24,240 [WARNING] rank 0 starts merging results.
2023-10-30 09:18:24,297 [INFO] {'agg_metrics': 0.639911929543635, 'total': 4996, 'CH': 63.103953147877014, 'CW': 62.05821205821206, 'TN': 57.09497206703911, 'TC': 67.26998491704374, 'DL': 86.77966101694915, 'DC': 51.41242937853108, 'DO': 75.73770491803279, 'TP': 68.51851851851852}
2023-10-30 09:18:24,299 [INFO] Removing checkpoint /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_8.pth.
2023-10-30 09:18:24,480 [INFO] Saving checkpoint at epoch 9 to /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_9.pth.
2023-10-30 09:18:27,709 [INFO] Loading checkpoint from /root/VideoQA/sevila/lavis/results/nextqa_sr/checkpoint_best.pth.
2023-10-30 09:18:33,054 [WARNING] 
                Key mismatch when loading checkpoint. This is expected if only part of the model is saved.
                Trying to load the model with strict=False.
                
2023-10-30 09:19:00,445 [INFO] Evaluation  [  0/625]  eta: 4:42:23    time: 27.1101  max mem: 34987
2023-10-30 09:19:32,109 [INFO] Evaluation  [ 10/625]  eta: 0:54:45    time: 5.3427  max mem: 34987
2023-10-30 09:20:00,459 [INFO] Evaluation  [ 20/625]  eta: 0:41:49    time: 2.9997  max mem: 34987
2023-10-30 09:20:26,421 [INFO] Evaluation  [ 30/625]  eta: 0:36:09    time: 2.7143  max mem: 34987
2023-10-30 09:20:52,846 [INFO] Evaluation  [ 40/625]  eta: 0:33:10    time: 2.6188  max mem: 34987
2023-10-30 09:21:18,805 [INFO] Evaluation  [ 50/625]  eta: 0:31:05    time: 2.6190  max mem: 34987
2023-10-30 09:21:45,144 [INFO] Evaluation  [ 60/625]  eta: 0:29:36    time: 2.6147  max mem: 34987
2023-10-30 09:22:14,245 [INFO] Evaluation  [ 70/625]  eta: 0:28:46    time: 2.7717  max mem: 34987
2023-10-30 09:22:40,657 [INFO] Evaluation  [ 80/625]  eta: 0:27:43    time: 2.7753  max mem: 34987
2023-10-30 09:23:07,834 [INFO] Evaluation  [ 90/625]  eta: 0:26:53    time: 2.6791  max mem: 34987
2023-10-30 09:23:33,867 [INFO] Evaluation  [100/625]  eta: 0:26:01    time: 2.6601  max mem: 34987
2023-10-30 09:24:00,031 [INFO] Evaluation  [110/625]  eta: 0:25:15    time: 2.6096  max mem: 34987
2023-10-30 09:24:25,858 [INFO] Evaluation  [120/625]  eta: 0:24:31    time: 2.5994  max mem: 34987
2023-10-30 09:24:51,499 [INFO] Evaluation  [130/625]  eta: 0:23:48    time: 2.5732  max mem: 34987
2023-10-30 09:25:17,129 [INFO] Evaluation  [140/625]  eta: 0:23:08    time: 2.5634  max mem: 34987
2023-10-30 09:25:42,986 [INFO] Evaluation  [150/625]  eta: 0:22:31    time: 2.5742  max mem: 34987
2023-10-30 09:26:08,933 [INFO] Evaluation  [160/625]  eta: 0:21:55    time: 2.5901  max mem: 34987
2023-10-30 09:26:34,738 [INFO] Evaluation  [170/625]  eta: 0:21:20    time: 2.5874  max mem: 34987
2023-10-30 09:27:00,929 [INFO] Evaluation  [180/625]  eta: 0:20:47    time: 2.5996  max mem: 34987
2023-10-30 09:27:26,946 [INFO] Evaluation  [190/625]  eta: 0:20:15    time: 2.6103  max mem: 34987
2023-10-30 09:27:53,012 [INFO] Evaluation  [200/625]  eta: 0:19:43    time: 2.6040  max mem: 34987
2023-10-30 09:28:18,804 [INFO] Evaluation  [210/625]  eta: 0:19:11    time: 2.5927  max mem: 34987
2023-10-30 09:28:44,903 [INFO] Evaluation  [220/625]  eta: 0:18:40    time: 2.5943  max mem: 34987
2023-10-30 09:29:10,917 [INFO] Evaluation  [230/625]  eta: 0:18:10    time: 2.6055  max mem: 34987
2023-10-30 09:29:36,940 [INFO] Evaluation  [240/625]  eta: 0:17:39    time: 2.6017  max mem: 34987
2023-10-30 09:30:02,896 [INFO] Evaluation  [250/625]  eta: 0:17:10    time: 2.5988  max mem: 34987
2023-10-30 09:30:29,058 [INFO] Evaluation  [260/625]  eta: 0:16:40    time: 2.6057  max mem: 34987
2023-10-30 09:30:54,938 [INFO] Evaluation  [270/625]  eta: 0:16:11    time: 2.6019  max mem: 34987
2023-10-30 09:31:24,869 [INFO] Evaluation  [280/625]  eta: 0:15:47    time: 2.7892  max mem: 34987
2023-10-30 09:31:50,930 [INFO] Evaluation  [290/625]  eta: 0:15:18    time: 2.7982  max mem: 34987
2023-10-30 09:32:17,414 [INFO] Evaluation  [300/625]  eta: 0:14:49    time: 2.6270  max mem: 34987
2023-10-30 09:32:43,489 [INFO] Evaluation  [310/625]  eta: 0:14:20    time: 2.6277  max mem: 34987
2023-10-30 09:33:10,257 [INFO] Evaluation  [320/625]  eta: 0:13:53    time: 2.6420  max mem: 34987
2023-10-30 09:33:36,291 [INFO] Evaluation  [330/625]  eta: 0:13:24    time: 2.6398  max mem: 34987
2023-10-30 09:34:02,408 [INFO] Evaluation  [340/625]  eta: 0:12:56    time: 2.6068  max mem: 34987
2023-10-30 09:34:28,813 [INFO] Evaluation  [350/625]  eta: 0:12:28    time: 2.6255  max mem: 34987
2023-10-30 09:34:54,833 [INFO] Evaluation  [360/625]  eta: 0:12:00    time: 2.6211  max mem: 34987
2023-10-30 09:35:20,975 [INFO] Evaluation  [370/625]  eta: 0:11:32    time: 2.6079  max mem: 34987
2023-10-30 09:35:46,848 [INFO] Evaluation  [380/625]  eta: 0:11:04    time: 2.6006  max mem: 34987
2023-10-30 09:36:18,110 [INFO] Evaluation  [390/625]  eta: 0:10:39    time: 2.8547  max mem: 34987
2023-10-30 09:36:43,934 [INFO] Evaluation  [400/625]  eta: 0:10:11    time: 2.8521  max mem: 34987
2023-10-30 09:37:14,671 [INFO] Evaluation  [410/625]  eta: 0:09:46    time: 2.8276  max mem: 34987
2023-10-30 09:37:41,015 [INFO] Evaluation  [420/625]  eta: 0:09:18    time: 2.8537  max mem: 34987
2023-10-30 09:38:31,213 [INFO] Evaluation  [430/625]  eta: 0:09:01    time: 3.8248  max mem: 34987
2023-10-30 09:39:00,950 [INFO] Evaluation  [440/625]  eta: 0:08:34    time: 3.9912  max mem: 34987
2023-10-30 09:39:27,133 [INFO] Evaluation  [450/625]  eta: 0:08:06    time: 2.7919  max mem: 34987
2023-10-30 09:39:53,052 [INFO] Evaluation  [460/625]  eta: 0:07:37    time: 2.6043  max mem: 34987
2023-10-30 09:40:18,867 [INFO] Evaluation  [470/625]  eta: 0:07:09    time: 2.5865  max mem: 34987
2023-10-30 09:40:44,726 [INFO] Evaluation  [480/625]  eta: 0:06:41    time: 2.5836  max mem: 34987
2023-10-30 09:41:10,927 [INFO] Evaluation  [490/625]  eta: 0:06:13    time: 2.6028  max mem: 34987
2023-10-30 09:41:37,279 [INFO] Evaluation  [500/625]  eta: 0:05:45    time: 2.6275  max mem: 34987
2023-10-30 09:42:03,472 [INFO] Evaluation  [510/625]  eta: 0:05:17    time: 2.6269  max mem: 34987
2023-10-30 09:42:29,793 [INFO] Evaluation  [520/625]  eta: 0:04:49    time: 2.6254  max mem: 34987
2023-10-30 09:42:55,709 [INFO] Evaluation  [530/625]  eta: 0:04:21    time: 2.6117  max mem: 34987
2023-10-30 09:43:22,294 [INFO] Evaluation  [540/625]  eta: 0:03:53    time: 2.6249  max mem: 34987
2023-10-30 09:43:48,825 [INFO] Evaluation  [550/625]  eta: 0:03:26    time: 2.6556  max mem: 34987
2023-10-30 09:44:16,689 [INFO] Evaluation  [560/625]  eta: 0:02:58    time: 2.7193  max mem: 34987
2023-10-30 09:44:42,924 [INFO] Evaluation  [570/625]  eta: 0:02:31    time: 2.7045  max mem: 34987
2023-10-30 09:45:09,090 [INFO] Evaluation  [580/625]  eta: 0:02:03    time: 2.6198  max mem: 34987
2023-10-30 09:45:34,925 [INFO] Evaluation  [590/625]  eta: 0:01:36    time: 2.5997  max mem: 34987
2023-10-30 09:46:01,118 [INFO] Evaluation  [600/625]  eta: 0:01:08    time: 2.6012  max mem: 34987
2023-10-30 09:46:26,987 [INFO] Evaluation  [610/625]  eta: 0:00:41    time: 2.6029  max mem: 34987
2023-10-30 09:46:52,705 [INFO] Evaluation  [620/625]  eta: 0:00:13    time: 2.5792  max mem: 34987
2023-10-30 09:47:02,394 [INFO] Evaluation  [624/625]  eta: 0:00:02    time: 2.5491  max mem: 34987
2023-10-30 09:47:02,490 [WARNING] rank 0 starts merging results.
2023-10-30 09:47:02,816 [INFO] {'agg_metrics': 0.6423138510808647, 'total': 4996, 'CH': 63.98243045387994, 'CW': 62.31808731808732, 'TN': 57.20670391061452, 'TC': 66.66666666666666, 'DL': 86.4406779661017, 'DC': 51.41242937853108, 'DO': 77.04918032786885, 'TP': 70.37037037037037}
2023-10-30 09:47:02,818 [INFO] Training time 11:39:13
