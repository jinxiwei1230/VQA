{
 "cells": [
  {
   "cell_type": "code",
   "id": "4204c7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:20:50.357190Z",
     "start_time": "2024-10-15T04:20:49.217721Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:20:54.460429Z",
     "start_time": "2024-10-15T04:20:54.457102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ],
   "id": "352a0ebdf7a16932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\xiwei\\Desktop\\大创\\sevila\\sevila_data\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f55a44ff",
   "metadata": {},
   "source": [
    "create folder for each dataset first"
   ]
  },
  {
   "cell_type": "code",
   "id": "09845339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:20:58.907797Z",
     "start_time": "2024-10-15T04:20:58.902912Z"
    }
   },
   "source": [
    "# 将 int64 值转换为普通的 Python 整数\n",
    "def convert(o):\n",
    "    if isinstance(o, np.int64):\n",
    "        return int(o)\n",
    "    raise TypeError(f\"对象类型 {o.__class__.__name__} 无法进行 JSON 序列化\")\n",
    "\n",
    "\n",
    "def save_json(content, save_path):\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(content, f, default=convert)\n",
    "\n",
    "\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T04:33:56.543469Z",
     "start_time": "2024-10-15T04:33:56.471189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = 'C:/Users/xiwei/Desktop/1'\n",
    "map_json = os.path.join(path, \"map_vid_vidorID.json\").replace('\\\\', '/')\n",
    "key = [\"video_id\", \"question\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"answer\", \"qid\", \"type\"]\n",
    "vid_map = json.load(open(map_json))\n",
    "\n",
    "for n_subset in [\"sanguoyanyi\"]:\n",
    "    raw_subset_csv = os.path.join(path, f\"{n_subset}.csv\")\n",
    "    raw_subset = pd.read_csv(raw_subset_csv, delimiter=\",\", dtype={\"video_id\": str, \"qid\": str})\n",
    "    raw_subset = raw_subset.dropna(subset=[\"video_id\"])\n",
    "    subset = [{k: raw_subset.iloc[i][k] for k in key} for i in range(len(raw_subset))]\n",
    "\n",
    "    new_subset = []\n",
    "    for qa in subset:\n",
    "        print(\"Current video_id:\", qa[\"video_id\"])  \n",
    "        qa_dict = {}\n",
    "        qa_dict[\"video_id\"] = vid_map[str(qa[\"video_id\"])]\n",
    "        qa_dict[\"num_option\"] = 5\n",
    "        qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video_id\"]), str(qa[\"qid\"])])\n",
    "        for i in range(5):\n",
    "            qa_dict[f\"a{str(i)}\"] = qa[f\"a{str(i)}\"] + \".\"\n",
    "        qa_dict[\"answer\"] = qa[\"answer\"]\n",
    "        qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "        new_subset.append(qa_dict)\n",
    "\n",
    "    save_json(new_subset, os.path.join(path, f\"{n_subset}.json\"))\n"
   ],
   "id": "85393bdcc32b6378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/xiwei/Desktop/1/map_vid_vidorID.json\n",
      "Current video_id: (501)\n",
      "Current video_id: (502)\n",
      "Current video_id: (503)\n",
      "Current video_id: (504)\n",
      "Current video_id: (505)\n",
      "Current video_id: (506)\n",
      "Current video_id: (507)\n",
      "Current video_id: (508)\n",
      "Current video_id: (509)\n",
      "Current video_id: (510)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "demo数据集",
   "id": "567110bf75291e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T12:41:46.763521Z",
     "start_time": "2024-10-12T12:41:46.726602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"/home/disk2/dachuang1-23/demo/qa_annos\"\n",
    "map_json = os.path.join(path, \"map_vid_vidorID.json\").replace('\\\\', '/')\n",
    "print(map_json)  # 确保输出路径是正斜杠\n",
    "\n",
    "\n",
    "key = [\"video_id\", \"question\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"answer\", \"qid\", \"type\"]\n",
    "vid_map = json.load(open(map_json))\n",
    "\n",
    "for n_subset in [\"demo-val\"]:\n",
    "    raw_subset_csv = os.path.join(path, f\"{n_subset}.csv\")\n",
    "    raw_subset = pd.read_csv(raw_subset_csv, delimiter=\",\", dtype={\"video_id\": str, \"qid\": str})\n",
    "    raw_subset = raw_subset.dropna(subset=[\"video_id\"])\n",
    "    subset = [{k: raw_subset.iloc[i][k] for k in key} for i in range(len(raw_subset))]\n",
    "\n",
    "    new_subset = []\n",
    "    for qa in subset:\n",
    "        print(\"Current video_id:\", qa[\"video_id\"])  \n",
    "        qa_dict = {}\n",
    "        qa_dict[\"video_id\"] = vid_map[str(qa[\"video_id\"])]\n",
    "        qa_dict[\"num_option\"] = 5\n",
    "        qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video_id\"]), str(qa[\"qid\"])])\n",
    "        for i in range(5):\n",
    "            qa_dict[f\"a{str(i)}\"] = qa[f\"a{str(i)}\"] + \".\"\n",
    "        qa_dict[\"answer\"] = qa[\"answer\"]\n",
    "        qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "        new_subset.append(qa_dict)\n",
    "\n",
    "    save_json(new_subset, os.path.join(path, f\"{n_subset}.json\"))\n"
   ],
   "id": "1b56ea0706dc70d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/disk2/dachuang1-23/demo/qa_annos/map_vid_vidorID.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/disk2/dachuang1-23/demo/qa_annos/map_vid_vidorID.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(map_json)  \u001B[38;5;66;03m# 确保输出路径是正斜杠\u001B[39;00m\n\u001B[0;32m      6\u001B[0m key \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvideo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma0\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 7\u001B[0m vid_map \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(map_json))\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n_subset \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdemo-val\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m     10\u001B[0m     raw_subset_csv \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_subset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\CHJpytorch\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/disk2/dachuang1-23/demo/qa_annos/map_vid_vidorID.json'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "1167f709",
   "metadata": {},
   "source": [
    "NExT-QA"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d49722d",
   "metadata": {},
   "source": [
    "#这段代码的功能是将train.csv、val.csv 和 test.csv 三个文件中的问答数据处理后，保存为对应的JSON格式文件。\n",
    "#这段代码的主要目的是将多个CSV格式的数据集转换为JSON格式，并根据指定的规则重新格式化数据。这个过程包括了视频ID的映射、问题和答案的格式化、以及保存处理后的数据。最终输出的JSON文件可以用于后续的模型训练或评估。\n",
    "\n",
    "path = \"/home/disk2/VQA/NExT-QA/qa_annos\"\n",
    "key = [\"video_id\", \"question\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"answer\", \"qid\", \"type\"]\n",
    "map_json = os.path.join(path, \"map_vid_vidorID.json\")\n",
    "vid_map = json.load(open(map_json))\n",
    "\n",
    "for n_subset in [\"train\", \"val\", \"test\"]:\n",
    "    raw_subset_csv = os.path.join(path, f\"{n_subset}.csv\")\n",
    "    raw_subset = pd.read_csv(raw_subset_csv, delimiter=\",\")\n",
    "\n",
    "    subset = [{k: raw_subset.iloc[i][k] for k in key} for i in range(len(raw_subset))]\n",
    "\n",
    "    new_subset = []\n",
    "    for qa in subset:\n",
    "        qa_dict = {}\n",
    "        qa_dict[\"video_id\"] = vid_map[str(qa[\"video_id\"])]\n",
    "        qa_dict[\"num_option\"] = 5\n",
    "        qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video_id\"]), str(qa[\"qid\"])])\n",
    "        for i in range(5):\n",
    "            qa_dict[f\"a{str(i)}\"] = qa[f\"a{str(i)}\"] + \".\"\n",
    "        qa_dict[\"answer\"] = qa[\"answer\"]\n",
    "        qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "        new_subset.append(qa_dict)\n",
    "\n",
    "    save_json(new_subset, os.path.join(path, f\"{n_subset}.json\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d7f4b92",
   "metadata": {},
   "source": [
    "STAR"
   ]
  },
  {
   "cell_type": "code",
   "id": "fed28d5a",
   "metadata": {},
   "source": [
    "train_path = 'STAR_train.json'\n",
    "val_path = 'STAR_val.json'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71918325",
   "metadata": {},
   "source": [
    "#这段代码的主要功能是将 STAR_train.json 和 STAR_val.json 文件中的问答数据重新格式化，并将处理后的数据保存为新的 JSON 文件。具体来说，它将每个问题和对应的答案选项重新组织成一种统一的格式。\n",
    "train = json.load(open(train_path))\n",
    "val = json.load(open(val_path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "209c3b2a",
   "metadata": {},
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "for qa in train:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['video_id']\n",
    "    qa_dict['num_option'] = 4\n",
    "    qa_dict['qid'] = qa['question_id']\n",
    "    for i, choice in enumerate(qa['choices']):\n",
    "        qa_dict['a{}'.format(str(i))] = choice['choice']\n",
    "        if choice['choice'] == qa['answer']:\n",
    "            answer = i\n",
    "    qa_dict['answer'] = answer\n",
    "    qa_dict['question'] = qa['question']\n",
    "    qa_dict['start'] = qa['start']\n",
    "    qa_dict['end'] = qa['end']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['video_id']\n",
    "    qa_dict['num_option'] = 4\n",
    "    qa_dict['qid'] = qa['question_id']\n",
    "    for i, choice in enumerate(qa['choices']):\n",
    "        qa_dict['a{}'.format(str(i))] = choice['choice']\n",
    "        if choice['choice'] == qa['answer']:\n",
    "            answer = i\n",
    "    qa_dict['answer'] = answer\n",
    "    qa_dict['question'] = qa['question']\n",
    "    qa_dict['start'] = qa['start']\n",
    "    qa_dict['end'] = qa['end']\n",
    "    new_val.append(qa_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6ced28c",
   "metadata": {},
   "source": [
    "\n",
    "save_json(new_train, 'star/train.json')\n",
    "save_json(new_val, 'star/val.json')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33accd21",
   "metadata": {},
   "source": [
    "How2QA"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ab388e9",
   "metadata": {},
   "source": [
    "train_path = 'how2qa_train_release.jsonl'\n",
    "val_path = 'how2qa_val_release.jsonl'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81bdadb9",
   "metadata": {},
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5164d95e",
   "metadata": {},
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 4\n",
    "    qa_dict['qid'] = 'HOW2QA_' + str(i)\n",
    "    for j in range(4):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['a{}'.format(str(j))]\n",
    "        \n",
    "    qa_dict['answer'] = qa['answer_idx']\n",
    "    qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'].split('-')[0]\n",
    "    qa_dict['end'] = qa['ts'].split('-')[1]\n",
    "        \n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 4\n",
    "    qa_dict['qid'] = 'HOW2QA_' + str(i)\n",
    "    for j in range(4):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['a{}'.format(str(j))]\n",
    "        \n",
    "    qa_dict['answer'] = qa['answer_idx']\n",
    "    qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'].split('-')[0]\n",
    "    qa_dict['end'] = qa['ts'].split('-')[1]\n",
    "        \n",
    "    new_val.append(qa_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2daa2a4a",
   "metadata": {},
   "source": [
    "save_json(new_train, 'how2qa/train.json')\n",
    "save_json(new_val, 'how2qa/val.json')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d326183b",
   "metadata": {},
   "source": [
    "TVQA"
   ]
  },
  {
   "cell_type": "code",
   "id": "319d0fb5",
   "metadata": {},
   "source": [
    "train_path = 'tvqa_train.jsonl'\n",
    "val_path = 'tvqa_val.jsonl'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0f498f5",
   "metadata": {},
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7c24578a",
   "metadata": {},
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 5\n",
    "    qa_dict['qid'] = 'TVQA_' + str(i)\n",
    "    for j in range(5):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['a{}'.format(str(j))]\n",
    "    qa_dict['answer'] = qa['answer_idx']\n",
    "    qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'].split('-')[0]\n",
    "    qa_dict['end'] = qa['ts'].split('-')[1]\n",
    "        \n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 5\n",
    "    qa_dict['qid'] = 'TVQA_' + str(i)\n",
    "    for j in range(5):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['a{}'.format(str(j))]\n",
    "    qa_dict['answer'] = qa['answer_idx']\n",
    "    qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'].split('-')[0]\n",
    "    qa_dict['end'] = qa['ts'].split('-')[1]\n",
    "        \n",
    "    new_val.append(qa_dict)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "348cafde",
   "metadata": {},
   "source": [
    "save_json(new_train, 'tvqa/train.json')\n",
    "save_json(new_val, 'tvqa/val.json')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52259cd2",
   "metadata": {},
   "source": [
    "# VLPE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1edd8e06",
   "metadata": {},
   "source": [
    "VLEP"
   ]
  },
  {
   "cell_type": "code",
   "id": "53646ebf",
   "metadata": {},
   "source": [
    "train_path = 'vlep_train_release.jsonl'\n",
    "val_path = 'vlep_dev_release.jsonl'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff92c404",
   "metadata": {},
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd62a11e",
   "metadata": {},
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 2\n",
    "    qa_dict['qid'] = 'VLEP_' + str(qa['example_id'])\n",
    "\n",
    "    for j in range(2):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['events'][j]\n",
    "    qa_dict['answer'] = qa['answer']\n",
    "    # qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'][0]\n",
    "    qa_dict['end'] = qa['ts'][1]\n",
    "    \n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid_name']\n",
    "    qa_dict['num_option'] = 2\n",
    "    qa_dict['qid'] = 'VLEP_' + str(qa['example_id'])\n",
    "\n",
    "    for j in range(2):\n",
    "        qa_dict['a{}'.format(str(j))] = qa['events'][j]\n",
    "    qa_dict['answer'] = qa['answer']\n",
    "    # qa_dict['question'] = qa['q']\n",
    "    qa_dict['start'] = qa['ts'][0]\n",
    "    qa_dict['end'] = qa['ts'][1]\n",
    "        \n",
    "    new_val.append(qa_dict)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "186de10a",
   "metadata": {},
   "source": [
    "save_json(new_train, 'vlep/train.json')\n",
    "save_json(new_val, 'vlep/val.json')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5b4ce14",
   "metadata": {},
   "source": [
    "QVHighlights"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a00480e",
   "metadata": {},
   "source": [
    "train_path = 'highlight_train_release.jsonl'\n",
    "val_path = 'highlight_val_release.jsonl'\n",
    "test_path = 'highlight_test_release.jsonl'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cc2f260",
   "metadata": {},
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "507365fc",
   "metadata": {},
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'QVHighlight_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['relevant_windows']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'QVHighlight_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['relevant_windows']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'QVHighlight_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    new_test.append(qa_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f9754fc",
   "metadata": {},
   "source": [
    "save_json(new_train, 'qvh/train.json')\n",
    "save_json(new_val, 'qvh/val.json')\n",
    "save_json(new_test, 'qvh/test.json')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('lavis_py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "066cb32fa0571e46f494b9369671dc4c83cbf0cda28cef3f9e0cac88461cd93b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
